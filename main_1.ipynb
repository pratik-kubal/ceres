{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Linear Regression README:\n",
    "Modes:\n",
    "1. Human Observed Dataset\n",
    "2. GSC\n",
    "Feature Type:\n",
    "a. Feature Concat\n",
    "b. Feature Subs\n",
    "'''\n",
    "mode = 1\n",
    "subMode = 'b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GSC or HOD??\n",
    "if(mode == 1):\n",
    "    hum_obs_master_data = pd.read_csv(\"../HumanObserved-Dataset/HumanObserved-Dataset/HumanObserved-Features-Data/HumanObserved-Features-Data.csv\")\n",
    "    hum_obs_pos_data = pd.read_csv(\"../HumanObserved-Dataset/HumanObserved-Dataset/HumanObserved-Features-Data/same_pairs.csv\")\n",
    "    hum_obs_neg_data = pd.read_csv(\"../HumanObserved-Dataset/HumanObserved-Dataset/HumanObserved-Features-Data/diffn_pairs.csv\")\n",
    "elif(mode ==2):\n",
    "    gsc_master_data = pd.read_csv(\"../GSC-Dataset/GSC-Dataset/GSC-Features-Data/GSC-Features.csv\")\n",
    "    gsc_pos_data = pd.read_csv(\"../GSC-Dataset/GSC-Dataset/GSC-Features-Data/same_pairs.csv\")\n",
    "    gsc_neg_data = pd.read_csv(\"../GSC-Dataset/GSC-Dataset/GSC-Features-Data/diffn_pairs.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_setting_one(master_data,pos_data):\n",
    "    raw_data_temp = pd.concat([pos_data.set_index('img_id_A'),master_data.set_index('img_id')],axis=1,join='inner').reset_index()\n",
    "    raw_data_feature_concat = pd.concat([raw_data_temp.set_index('img_id_B'),master_data.set_index('img_id')],axis=1,join='inner').reset_index()\n",
    "    if(np.shape(raw_data_feature_concat)[1] < 25):\n",
    "        raw_data_feature_concat.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "        num_features = 9 + 1\n",
    "    else:\n",
    "        num_features = 512+1\n",
    "    col_rename = ['img_id_B','img_id_A','target']\n",
    "    for columns in range(1,len(list(raw_data_feature_concat.columns)[3:])+1):\n",
    "        if(columns < num_features):\n",
    "            col_rename.append(\"fa\"+str(columns))\n",
    "        else:\n",
    "            col_rename.append(\"fb\"+str(columns - num_features+1))\n",
    "    raw_data_feature_concat.columns = col_rename\n",
    "    col_rename.append(col_rename.pop(2))\n",
    "    temp = col_rename[0]\n",
    "    col_rename[0] = col_rename[1]\n",
    "    col_rename[1] = temp\n",
    "    raw_data_feature_concat = raw_data_feature_concat[col_rename]\n",
    "    return raw_data_feature_concat\n",
    "\n",
    "def create_setting_two(raw_data_feature_concat):\n",
    "    raw_data_feature_subs = pd.concat([raw_data_feature_concat.iloc[:,0:2],raw_data_feature_concat.iloc[:,-1]],axis=1,join='inner').reset_index()\n",
    "    for columns in range(1,int((len(list(raw_data_feature_concat.columns))-3)/2+1)):\n",
    "        raw_data_feature_subs['fm'+str(columns)] = abs(raw_data_feature_concat['fa'+str(columns)] - raw_data_feature_concat['fb'+str(columns)])\n",
    "    col_swap = list(raw_data_feature_subs.columns)[1:]\n",
    "    col_swap.append(col_swap.pop(2))\n",
    "    raw_data_feature_subs=raw_data_feature_subs[col_swap]\n",
    "    return raw_data_feature_subs\n",
    "\n",
    "def representativeClustering(data,sizeOfTheCluster,seed):\n",
    "    kmeans = KMeans(n_clusters=sizeOfTheCluster, random_state=seed)\n",
    "    kmeans_data = kmeans.fit_predict(data.iloc[:,data.columns != 'target'])\n",
    "    data = data.join(pd.DataFrame(kmeans_data,columns=[\"kmean_cluster_number\"]))\n",
    "    '''\n",
    "    2D stratified sampling on the target value and the cluster number so that the algorithm which we will \n",
    "    implement will have fair chances of learning all types of data.\n",
    "    '''\n",
    "    train,test_val = train_test_split(data,test_size = 0.2,stratify=data[[\"target\",\"kmean_cluster_number\"]],random_state=seed)\n",
    "    val,test = train_test_split(test_val,test_size = 0.5,stratify=test_val[[\"target\",\"kmean_cluster_number\"]],random_state=seed)\n",
    "    '''\n",
    "    Cluster number is not required now\n",
    "    '''\n",
    "    train = train.drop([\"kmean_cluster_number\"],axis=1)\n",
    "    test = test.drop([\"kmean_cluster_number\"],axis=1)\n",
    "    val = val.drop([\"kmean_cluster_number\"],axis=1)\n",
    "\n",
    "    mu = kmeans.cluster_centers_\n",
    "    return train,test,val,mu\n",
    "\n",
    "# Linear Regression Functions Development\n",
    "def covar(trainData,num_basis):\n",
    "    ''' \n",
    "    Getting the covar over the training data based on number of basics we have implemented\n",
    "    Changed the spread for Gaussian radial basis function\n",
    "    '''\n",
    "    #print(\"Using Uniform Gaussian radial basis function\")\n",
    "    train_transpose = np.transpose(trainData)\n",
    "    iden = np.identity(np.shape(train_transpose)[0])\n",
    "    for i in range(0,np.shape(train_transpose)[0]):\n",
    "        # EDIT HERE FOR PRECISION AND NON UNIFORM RADIAL BASICS\n",
    "        iden[i] = np.dot(iden[i],np.dot(200*i,np.var(train_transpose.iloc[i,:])))\n",
    "    return iden\n",
    "\n",
    "def genPhi(train,covarMat,num_basis,mu):\n",
    "    '''\n",
    "    Getting the Phi based on the covariance and number of basis\n",
    "    '''\n",
    "    phiMat = np.zeros((len(train),int(num_basis))) \n",
    "    covarMatInv = np.linalg.pinv(covarMat)\n",
    "    for i in range(0,num_basis):\n",
    "        for j in range(0,len(train)):\n",
    "            subsResult = (np.subtract(train.iloc[j,],mu[i,]))\n",
    "            L = np.dot(np.transpose(subsResult),covarMatInv)\n",
    "            R = np.dot(L,subsResult)\n",
    "            phiMat[j][i] = math.exp(-np.dot(0.5,R))\n",
    "    return phiMat\n",
    "\n",
    "def updateWeights(weights,phiMat,train_lab,alpha,lam): \n",
    "    midT = np.dot(np.transpose(weights),phiMat)\n",
    "    deltaL = -(np.subtract(train_lab,midT))\n",
    "    deltaD = np.dot(float(deltaL),phiMat)\n",
    "    deltaE = np.transpose(np.matrix(deltaD)) + np.dot(lam,weights)\n",
    "\n",
    "    delta = np.dot(-alpha,deltaE)\n",
    "    new_weight = weights + delta\n",
    "    return new_weight\n",
    "\n",
    "def GetValTest(VAL_PHI,W):\n",
    "    Y = np.dot(np.transpose(prev_weight),np.transpose(VAL_PHI))\n",
    "    ##print (\"Test Out Generated..\")\n",
    "    return Y\n",
    "\n",
    "def GetErms(valData,ValDataAct):\n",
    "    sum = 0.0\n",
    "    t=0\n",
    "    accuracy = 0.0\n",
    "    counter = 0\n",
    "    val = 0.0\n",
    "    for i in range (0,len(valData)):\n",
    "        sum = sum + math.pow((ValDataAct[i] - valData[i]),2)\n",
    "        if(int(np.around(valData[i], 0)) == ValDataAct[i]):\n",
    "            counter+=1\n",
    "    accuracy = (float((counter*100))/float(len(valData)))\n",
    "    ##print (\"Accuracy Generated..\")\n",
    "    ##print (\"Validation E_RMS : \" + str(math.sqrt(sum/len(VAL_TEST_OUT))))\n",
    "    return (str(accuracy) + ',' +  str(math.sqrt(sum/len(valData)))),math.sqrt(sum/len(valData))\n",
    "\n",
    "def plotData(log_erms_train,log_erms_val,log_erms_test):\n",
    "    writePlot('log_erms_train',log_erms_train)\n",
    "    writePlot('log_erms_val',log_erms_val)\n",
    "    writePlot('log_erms_test',log_erms_test)\n",
    "    return True\n",
    "\n",
    "def writePlot(filename,log):\n",
    "    df = pd.DataFrame(log)\n",
    "    ax = df.plot(figsize=(10,15))\n",
    "    ax.ticklabel_format(useOffset=False)\n",
    "\n",
    "    plt.savefig(('./'+filename+'.png'),bbox_inches='tight')\n",
    "    plt.close(\"all\")\n",
    "    \n",
    "def epoch_shuffle(train,train_lab,phiMat):\n",
    "    # Merge\n",
    "    temp = pd.merge(train.reset_index(),pd.DataFrame(train_lab).reset_index())\n",
    "    temp.columns.values[-1] = \"target\"\n",
    "    temp = pd.merge(temp,pd.DataFrame(phiMat).reset_index())\n",
    "    temp = temp.sample(frac=1,random_state=431).reset_index().iloc[:,2:]\n",
    "    if(mode == 1):\n",
    "        if(subMode == 'a'):\n",
    "            num_feat = 18\n",
    "        elif(subMode == 'b'):\n",
    "            num_feat = 9\n",
    "    elif(mode == 2):\n",
    "        if(subMode == 'a'):\n",
    "            num_feat = 512*2\n",
    "        elif(subMode == 'b'):\n",
    "            num_feat = 512\n",
    "    train = temp.iloc[:,0:num_feat]\n",
    "    train_lab = np.asarray(temp.iloc[:,num_feat])\n",
    "    phiMat = np.array(temp.iloc[:,num_feat+1:])\n",
    "    return train,train_lab,phiMat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Various Setting Generations\n",
    "Oversampling = o\n",
    "Undersampling = u\n",
    "Perfect = p\n",
    "'''\n",
    "sampling = 'p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(sampling == 'p'):\n",
    "    if(mode ==1):\n",
    "        raw_pos_data = create_setting_one(hum_obs_master_data,hum_obs_pos_data)\n",
    "        raw_neg_data = create_setting_one(hum_obs_master_data,hum_obs_neg_data.sample(len(raw_pos_data),random_state = 444))\n",
    "        if(subMode == 'b'):\n",
    "            raw_pos_data = create_setting_two(raw_pos_data)\n",
    "            raw_neg_data = create_setting_two(raw_neg_data)\n",
    "            del hum_obs_master_data,hum_obs_pos_data,hum_obs_neg_data\n",
    "    elif(mode == 2):\n",
    "    # High Memory -> NEED TO FIX\n",
    "        raw_pos_data = create_setting_one(gsc_master_data,gsc_pos_data)\n",
    "        raw_neg_data = create_setting_one(gsc_master_data,gsc_neg_data.sample(len(gsc_pos_data),random_state = 444))\n",
    "        if(subMode == 'b'):\n",
    "            raw_pos_data = create_setting_two(raw_pos_data)\n",
    "            raw_neg_data = create_setting_two(raw_neg_data)\n",
    "            del gsc_master_data,gsc_pos_data,gsc_neg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Partition Scheme\n",
    "unseenWriter = true\n",
    "default = false\n",
    "'''\n",
    "partScheme = False\n",
    "if(partScheme):\n",
    "    # Unseen Writer partitions\n",
    "    raw_data_feature_concat_pos[['A','A_imgNo']] = raw_data_feature_concat_pos['img_id_A'].str.extract('(\\d\\d\\d\\d)([a-z])', expand=False)\n",
    "    raw_data_feature_concat_pos[['B','B_imgNo']] = raw_data_feature_concat_pos['img_id_B'].str.extract('(\\d\\d\\d\\d)([a-z])', expand=False)\n",
    "    #raw_data_feature_concat['img_id_A'].str.extract('(?P<writerA>\\d\\d\\d\\d)(?P<imageNo>[abcd])', expand=False)\n",
    "    raw_data_feature_concat_neg[['A','A_imgNo']] = raw_data_feature_concat_neg['img_id_A'].str.extract('(\\d\\d\\d\\d)([a-z])', expand=False)\n",
    "    raw_data_feature_concat_neg[['B','B_imgNo']] = raw_data_feature_concat_neg['img_id_B'].str.extract('(\\d\\d\\d\\d)([a-z])', expand=False)\n",
    "    data = pd.concat([raw_pos_data,raw_neg_data],ignore_index=True)\n",
    "else:\n",
    "    data = pd.concat([raw_pos_data,raw_neg_data],ignore_index=True)\n",
    "data = data.iloc[:,2:np.shape(data)[1]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "Sum_of_squared_distances = []\n",
    "K = range(2,16)\n",
    "for k in K:\n",
    "    print(k)\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(data.iloc[:,0:len(data.columns)-1])\n",
    "    Sum_of_squared_distances.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe6010dd978>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get The heatmap of corr to determine the clusters\n",
    "sns.heatmap(np.corrcoef(raw_pos_data.iloc[:,2:-1],raw_neg_data.iloc[:,2:-1],rowvar=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(mode == 2):\n",
    "    if(subMode == 'a'):\n",
    "        M = 9\n",
    "else:\n",
    "    M = 5\n",
    "data = data.sample(frac=1)\n",
    "train,test,val,mu = representativeClustering(data=data,sizeOfTheCluster=M,seed=421)\n",
    "if(sampling == 'o'):\n",
    "    pos = train[train['target'] == 1]\n",
    "    neg = train[train['target'] == 0]\n",
    "    train_pos = pd.concat([pos,pos,pos,pos,pos],ignore_index=True)\n",
    "    train_neg = neg.sample(n=len(pos))\n",
    "    train = pd.concat([train_pos,train_neg])\n",
    "    del pos,neg,train_pos,train_neg\n",
    "train = train.sample(frac=1,random_state=444).reset_index().iloc[:,1:]\n",
    "train_lab = train.iloc[:,train.columns == 'target']\n",
    "val_lab = val.iloc[:,val.columns == 'target']\n",
    "test_lab = test.iloc[:,test.columns == 'target']\n",
    "train = train.iloc[:,train.columns != 'target']\n",
    "val = val.iloc[:,val.columns != 'target']\n",
    "test = val.iloc[:,test.columns != 'target']\n",
    "#print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fm1</th>\n",
       "      <th>fm2</th>\n",
       "      <th>fm3</th>\n",
       "      <th>fm4</th>\n",
       "      <th>fm5</th>\n",
       "      <th>fm6</th>\n",
       "      <th>fm7</th>\n",
       "      <th>fm8</th>\n",
       "      <th>fm9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.225141</td>\n",
       "      <td>2.077330</td>\n",
       "      <td>1.527650</td>\n",
       "      <td>-1.203085</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>-1.306106</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.225141</td>\n",
       "      <td>2.077330</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>1.309688</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>0.496648</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.225141</td>\n",
       "      <td>1.304441</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-1.203085</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>-1.041079</td>\n",
       "      <td>-1.306106</td>\n",
       "      <td>1.497862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>-0.241337</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-0.365494</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>1.894774</td>\n",
       "      <td>-1.041079</td>\n",
       "      <td>-1.306106</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>0.531552</td>\n",
       "      <td>1.527650</td>\n",
       "      <td>0.472097</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>-0.979194</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>1.398025</td>\n",
       "      <td>1.497862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.098402</td>\n",
       "      <td>-1.014226</td>\n",
       "      <td>1.527650</td>\n",
       "      <td>0.472097</td>\n",
       "      <td>0.486818</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>1.398025</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.260174</td>\n",
       "      <td>0.531552</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-1.203085</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>-0.979194</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>-0.404729</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>-0.241337</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>1.309688</td>\n",
       "      <td>1.637894</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>-0.404729</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.098402</td>\n",
       "      <td>-1.014226</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>1.309688</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>-0.404729</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>-0.241337</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-0.365494</td>\n",
       "      <td>1.637894</td>\n",
       "      <td>-0.979194</td>\n",
       "      <td>1.212069</td>\n",
       "      <td>1.398025</td>\n",
       "      <td>1.497862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>-1.014226</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>1.309688</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>1.894774</td>\n",
       "      <td>-1.041079</td>\n",
       "      <td>-0.404729</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.098402</td>\n",
       "      <td>2.077330</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>2.147279</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>3.331759</td>\n",
       "      <td>-1.041079</td>\n",
       "      <td>-0.404729</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.260174</td>\n",
       "      <td>-0.241337</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-1.203085</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>0.496648</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.225141</td>\n",
       "      <td>-1.014226</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-0.365494</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>-0.404729</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>2.077330</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-1.203085</td>\n",
       "      <td>1.637894</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>-0.404729</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.098402</td>\n",
       "      <td>-1.014226</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>1.309688</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>-0.979194</td>\n",
       "      <td>1.212069</td>\n",
       "      <td>-1.306106</td>\n",
       "      <td>1.497862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>1.304441</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-1.203085</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>-0.404729</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>-1.014226</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-1.203085</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>1.212069</td>\n",
       "      <td>0.496648</td>\n",
       "      <td>1.497862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.225141</td>\n",
       "      <td>1.304441</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>0.472097</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>-0.979194</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>-1.306106</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.098402</td>\n",
       "      <td>-1.014226</td>\n",
       "      <td>1.527650</td>\n",
       "      <td>-0.365494</td>\n",
       "      <td>1.637894</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>-1.041079</td>\n",
       "      <td>0.496648</td>\n",
       "      <td>1.497862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>2.077330</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>0.472097</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>-1.041079</td>\n",
       "      <td>-0.404729</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>2.077330</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-0.365494</td>\n",
       "      <td>1.637894</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>2.299401</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.098402</td>\n",
       "      <td>-1.014226</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-1.203085</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>-0.979194</td>\n",
       "      <td>-1.041079</td>\n",
       "      <td>0.496648</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>1.304441</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>1.309688</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>-1.041079</td>\n",
       "      <td>0.496648</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>0.531552</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-0.365494</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>-0.979194</td>\n",
       "      <td>1.212069</td>\n",
       "      <td>-0.404729</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>-1.014226</td>\n",
       "      <td>1.527650</td>\n",
       "      <td>0.472097</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>-0.979194</td>\n",
       "      <td>-1.041079</td>\n",
       "      <td>0.496648</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>-1.014226</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>2.147279</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>1.894774</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>-1.306106</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.098402</td>\n",
       "      <td>-0.241337</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>1.309688</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>-0.979194</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>-0.404729</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>1.304441</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>1.309688</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>1.212069</td>\n",
       "      <td>-0.404729</td>\n",
       "      <td>1.497862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>2.077330</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-0.365494</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>-1.306106</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>1.304441</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>1.309688</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>-0.979194</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>0.496648</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>-1.225141</td>\n",
       "      <td>1.304441</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>0.472097</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>0.496648</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>1.098402</td>\n",
       "      <td>-0.241337</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>1.309688</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>-0.979194</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>0.496648</td>\n",
       "      <td>1.497862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>1.098402</td>\n",
       "      <td>-0.241337</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-0.365494</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>-0.979194</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>0.496648</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>1.098402</td>\n",
       "      <td>0.531552</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>1.309688</td>\n",
       "      <td>1.637894</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>0.496648</td>\n",
       "      <td>1.497862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>1.098402</td>\n",
       "      <td>0.531552</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>1.309688</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>1.894774</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>-0.404729</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>2.260174</td>\n",
       "      <td>-0.241337</td>\n",
       "      <td>1.527650</td>\n",
       "      <td>-0.365494</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>-0.979194</td>\n",
       "      <td>-1.041079</td>\n",
       "      <td>-0.404729</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>1.098402</td>\n",
       "      <td>-0.241337</td>\n",
       "      <td>1.527650</td>\n",
       "      <td>-0.365494</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>-0.979194</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>-1.306106</td>\n",
       "      <td>1.497862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>1.098402</td>\n",
       "      <td>-0.241337</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>1.309688</td>\n",
       "      <td>1.637894</td>\n",
       "      <td>-0.979194</td>\n",
       "      <td>-1.041079</td>\n",
       "      <td>-0.404729</td>\n",
       "      <td>1.497862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>1.098402</td>\n",
       "      <td>2.077330</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-0.365494</td>\n",
       "      <td>1.637894</td>\n",
       "      <td>-0.979194</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>-0.404729</td>\n",
       "      <td>1.497862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>-1.225141</td>\n",
       "      <td>-0.241337</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>0.472097</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>0.496648</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>2.260174</td>\n",
       "      <td>0.531552</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-1.203085</td>\n",
       "      <td>1.637894</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>1.212069</td>\n",
       "      <td>0.496648</td>\n",
       "      <td>1.497862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>-1.225141</td>\n",
       "      <td>-1.014226</td>\n",
       "      <td>1.527650</td>\n",
       "      <td>0.472097</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>2.338644</td>\n",
       "      <td>-1.306106</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>1.098402</td>\n",
       "      <td>-1.014226</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-0.365494</td>\n",
       "      <td>0.486818</td>\n",
       "      <td>1.894774</td>\n",
       "      <td>2.338644</td>\n",
       "      <td>-0.404729</td>\n",
       "      <td>1.497862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>2.077330</td>\n",
       "      <td>1.527650</td>\n",
       "      <td>0.472097</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>-1.041079</td>\n",
       "      <td>-1.306106</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>0.531552</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-0.365494</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>1.894774</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>1.398025</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>-0.241337</td>\n",
       "      <td>1.527650</td>\n",
       "      <td>-0.365494</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>-1.306106</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>-1.225141</td>\n",
       "      <td>-0.241337</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>1.309688</td>\n",
       "      <td>1.637894</td>\n",
       "      <td>-0.979194</td>\n",
       "      <td>-1.041079</td>\n",
       "      <td>0.496648</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>-1.014226</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-0.365494</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>-1.041079</td>\n",
       "      <td>-0.404729</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>1.098402</td>\n",
       "      <td>1.304441</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-1.203085</td>\n",
       "      <td>1.637894</td>\n",
       "      <td>1.894774</td>\n",
       "      <td>1.212069</td>\n",
       "      <td>-1.306106</td>\n",
       "      <td>1.497862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>2.077330</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-0.365494</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>-0.979194</td>\n",
       "      <td>1.212069</td>\n",
       "      <td>1.398025</td>\n",
       "      <td>1.497862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>-1.225141</td>\n",
       "      <td>0.531552</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-1.203085</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>-1.041079</td>\n",
       "      <td>-0.404729</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>0.531552</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>2.147279</td>\n",
       "      <td>1.637894</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>-1.041079</td>\n",
       "      <td>-1.306106</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>0.531552</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-1.203085</td>\n",
       "      <td>1.637894</td>\n",
       "      <td>-0.979194</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>-1.306106</td>\n",
       "      <td>1.497862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>-0.241337</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>0.472097</td>\n",
       "      <td>1.637894</td>\n",
       "      <td>-0.979194</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>-0.404729</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>-1.225141</td>\n",
       "      <td>1.304441</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>1.309688</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>-0.979194</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>-0.404729</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>-0.241337</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>1.309688</td>\n",
       "      <td>1.637894</td>\n",
       "      <td>-0.979194</td>\n",
       "      <td>1.212069</td>\n",
       "      <td>-0.404729</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>-1.014226</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-1.203085</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>-0.979194</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>-0.404729</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>-0.063369</td>\n",
       "      <td>-1.014226</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>1.309688</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>-0.979194</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>0.496648</td>\n",
       "      <td>-0.667618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>-1.225141</td>\n",
       "      <td>-0.241337</td>\n",
       "      <td>-0.543601</td>\n",
       "      <td>-0.365494</td>\n",
       "      <td>-0.664257</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>0.496648</td>\n",
       "      <td>1.497862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1265 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           fm1       fm2       fm3       fm4       fm5       fm6       fm7  \\\n",
       "0    -1.225141  2.077330  1.527650 -1.203085 -0.664257  0.457790  0.085495   \n",
       "1    -1.225141  2.077330 -0.543601  1.309688 -0.664257  0.457790  0.085495   \n",
       "2    -1.225141  1.304441 -0.543601 -1.203085 -0.664257  0.457790 -1.041079   \n",
       "3    -0.063369 -0.241337 -0.543601 -0.365494 -0.664257  1.894774 -1.041079   \n",
       "4    -0.063369  0.531552  1.527650  0.472097 -0.664257 -0.979194  0.085495   \n",
       "5     1.098402 -1.014226  1.527650  0.472097  0.486818  0.457790  0.085495   \n",
       "6     2.260174  0.531552 -0.543601 -1.203085 -0.664257 -0.979194  0.085495   \n",
       "7    -0.063369 -0.241337 -0.543601  1.309688  1.637894  0.457790  0.085495   \n",
       "8     1.098402 -1.014226 -0.543601  1.309688 -0.664257  0.457790  0.085495   \n",
       "9    -0.063369 -0.241337 -0.543601 -0.365494  1.637894 -0.979194  1.212069   \n",
       "10   -0.063369 -1.014226 -0.543601  1.309688 -0.664257  1.894774 -1.041079   \n",
       "11    1.098402  2.077330 -0.543601  2.147279 -0.664257  3.331759 -1.041079   \n",
       "12    2.260174 -0.241337 -0.543601 -1.203085 -0.664257  0.457790  0.085495   \n",
       "13   -1.225141 -1.014226 -0.543601 -0.365494 -0.664257  0.457790  0.085495   \n",
       "14   -0.063369  2.077330 -0.543601 -1.203085  1.637894  0.457790  0.085495   \n",
       "15    1.098402 -1.014226 -0.543601  1.309688 -0.664257 -0.979194  1.212069   \n",
       "16   -0.063369  1.304441 -0.543601 -1.203085 -0.664257  0.457790  0.085495   \n",
       "17   -0.063369 -1.014226 -0.543601 -1.203085 -0.664257  0.457790  1.212069   \n",
       "18   -1.225141  1.304441 -0.543601  0.472097 -0.664257 -0.979194  0.085495   \n",
       "19    1.098402 -1.014226  1.527650 -0.365494  1.637894  0.457790 -1.041079   \n",
       "20   -0.063369  2.077330 -0.543601  0.472097 -0.664257  0.457790 -1.041079   \n",
       "21   -0.063369  2.077330 -0.543601 -0.365494  1.637894  0.457790  0.085495   \n",
       "22    1.098402 -1.014226 -0.543601 -1.203085 -0.664257 -0.979194 -1.041079   \n",
       "23   -0.063369  1.304441 -0.543601  1.309688 -0.664257  0.457790 -1.041079   \n",
       "24   -0.063369  0.531552 -0.543601 -0.365494 -0.664257 -0.979194  1.212069   \n",
       "25   -0.063369 -1.014226  1.527650  0.472097 -0.664257 -0.979194 -1.041079   \n",
       "26   -0.063369 -1.014226 -0.543601  2.147279 -0.664257  1.894774  0.085495   \n",
       "27    1.098402 -0.241337 -0.543601  1.309688 -0.664257 -0.979194  0.085495   \n",
       "28   -0.063369  1.304441 -0.543601  1.309688 -0.664257  0.457790  1.212069   \n",
       "29   -0.063369  2.077330 -0.543601 -0.365494 -0.664257  0.457790  0.085495   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1235 -0.063369  1.304441 -0.543601  1.309688 -0.664257 -0.979194  0.085495   \n",
       "1236 -1.225141  1.304441 -0.543601  0.472097 -0.664257  0.457790  0.085495   \n",
       "1237  1.098402 -0.241337 -0.543601  1.309688 -0.664257 -0.979194  0.085495   \n",
       "1238  1.098402 -0.241337 -0.543601 -0.365494 -0.664257 -0.979194  0.085495   \n",
       "1239  1.098402  0.531552 -0.543601  1.309688  1.637894  0.457790  0.085495   \n",
       "1240  1.098402  0.531552 -0.543601  1.309688 -0.664257  1.894774  0.085495   \n",
       "1241  2.260174 -0.241337  1.527650 -0.365494 -0.664257 -0.979194 -1.041079   \n",
       "1242  1.098402 -0.241337  1.527650 -0.365494 -0.664257 -0.979194  0.085495   \n",
       "1243  1.098402 -0.241337 -0.543601  1.309688  1.637894 -0.979194 -1.041079   \n",
       "1244  1.098402  2.077330 -0.543601 -0.365494  1.637894 -0.979194  0.085495   \n",
       "1245 -1.225141 -0.241337 -0.543601  0.472097 -0.664257  0.457790  0.085495   \n",
       "1246  2.260174  0.531552 -0.543601 -1.203085  1.637894  0.457790  1.212069   \n",
       "1247 -1.225141 -1.014226  1.527650  0.472097 -0.664257  0.457790  2.338644   \n",
       "1248  1.098402 -1.014226 -0.543601 -0.365494  0.486818  1.894774  2.338644   \n",
       "1249 -0.063369  2.077330  1.527650  0.472097 -0.664257  0.457790 -1.041079   \n",
       "1250 -0.063369  0.531552 -0.543601 -0.365494 -0.664257  1.894774  0.085495   \n",
       "1251 -0.063369 -0.241337  1.527650 -0.365494 -0.664257  0.457790  0.085495   \n",
       "1252 -1.225141 -0.241337 -0.543601  1.309688  1.637894 -0.979194 -1.041079   \n",
       "1253 -0.063369 -1.014226 -0.543601 -0.365494 -0.664257  0.457790 -1.041079   \n",
       "1254  1.098402  1.304441 -0.543601 -1.203085  1.637894  1.894774  1.212069   \n",
       "1255 -0.063369  2.077330 -0.543601 -0.365494 -0.664257 -0.979194  1.212069   \n",
       "1256 -1.225141  0.531552 -0.543601 -1.203085 -0.664257  0.457790 -1.041079   \n",
       "1257 -0.063369  0.531552 -0.543601  2.147279  1.637894  0.457790 -1.041079   \n",
       "1258 -0.063369  0.531552 -0.543601 -1.203085  1.637894 -0.979194  0.085495   \n",
       "1259 -0.063369 -0.241337 -0.543601  0.472097  1.637894 -0.979194  0.085495   \n",
       "1260 -1.225141  1.304441 -0.543601  1.309688 -0.664257 -0.979194  0.085495   \n",
       "1261 -0.063369 -0.241337 -0.543601  1.309688  1.637894 -0.979194  1.212069   \n",
       "1262 -0.063369 -1.014226 -0.543601 -1.203085 -0.664257 -0.979194  0.085495   \n",
       "1263 -0.063369 -1.014226 -0.543601  1.309688 -0.664257 -0.979194  0.085495   \n",
       "1264 -1.225141 -0.241337 -0.543601 -0.365494 -0.664257  0.457790  0.085495   \n",
       "\n",
       "           fm8       fm9  \n",
       "0    -1.306106 -0.667618  \n",
       "1     0.496648 -0.667618  \n",
       "2    -1.306106  1.497862  \n",
       "3    -1.306106 -0.667618  \n",
       "4     1.398025  1.497862  \n",
       "5     1.398025 -0.667618  \n",
       "6    -0.404729 -0.667618  \n",
       "7    -0.404729 -0.667618  \n",
       "8    -0.404729 -0.667618  \n",
       "9     1.398025  1.497862  \n",
       "10   -0.404729 -0.667618  \n",
       "11   -0.404729 -0.667618  \n",
       "12    0.496648 -0.667618  \n",
       "13   -0.404729 -0.667618  \n",
       "14   -0.404729 -0.667618  \n",
       "15   -1.306106  1.497862  \n",
       "16   -0.404729 -0.667618  \n",
       "17    0.496648  1.497862  \n",
       "18   -1.306106 -0.667618  \n",
       "19    0.496648  1.497862  \n",
       "20   -0.404729 -0.667618  \n",
       "21    2.299401 -0.667618  \n",
       "22    0.496648 -0.667618  \n",
       "23    0.496648 -0.667618  \n",
       "24   -0.404729 -0.667618  \n",
       "25    0.496648 -0.667618  \n",
       "26   -1.306106 -0.667618  \n",
       "27   -0.404729 -0.667618  \n",
       "28   -0.404729  1.497862  \n",
       "29   -1.306106 -0.667618  \n",
       "...        ...       ...  \n",
       "1235  0.496648 -0.667618  \n",
       "1236  0.496648 -0.667618  \n",
       "1237  0.496648  1.497862  \n",
       "1238  0.496648 -0.667618  \n",
       "1239  0.496648  1.497862  \n",
       "1240 -0.404729 -0.667618  \n",
       "1241 -0.404729 -0.667618  \n",
       "1242 -1.306106  1.497862  \n",
       "1243 -0.404729  1.497862  \n",
       "1244 -0.404729  1.497862  \n",
       "1245  0.496648 -0.667618  \n",
       "1246  0.496648  1.497862  \n",
       "1247 -1.306106 -0.667618  \n",
       "1248 -0.404729  1.497862  \n",
       "1249 -1.306106 -0.667618  \n",
       "1250  1.398025 -0.667618  \n",
       "1251 -1.306106 -0.667618  \n",
       "1252  0.496648 -0.667618  \n",
       "1253 -0.404729 -0.667618  \n",
       "1254 -1.306106  1.497862  \n",
       "1255  1.398025  1.497862  \n",
       "1256 -0.404729 -0.667618  \n",
       "1257 -1.306106 -0.667618  \n",
       "1258 -1.306106  1.497862  \n",
       "1259 -0.404729 -0.667618  \n",
       "1260 -0.404729 -0.667618  \n",
       "1261 -0.404729 -0.667618  \n",
       "1262 -0.404729 -0.667618  \n",
       "1263  0.496648 -0.667618  \n",
       "1264  0.496648  1.497862  \n",
       "\n",
       "[1265 rows x 9 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train)\n",
    "train_norm = pd.DataFrame(scaler.transform(train),columns=train.columns)\n",
    "train_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "covarMat = covar(train_norm,M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\" Getting the covar over the training data based on number of basics we have implemented\")\n",
    "#covarMat = covar(train,M)\n",
    "phiMat = genPhi(train,covarMat,M,mu)\n",
    "valMat = genPhi(val,covarMat,M,mu)\n",
    "testMat = genPhi(test,covarMat,M,mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.3887621 ],\n",
       "        [0.01547099],\n",
       "        [0.94718274],\n",
       "        [0.33959462],\n",
       "        [0.78467214]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1994)\n",
    "if(mode == 2):\n",
    "    if(subMode == 'a'):\n",
    "        prev_weight = np.zeros((M,1))\n",
    "else:\n",
    "    prev_weight = np.matrix(np.random.rand(M,1))\n",
    "prev_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchUpdateWeights(weights,phiMat,train_lab,alpha,lam): \n",
    "    midT = np.dot(phiMat,weights)\n",
    "    deltaL = -(np.subtract(train_lab,midT))\n",
    "    deltaD = np.dot(np.transpose(deltaL),phiMat)\n",
    "    deltaE = np.transpose(deltaD) + np.dot(lam,prev_weight)\n",
    "\n",
    "    delta = np.dot(-alpha,deltaE)\n",
    "    new_weight = weights + delta\n",
    "    return new_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alpha' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-948201d2f060>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatchUpdateWeights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mphiMat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_lab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'alpha' is not defined"
     ]
    }
   ],
   "source": [
    "batchUpdateWeights(prev_weight,phiMat,pd.DataFrame(train_lab),alpha,lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in add\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in subtract\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.001\n",
    "lam = 0.005\n",
    "if(mode == 2):\n",
    "    if(subMode == 'a'):\n",
    "        nprev_weight = np.zeros((M,1))\n",
    "else:\n",
    "    nprev_weight = np.matrix(np.random.rand(M,1))\n",
    "    \n",
    "while((np.subtract(prev_weight,prev_weight) == np.zeros((M,1))).all()):\n",
    "    prev_weight = nprev_weight\n",
    "    nprev_weight = batchUpdateWeights(prev_weight,phiMat,pd.DataFrame(train_lab),alpha,lam) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('53.164556962025316,0.6031150545786021', 0.6031150545786021)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAL_TEST_OUT  = GetValTest(valMat,prev_weight) \n",
    "GetErms(np.transpose(VAL_TEST_OUT),np.asarray(val_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\n",
      "\n",
      "Epoch: 1\n",
      "49.9604743083004,0.6505932191811619\n",
      "50.0,0.6503544573352176\n",
      "Epoch: 2\n",
      "49.9604743083004,0.608993404352446\n",
      "50.0,0.6087903866909163\n",
      "Epoch: 3\n",
      "49.9604743083004,0.5788938527848272\n",
      "50.0,0.5787216966492195\n",
      "Epoch: 4\n",
      "49.9604743083004,0.557312134193156\n",
      "50.0,0.55716615732975\n",
      "Epoch: 5\n",
      "49.9604743083004,0.5419240617881126\n",
      "50.0,0.5417999556813732\n",
      "Epoch: 6\n",
      "49.9604743083004,0.5309764041405202\n",
      "50.0,0.5308703534428623\n",
      "Epoch: 7\n",
      "49.9604743083004,0.523181553377595\n",
      "50.0,0.5230902825078267\n",
      "Epoch: 8\n",
      "49.9604743083004,0.5176128604617015\n",
      "50.0,0.5175336209826948\n",
      "Epoch: 9\n",
      "49.9604743083004,0.5136128799254118\n",
      "50.0,0.5135434020911692\n",
      "Epoch: 10\n",
      "49.9604743083004,0.510719384271971\n",
      "50.0,0.5106578130333984\n",
      "Epoch: 11\n",
      "49.9604743083004,0.5086089831847397\n",
      "50.0,0.5085538120188332\n",
      "Epoch: 12\n",
      "49.9604743083004,0.5070557679556504\n",
      "50.0,0.5070057776932309\n",
      "Epoch: 13\n",
      "49.9604743083004,0.5059017437719936\n",
      "50.0,0.5058559494065998\n",
      "Epoch: 14\n",
      "49.9604743083004,0.5050360433254983\n",
      "50.0,0.5049936493868395\n",
      "Epoch: 15\n",
      "49.9604743083004,0.5043804693745391\n",
      "50.0,0.5043408332724573\n",
      "Epoch: 16\n",
      "49.9604743083004,0.503879502323782\n",
      "50.0,0.5038421046074524\n",
      "Epoch: 17\n",
      "49.9604743083004,0.5034934148618879\n",
      "50.0,0.5034578352517116\n",
      "Epoch: 18\n",
      "49.9604743083004,0.5031935302680614\n",
      "50.0,0.5031594284019373\n",
      "Epoch: 19\n",
      "49.9604743083004,0.5029589524385817\n",
      "50.0,0.5029260524212766\n",
      "Epoch: 20\n",
      "49.9604743083004,0.5027743040117829\n",
      "50.0,0.5027423820127102\n",
      "Epoch: 21\n",
      "49.9604743083004,0.5026281548461838\n",
      "50.0,0.502597029133908\n",
      "Epoch: 22\n",
      "49.9604743083004,0.5025119239113347\n",
      "50.0,0.5024814468348365\n",
      "Epoch: 23\n",
      "49.9604743083004,0.5024191067247544\n",
      "50.0,0.502389158251234\n",
      "Epoch: 24\n",
      "49.9604743083004,0.5023447275530761\n",
      "50.0,0.502315210052189\n",
      "Epoch: 25\n",
      "49.9604743083004,0.5022849475971275\n",
      "50.0,0.502255781625179\n",
      "Epoch: 26\n",
      "49.9604743083004,0.50223678210373\n",
      "50.0,0.5022079029916807\n",
      "Epoch: 27\n",
      "49.9604743083004,0.5021978940941809\n",
      "50.0,0.5021692491830043\n",
      "Epoch: 28\n",
      "49.9604743083004,0.5021664424227172\n",
      "50.0,0.5021379888210511\n",
      "Epoch: 29\n",
      "49.9604743083004,0.502140968706008\n",
      "50.0,0.502112671469862\n",
      "Epoch: 30\n",
      "49.9604743083004,0.5021203123301261\n",
      "50.0,0.5020921429841267\n",
      "Epoch: 31\n",
      "49.9604743083004,0.502103545942352\n",
      "50.0,0.5020754812777055\n",
      "Epoch: 32\n",
      "49.9604743083004,0.5020899260421301\n",
      "50.0,0.5020619471390209\n",
      "Epoch: 33\n",
      "49.9604743083004,0.5020788548161914\n",
      "50.0,0.5020509462483699\n",
      "Epoch: 34\n",
      "49.9604743083004,0.5020698504316735\n",
      "50.0,0.5020419996190502\n",
      "Epoch: 35\n",
      "49.9604743083004,0.502062523753169\n",
      "50.0,0.502034720434722\n",
      "Epoch: 36\n",
      "49.9604743083004,0.502056559983344\n",
      "50.0,0.5020287957878747\n",
      "Epoch: 37\n",
      "49.9604743083004,0.5020517041090058\n",
      "50.0,0.5020239722055078\n",
      "Epoch: 38\n",
      "49.9604743083004,0.5020477493109239\n",
      "50.0,0.502020044123756\n",
      "Epoch: 39\n",
      "49.9604743083004,0.5020445276977036\n",
      "50.0,0.5020168446745199\n",
      "Epoch: 40\n",
      "49.9604743083004,0.5020419028730528\n",
      "50.0,0.502014238295701\n",
      "Epoch: 41\n",
      "49.9604743083004,0.5020397639570049\n",
      "50.0,0.5020121147874183\n",
      "Epoch: 42\n",
      "49.9604743083004,0.5020380207653917\n",
      "50.0,0.5020103845199934\n",
      "Epoch: 43\n",
      "49.9604743083004,0.5020365999155891\n",
      "50.0,0.5020089745629243\n",
      "Epoch: 44\n",
      "49.9604743083004,0.5020354416754366\n",
      "50.0,0.5020078255527339\n",
      "Epoch: 45\n",
      "49.9604743083004,0.5020344974100817\n",
      "50.0,0.5020068891552402\n",
      "Epoch: 46\n",
      "49.9604743083004,0.5020337275109964\n",
      "50.0,0.5020061260071429\n",
      "Epoch: 47\n",
      "49.9604743083004,0.5020330997145689\n",
      "50.0,0.5020055040448617\n",
      "Epoch: 48\n",
      "49.9604743083004,0.5020325877359617\n",
      "50.0,0.5020049971467468\n",
      "Epoch: 49\n",
      "49.9604743083004,0.5020321701584411\n",
      "50.0,0.5020045840292161\n",
      "Epoch: 50\n",
      "49.9604743083004,0.5020318295299517\n",
      "50.0,0.5020042473488744\n",
      "Epoch: 51\n",
      "49.9604743083004,0.5020315516279477\n",
      "50.0,0.5020039729718734\n",
      "Epoch: 52\n",
      "49.9604743083004,0.5020313248609569\n",
      "50.0,0.5020037493791594\n",
      "Epoch: 53\n",
      "49.9604743083004,0.5020311397813031\n",
      "50.0,0.5020035671822023\n",
      "Epoch: 54\n",
      "49.9604743083004,0.5020309886882502\n",
      "50.0,0.5020034187285918\n",
      "Epoch: 55\n",
      "49.9604743083004,0.5020308653047348\n",
      "50.0,0.5020032977807642\n",
      "Epoch: 56\n",
      "49.9604743083004,0.5020307645139928\n",
      "50.0,0.5020031992542607\n",
      "Epoch: 57\n",
      "49.9604743083004,0.502030682144966\n",
      "50.0,0.5020031190044603\n",
      "Epoch: 58\n",
      "49.9604743083004,0.502030614797431\n",
      "50.0,0.5020030536527884\n",
      "Epoch: 59\n",
      "49.9604743083004,0.5020305596994836\n",
      "50.0,0.5020030004450904\n",
      "Epoch: 60\n",
      "49.9604743083004,0.502030514591394\n",
      "50.0,0.5020029571361987\n",
      "Epoch: 61\n",
      "49.9604743083004,0.5020304776309368\n",
      "50.0,0.5020029218958539\n",
      "Epoch: 62\n",
      "49.9604743083004,0.5020304473162293\n",
      "50.0,0.5020028932320201\n",
      "Epoch: 63\n",
      "49.9604743083004,0.5020304224228346\n",
      "50.0,0.5020028699283765\n",
      "Epoch: 64\n",
      "49.9604743083004,0.5020304019524914\n",
      "50.0,0.5020028509933672\n",
      "Epoch: 65\n",
      "49.9604743083004,0.5020303850913198\n",
      "50.0,0.5020028356186659\n",
      "Epoch: 66\n",
      "49.9604743083004,0.5020303711757547\n",
      "50.0,0.5020028231453175\n",
      "Epoch: 67\n",
      "49.9604743083004,0.5020303596647687\n",
      "50.0,0.5020028130361386\n",
      "Epoch: 68\n",
      "49.9604743083004,0.5020303501172372\n",
      "50.0,0.5020028048532164\n",
      "Epoch: 69\n",
      "49.9604743083004,0.5020303421734739\n",
      "50.0,0.5020027982395675\n",
      "Epoch: 70\n",
      "49.9604743083004,0.5020303355401915\n",
      "50.0,0.5020027929041831\n",
      "Epoch: 71\n",
      "49.9604743083004,0.502030329978232\n",
      "50.0,0.5020027886098408\n",
      "Epoch: 72\n",
      "49.9604743083004,0.5020303252925651\n",
      "50.0,0.5020027851631654\n",
      "Epoch: 73\n",
      "49.9604743083004,0.5020303213241415\n",
      "50.0,0.5020027824065275\n",
      "Epoch: 74\n",
      "49.9604743083004,0.5020303179432415\n",
      "50.0,0.5020027802114402\n",
      "Epoch: 75\n",
      "49.9604743083004,0.5020303150440569\n",
      "50.0,0.5020027784731729\n",
      "Epoch: 76\n",
      "49.9604743083004,0.5020303125402799\n",
      "50.0,0.5020027771063629\n",
      "Epoch: 77\n",
      "49.9604743083004,0.5020303103614953\n",
      "50.0,0.5020027760414364\n",
      "Epoch: 78\n",
      "49.9604743083004,0.5020303084502475\n",
      "50.0,0.5020027752216917\n",
      "Epoch: 79\n",
      "49.9604743083004,0.5020303067596484\n",
      "50.0,0.5020027746009199\n",
      "Epoch: 80\n",
      "49.9604743083004,0.5020303052514238\n",
      "50.0,0.5020027741414659\n",
      "Epoch: 81\n",
      "49.9604743083004,0.5020303038943241\n",
      "50.0,0.5020027738126482\n",
      "Epoch: 82\n",
      "49.9604743083004,0.5020303026628272\n",
      "50.0,0.5020027735894717\n",
      "Epoch: 83\n",
      "49.9604743083004,0.5020303015360806\n",
      "50.0,0.5020027734515738\n",
      "Epoch: 84\n",
      "49.9604743083004,0.502030300497041\n",
      "50.0,0.5020027733823701\n",
      "Epoch: 85\n",
      "49.9604743083004,0.5020302995317696\n",
      "50.0,0.5020027733683561\n",
      "Epoch: 86\n",
      "49.9604743083004,0.5020302986288596\n",
      "50.0,0.5020027733985375\n",
      "Epoch: 87\n",
      "49.9604743083004,0.5020302977789723\n",
      "50.0,0.5020027734639658\n",
      "Epoch: 88\n",
      "49.9604743083004,0.5020302969744507\n",
      "50.0,0.502002773557361\n",
      "Epoch: 89\n",
      "49.9604743083004,0.5020302962090126\n",
      "50.0,0.5020027736728024\n",
      "Epoch: 90\n",
      "49.9604743083004,0.5020302954774984\n",
      "50.0,0.502002773805477\n",
      "Epoch: 91\n",
      "49.9604743083004,0.5020302947756621\n",
      "50.0,0.5020027739514753\n",
      "Epoch: 92\n",
      "49.9604743083004,0.502030294100004\n",
      "50.0,0.5020027741076233\n",
      "Epoch: 93\n",
      "49.9604743083004,0.5020302934476331\n",
      "50.0,0.5020027742713478\n",
      "Epoch: 94\n",
      "49.9604743083004,0.5020302928161562\n",
      "50.0,0.5020027744405627\n",
      "Epoch: 95\n",
      "49.9604743083004,0.5020302922035883\n",
      "50.0,0.5020027746135812\n",
      "Epoch: 96\n",
      "49.9604743083004,0.5020302916082732\n",
      "50.0,0.5020027747890408\n",
      "Epoch: 97\n",
      "49.9604743083004,0.5020302910288279\n",
      "50.0,0.5020027749658427\n",
      "Epoch: 98\n",
      "49.9604743083004,0.5020302904640893\n",
      "50.0,0.5020027751431033\n",
      "Epoch: 99\n",
      "49.9604743083004,0.5020302899130785\n",
      "50.0,0.5020027753201146\n",
      "Epoch: 100\n",
      "49.9604743083004,0.5020302893749615\n",
      "50.0,0.502002775496311\n",
      "Epoch: 101\n",
      "49.9604743083004,0.5020302888490284\n",
      "50.0,0.5020027756712425\n",
      "Epoch: 102\n",
      "49.9604743083004,0.5020302883346692\n",
      "50.0,0.5020027758445543\n",
      "Epoch: 103\n",
      "49.9604743083004,0.5020302878313554\n",
      "50.0,0.5020027760159673\n",
      "Epoch: 104\n",
      "49.9604743083004,0.5020302873386249\n",
      "50.0,0.5020027761852657\n",
      "Epoch: 105\n",
      "49.9604743083004,0.5020302868560724\n",
      "50.0,0.5020027763522835\n",
      "Epoch: 106\n",
      "49.9604743083004,0.5020302863833378\n",
      "50.0,0.5020027765168968\n",
      "Epoch: 107\n",
      "49.9604743083004,0.5020302859200989\n",
      "50.0,0.502002776679014\n",
      "Epoch: 108\n",
      "49.9604743083004,0.5020302854660659\n",
      "50.0,0.5020027768385705\n",
      "Epoch: 109\n",
      "49.9604743083004,0.5020302850209739\n",
      "50.0,0.5020027769955241\n",
      "Epoch: 110\n",
      "49.9604743083004,0.5020302845845807\n",
      "50.0,0.5020027771498495\n",
      "Epoch: 111\n",
      "49.9604743083004,0.5020302841566604\n",
      "50.0,0.5020027773015362\n",
      "Epoch: 112\n",
      "49.9604743083004,0.5020302837370066\n",
      "50.0,0.5020027774505847\n",
      "Epoch: 113\n",
      "49.9604743083004,0.5020302833254217\n",
      "50.0,0.5020027775970041\n",
      "Epoch: 114\n",
      "49.9604743083004,0.5020302829217214\n",
      "50.0,0.5020027777408119\n",
      "Epoch: 115\n",
      "49.9604743083004,0.5020302825257312\n",
      "50.0,0.5020027778820301\n",
      "Epoch: 116\n",
      "49.9604743083004,0.5020302821372846\n",
      "50.0,0.5020027780206858\n",
      "Epoch: 117\n",
      "49.9604743083004,0.5020302817562206\n",
      "50.0,0.5020027781568097\n",
      "Epoch: 118\n",
      "49.9604743083004,0.5020302813823869\n",
      "50.0,0.5020027782904349\n",
      "Epoch: 119\n",
      "49.9604743083004,0.5020302810156347\n",
      "50.0,0.5020027784215967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 120\n",
      "49.9604743083004,0.5020302806558224\n",
      "50.0,0.5020027785503319\n",
      "Epoch: 121\n",
      "49.9604743083004,0.5020302803028107\n",
      "50.0,0.5020027786766783\n",
      "Epoch: 122\n",
      "49.9604743083004,0.5020302799564662\n",
      "50.0,0.5020027788006742\n",
      "Epoch: 123\n",
      "49.9604743083004,0.502030279616657\n",
      "50.0,0.5020027789223592\n",
      "Epoch: 124\n",
      "49.9604743083004,0.5020302792832569\n",
      "50.0,0.5020027790417724\n",
      "Epoch: 125\n",
      "49.9604743083004,0.5020302789561418\n",
      "50.0,0.502002779158953\n",
      "Epoch: 126\n",
      "49.9604743083004,0.5020302786351903\n",
      "50.0,0.5020027792739402\n",
      "Epoch: 127\n",
      "49.9604743083004,0.5020302783202846\n",
      "50.0,0.5020027793867726\n",
      "Epoch: 128\n",
      "49.9604743083004,0.5020302780113084\n",
      "50.0,0.5020027794974895\n",
      "Epoch: 129\n",
      "49.9604743083004,0.5020302777081496\n",
      "50.0,0.5020027796061292\n",
      "Epoch: 130\n",
      "49.9604743083004,0.5020302774106968\n",
      "50.0,0.502002779712729\n",
      "Epoch: 131\n",
      "49.9604743083004,0.5020302771188421\n",
      "50.0,0.5020027798173267\n",
      "Epoch: 132\n",
      "49.9604743083004,0.502030276832479\n",
      "50.0,0.5020027799199591\n",
      "Epoch: 133\n",
      "49.9604743083004,0.5020302765515045\n",
      "50.0,0.5020027800206623\n",
      "Epoch: 134\n",
      "49.9604743083004,0.5020302762758156\n",
      "50.0,0.5020027801194724\n",
      "Epoch: 135\n",
      "49.9604743083004,0.5020302760053136\n",
      "50.0,0.5020027802164245\n",
      "Epoch: 136\n",
      "49.9604743083004,0.5020302757398987\n",
      "50.0,0.5020027803115529\n",
      "Epoch: 137\n",
      "49.9604743083004,0.5020302754794768\n",
      "50.0,0.502002780404892\n",
      "Epoch: 138\n",
      "49.9604743083004,0.5020302752239534\n",
      "50.0,0.502002780496475\n",
      "Epoch: 139\n",
      "49.9604743083004,0.5020302749732352\n",
      "50.0,0.5020027805863352\n",
      "Epoch: 140\n",
      "49.9604743083004,0.502030274727232\n",
      "50.0,0.502002780674504\n",
      "Epoch: 141\n",
      "49.9604743083004,0.5020302744858562\n",
      "50.0,0.5020027807610138\n",
      "Epoch: 142\n",
      "49.9604743083004,0.50203027424902\n",
      "50.0,0.5020027808458956\n",
      "Epoch: 143\n",
      "49.9604743083004,0.502030274016637\n",
      "50.0,0.5020027809291797\n",
      "Epoch: 144\n",
      "49.9604743083004,0.5020302737886246\n",
      "50.0,0.5020027810108967\n",
      "Epoch: 145\n",
      "49.9604743083004,0.5020302735649006\n",
      "50.0,0.5020027810910754\n",
      "Epoch: 146\n",
      "49.9604743083004,0.5020302733453834\n",
      "50.0,0.5020027811697452\n",
      "Epoch: 147\n",
      "49.9604743083004,0.502030273129994\n",
      "50.0,0.502002781246934\n",
      "Epoch: 148\n",
      "49.9604743083004,0.5020302729186551\n",
      "50.0,0.5020027813226698\n",
      "Epoch: 149\n",
      "49.9604743083004,0.5020302727112904\n",
      "50.0,0.5020027813969801\n",
      "Epoch: 150\n",
      "49.9604743083004,0.5020302725078253\n",
      "50.0,0.5020027814698917\n",
      "Epoch: 151\n",
      "49.9604743083004,0.502030272308186\n",
      "50.0,0.5020027815414306\n",
      "Epoch: 152\n",
      "49.9604743083004,0.5020302721123012\n",
      "50.0,0.5020027816116229\n",
      "Epoch: 153\n",
      "49.9604743083004,0.5020302719201002\n",
      "50.0,0.5020027816804938\n",
      "Epoch: 154\n",
      "49.9604743083004,0.5020302717315133\n",
      "50.0,0.5020027817480687\n",
      "Epoch: 155\n",
      "49.9604743083004,0.5020302715464721\n",
      "50.0,0.502002781814371\n",
      "Epoch: 156\n",
      "49.9604743083004,0.5020302713649103\n",
      "50.0,0.5020027818794254\n",
      "Epoch: 157\n",
      "49.9604743083004,0.5020302711867638\n",
      "50.0,0.502002781943255\n",
      "Epoch: 158\n",
      "49.9604743083004,0.5020302710119662\n",
      "50.0,0.5020027820058836\n",
      "Epoch: 159\n",
      "49.9604743083004,0.5020302708404567\n",
      "50.0,0.5020027820673324\n",
      "Epoch: 160\n",
      "49.9604743083004,0.5020302706721718\n",
      "50.0,0.5020027821276246\n",
      "Epoch: 161\n",
      "49.9604743083004,0.5020302705070513\n",
      "50.0,0.502002782186782\n",
      "Epoch: 162\n",
      "49.9604743083004,0.5020302703450357\n",
      "50.0,0.5020027822448255\n",
      "Epoch: 163\n",
      "49.9604743083004,0.5020302701860669\n",
      "50.0,0.5020027823017769\n",
      "Epoch: 164\n",
      "49.9604743083004,0.5020302700300874\n",
      "50.0,0.5020027823576555\n",
      "Epoch: 165\n",
      "49.9604743083004,0.5020302698770409\n",
      "50.0,0.5020027824124826\n",
      "Epoch: 166\n",
      "49.9604743083004,0.5020302697268724\n",
      "50.0,0.5020027824662773\n",
      "Epoch: 167\n",
      "49.9604743083004,0.502030269579528\n",
      "50.0,0.5020027825190595\n",
      "Epoch: 168\n",
      "49.9604743083004,0.5020302694349534\n",
      "50.0,0.5020027825708481\n",
      "Epoch: 169\n",
      "49.9604743083004,0.502030269293098\n",
      "50.0,0.5020027826216616\n",
      "Epoch: 170\n",
      "49.9604743083004,0.5020302691539109\n",
      "50.0,0.5020027826715185\n",
      "Epoch: 171\n",
      "49.9604743083004,0.50203026901734\n",
      "50.0,0.5020027827204367\n",
      "Epoch: 172\n",
      "49.9604743083004,0.5020302688833376\n",
      "50.0,0.5020027827684342\n",
      "Epoch: 173\n",
      "49.9604743083004,0.5020302687518544\n",
      "50.0,0.5020027828155282\n",
      "Epoch: 174\n",
      "49.9604743083004,0.5020302686228442\n",
      "50.0,0.5020027828617355\n",
      "Epoch: 175\n",
      "49.9604743083004,0.5020302684962599\n",
      "50.0,0.502002782907073\n",
      "Epoch: 176\n",
      "49.9604743083004,0.5020302683720566\n",
      "50.0,0.5020027829515568\n",
      "Epoch: 177\n",
      "49.9604743083004,0.5020302682501878\n",
      "50.0,0.5020027829952033\n",
      "Epoch: 178\n",
      "49.9604743083004,0.5020302681306108\n",
      "50.0,0.5020027830380283\n",
      "Epoch: 179\n",
      "49.9604743083004,0.502030268013283\n",
      "50.0,0.5020027830800468\n",
      "Epoch: 180\n",
      "49.9604743083004,0.5020302678981609\n",
      "50.0,0.5020027831212744\n",
      "Epoch: 181\n",
      "49.9604743083004,0.5020302677852033\n",
      "50.0,0.5020027831617256\n",
      "Epoch: 182\n",
      "49.9604743083004,0.5020302676743708\n",
      "50.0,0.5020027832014158\n",
      "Epoch: 183\n",
      "49.9604743083004,0.5020302675656219\n",
      "50.0,0.5020027832403583\n",
      "Epoch: 184\n",
      "49.9604743083004,0.5020302674589171\n",
      "50.0,0.5020027832785678\n",
      "Epoch: 185\n",
      "49.9604743083004,0.5020302673542197\n",
      "50.0,0.5020027833160582\n",
      "Epoch: 186\n",
      "49.9604743083004,0.5020302672514906\n",
      "50.0,0.5020027833528428\n",
      "Epoch: 187\n",
      "49.9604743083004,0.5020302671506944\n",
      "50.0,0.502002783388935\n",
      "Epoch: 188\n",
      "49.9604743083004,0.5020302670517927\n",
      "50.0,0.5020027834243473\n",
      "Epoch: 189\n",
      "49.9604743083004,0.5020302669547504\n",
      "50.0,0.502002783459093\n",
      "Epoch: 190\n",
      "49.9604743083004,0.5020302668595331\n",
      "50.0,0.502002783493185\n",
      "Epoch: 191\n",
      "49.9604743083004,0.5020302667661065\n",
      "50.0,0.5020027835266347\n",
      "Epoch: 192\n",
      "49.9604743083004,0.5020302666744372\n",
      "50.0,0.5020027835594552\n",
      "Epoch: 193\n",
      "49.9604743083004,0.5020302665844908\n",
      "50.0,0.5020027835916576\n",
      "Epoch: 194\n",
      "49.9604743083004,0.5020302664962358\n",
      "50.0,0.5020027836232536\n",
      "Epoch: 195\n",
      "49.9604743083004,0.5020302664096409\n",
      "50.0,0.5020027836542548\n",
      "Epoch: 196\n",
      "49.9604743083004,0.5020302663246741\n",
      "50.0,0.5020027836846724\n",
      "Epoch: 197\n",
      "49.9604743083004,0.502030266241305\n",
      "50.0,0.5020027837145176\n",
      "Epoch: 198\n",
      "49.9604743083004,0.5020302661595037\n",
      "50.0,0.5020027837438008\n",
      "Epoch: 199\n",
      "49.9604743083004,0.5020302660792407\n",
      "50.0,0.5020027837725326\n",
      "Epoch: 200\n",
      "49.9604743083004,0.5020302660004871\n",
      "50.0,0.5020027838007237\n",
      "Epoch: 201\n",
      "49.9604743083004,0.5020302659232135\n",
      "50.0,0.5020027838283839\n",
      "Epoch: 202\n",
      "49.9604743083004,0.5020302658473939\n",
      "50.0,0.5020027838555233\n",
      "Epoch: 203\n",
      "49.9604743083004,0.5020302657729996\n",
      "50.0,0.502002783882152\n",
      "Epoch: 204\n",
      "49.9604743083004,0.5020302657000044\n",
      "50.0,0.5020027839082795\n",
      "Epoch: 205\n",
      "49.9604743083004,0.5020302656283815\n",
      "50.0,0.5020027839339151\n",
      "Epoch: 206\n",
      "49.9604743083004,0.5020302655581055\n",
      "50.0,0.5020027839590677\n",
      "Epoch: 207\n",
      "49.9604743083004,0.5020302654891518\n",
      "50.0,0.5020027839837469\n",
      "Epoch: 208\n",
      "49.9604743083004,0.5020302654214932\n",
      "50.0,0.5020027840079615\n",
      "Epoch: 209\n",
      "49.9604743083004,0.5020302653551082\n",
      "50.0,0.5020027840317203\n",
      "Epoch: 210\n",
      "49.9604743083004,0.5020302652899711\n",
      "50.0,0.5020027840550318\n",
      "Epoch: 211\n",
      "49.9604743083004,0.5020302652260585\n",
      "50.0,0.5020027840779047\n",
      "Epoch: 212\n",
      "49.9604743083004,0.5020302651633471\n",
      "50.0,0.5020027841003466\n",
      "Epoch: 213\n",
      "49.9604743083004,0.5020302651018165\n",
      "50.0,0.5020027841223662\n",
      "Epoch: 214\n",
      "49.9604743083004,0.5020302650414421\n",
      "50.0,0.5020027841439713\n",
      "Epoch: 215\n",
      "49.9604743083004,0.5020302649822035\n",
      "50.0,0.5020027841651696\n",
      "Epoch: 216\n",
      "49.9604743083004,0.5020302649240779\n",
      "50.0,0.5020027841859687\n",
      "Epoch: 217\n",
      "49.9604743083004,0.502030264867046\n",
      "50.0,0.5020027842063766\n",
      "Epoch: 218\n",
      "49.9604743083004,0.5020302648110864\n",
      "50.0,0.5020027842263999\n",
      "Epoch: 219\n",
      "49.9604743083004,0.5020302647561793\n",
      "50.0,0.5020027842460462\n",
      "Epoch: 220\n",
      "49.9604743083004,0.5020302647023043\n",
      "50.0,0.5020027842653231\n",
      "Epoch: 221\n",
      "49.9604743083004,0.5020302646494419\n",
      "50.0,0.5020027842842366\n",
      "Epoch: 222\n",
      "49.9604743083004,0.5020302645975746\n",
      "50.0,0.5020027843027941\n",
      "Epoch: 223\n",
      "49.9604743083004,0.5020302645466821\n",
      "50.0,0.5020027843210024\n",
      "Epoch: 224\n",
      "49.9604743083004,0.5020302644967463\n",
      "50.0,0.5020027843388679\n",
      "Epoch: 225\n",
      "49.9604743083004,0.5020302644477501\n",
      "50.0,0.5020027843563971\n",
      "Epoch: 226\n",
      "49.9604743083004,0.5020302643996746\n",
      "50.0,0.5020027843735962\n",
      "Epoch: 227\n",
      "49.9604743083004,0.5020302643525033\n",
      "50.0,0.5020027843904715\n",
      "Epoch: 228\n",
      "49.9604743083004,0.5020302643062186\n",
      "50.0,0.5020027844070293\n",
      "Epoch: 229\n",
      "49.9604743083004,0.5020302642608053\n",
      "50.0,0.5020027844232751\n",
      "Epoch: 230\n",
      "49.9604743083004,0.5020302642162456\n",
      "50.0,0.5020027844392152\n",
      "Epoch: 231\n",
      "49.9604743083004,0.502030264172524\n",
      "50.0,0.5020027844548552\n",
      "Epoch: 232\n",
      "49.9604743083004,0.5020302641296235\n",
      "50.0,0.5020027844702007\n",
      "Epoch: 233\n",
      "49.9604743083004,0.5020302640875304\n",
      "50.0,0.5020027844852575\n",
      "Epoch: 234\n",
      "49.9604743083004,0.5020302640462286\n",
      "50.0,0.5020027845000307\n",
      "Epoch: 235\n",
      "49.9604743083004,0.5020302640057038\n",
      "50.0,0.5020027845145256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 236\n",
      "49.9604743083004,0.502030263965941\n",
      "50.0,0.5020027845287477\n",
      "Epoch: 237\n",
      "49.9604743083004,0.5020302639269252\n",
      "50.0,0.5020027845427022\n",
      "Epoch: 238\n",
      "49.9604743083004,0.5020302638886442\n",
      "50.0,0.5020027845563939\n",
      "Epoch: 239\n",
      "49.9604743083004,0.5020302638510826\n",
      "50.0,0.5020027845698278\n",
      "Epoch: 240\n",
      "49.9604743083004,0.502030263814227\n",
      "50.0,0.5020027845830091\n",
      "Epoch: 241\n",
      "49.9604743083004,0.5020302637780648\n",
      "50.0,0.5020027845959417\n",
      "Epoch: 242\n",
      "49.9604743083004,0.5020302637425821\n",
      "50.0,0.5020027846086311\n",
      "Epoch: 243\n",
      "49.9604743083004,0.5020302637077672\n",
      "50.0,0.5020027846210816\n",
      "Epoch: 244\n",
      "49.9604743083004,0.5020302636736066\n",
      "50.0,0.502002784633298\n",
      "Epoch: 245\n",
      "49.9604743083004,0.5020302636400884\n",
      "50.0,0.502002784645284\n",
      "Epoch: 246\n",
      "49.9604743083004,0.5020302636072004\n",
      "50.0,0.5020027846570444\n",
      "Epoch: 247\n",
      "49.9604743083004,0.5020302635749321\n",
      "50.0,0.5020027846685837\n",
      "Epoch: 248\n",
      "49.9604743083004,0.5020302635432684\n",
      "50.0,0.5020027846799056\n",
      "Epoch: 249\n",
      "49.9604743083004,0.5020302635122006\n",
      "50.0,0.5020027846910141\n",
      "Epoch: 250\n",
      "49.9604743083004,0.5020302634817179\n",
      "50.0,0.5020027847019137\n",
      "Epoch: 251\n",
      "49.9604743083004,0.5020302634518086\n",
      "50.0,0.5020027847126082\n",
      "Epoch: 252\n",
      "49.9604743083004,0.5020302634224605\n",
      "50.0,0.502002784723101\n",
      "Epoch: 253\n",
      "49.9604743083004,0.5020302633936651\n",
      "50.0,0.5020027847333967\n",
      "Epoch: 254\n",
      "49.9604743083004,0.5020302633654109\n",
      "50.0,0.5020027847434982\n",
      "Epoch: 255\n",
      "49.9604743083004,0.5020302633376879\n",
      "50.0,0.5020027847534098\n",
      "Epoch: 256\n",
      "49.9604743083004,0.5020302633104866\n",
      "50.0,0.5020027847631346\n",
      "Epoch: 257\n",
      "49.9604743083004,0.5020302632837963\n",
      "50.0,0.5020027847726765\n",
      "Epoch: 258\n",
      "49.9604743083004,0.5020302632576081\n",
      "50.0,0.5020027847820386\n",
      "Epoch: 259\n",
      "49.9604743083004,0.5020302632319124\n",
      "50.0,0.5020027847912244\n",
      "Epoch: 260\n",
      "49.9604743083004,0.5020302632067004\n",
      "50.0,0.5020027848002374\n",
      "Epoch: 261\n",
      "49.9604743083004,0.5020302631819619\n",
      "50.0,0.5020027848090808\n",
      "Epoch: 262\n",
      "49.9604743083004,0.5020302631576882\n",
      "50.0,0.5020027848177576\n",
      "Epoch: 263\n",
      "49.9604743083004,0.5020302631338716\n",
      "50.0,0.502002784826271\n",
      "Epoch: 264\n",
      "49.9604743083004,0.5020302631105026\n",
      "50.0,0.5020027848346242\n",
      "Epoch: 265\n",
      "49.9604743083004,0.502030263087573\n",
      "50.0,0.5020027848428201\n",
      "Epoch: 266\n",
      "49.9604743083004,0.5020302630650741\n",
      "50.0,0.5020027848508617\n",
      "Epoch: 267\n",
      "49.9604743083004,0.5020302630429991\n",
      "50.0,0.5020027848587518\n",
      "Epoch: 268\n",
      "49.9604743083004,0.5020302630213389\n",
      "50.0,0.5020027848664936\n",
      "Epoch: 269\n",
      "49.9604743083004,0.5020302630000858\n",
      "50.0,0.5020027848740897\n",
      "Epoch: 270\n",
      "49.9604743083004,0.502030262979233\n",
      "50.0,0.5020027848815424\n",
      "Epoch: 271\n",
      "49.9604743083004,0.5020302629587721\n",
      "50.0,0.502002784888855\n",
      "Epoch: 272\n",
      "49.9604743083004,0.5020302629386953\n",
      "50.0,0.5020027848960299\n",
      "Epoch: 273\n",
      "49.9604743083004,0.5020302629189967\n",
      "50.0,0.50200278490307\n",
      "Epoch: 274\n",
      "49.9604743083004,0.5020302628996675\n",
      "50.0,0.5020027849099771\n",
      "Epoch: 275\n",
      "49.9604743083004,0.5020302628807033\n",
      "50.0,0.5020027849167547\n",
      "Epoch: 276\n",
      "49.9604743083004,0.5020302628620947\n",
      "50.0,0.5020027849234042\n",
      "Epoch: 277\n",
      "49.9604743083004,0.5020302628438356\n",
      "50.0,0.5020027849299288\n",
      "Epoch: 278\n",
      "49.9604743083004,0.5020302628259209\n",
      "50.0,0.5020027849363303\n",
      "Epoch: 279\n",
      "49.9604743083004,0.5020302628083432\n",
      "50.0,0.5020027849426116\n",
      "Epoch: 280\n",
      "49.9604743083004,0.5020302627910952\n",
      "50.0,0.5020027849487745\n",
      "Epoch: 281\n",
      "49.9604743083004,0.502030262774172\n",
      "50.0,0.5020027849548213\n",
      "Epoch: 282\n",
      "49.9604743083004,0.5020302627575662\n",
      "50.0,0.5020027849607542\n",
      "Epoch: 283\n",
      "49.9604743083004,0.5020302627412734\n",
      "50.0,0.5020027849665756\n",
      "Epoch: 284\n",
      "49.9604743083004,0.5020302627252872\n",
      "50.0,0.5020027849722875\n",
      "Epoch: 285\n",
      "49.9604743083004,0.5020302627096013\n",
      "50.0,0.5020027849778919\n",
      "Epoch: 286\n",
      "49.9604743083004,0.5020302626942099\n",
      "50.0,0.5020027849833902\n",
      "Epoch: 287\n",
      "49.9604743083004,0.5020302626791086\n",
      "50.0,0.5020027849887856\n",
      "Epoch: 288\n",
      "49.9604743083004,0.502030262664291\n",
      "50.0,0.5020027849940792\n",
      "Epoch: 289\n",
      "49.9604743083004,0.5020302626497514\n",
      "50.0,0.5020027849992731\n",
      "Epoch: 290\n",
      "49.9604743083004,0.5020302626354859\n",
      "50.0,0.5020027850043692\n",
      "Epoch: 291\n",
      "49.9604743083004,0.5020302626214885\n",
      "50.0,0.5020027850093696\n",
      "Epoch: 292\n",
      "49.9604743083004,0.5020302626077549\n",
      "50.0,0.5020027850142756\n",
      "Epoch: 293\n",
      "49.9604743083004,0.5020302625942791\n",
      "50.0,0.5020027850190892\n",
      "Epoch: 294\n",
      "49.9604743083004,0.5020302625810563\n",
      "50.0,0.5020027850238123\n",
      "Epoch: 295\n",
      "49.9604743083004,0.5020302625680829\n",
      "50.0,0.5020027850284464\n",
      "Epoch: 296\n",
      "49.9604743083004,0.5020302625553525\n",
      "50.0,0.5020027850329936\n",
      "Epoch: 297\n",
      "49.9604743083004,0.502030262542862\n",
      "50.0,0.5020027850374549\n",
      "Epoch: 298\n",
      "49.9604743083004,0.5020302625306067\n",
      "50.0,0.5020027850418323\n",
      "Epoch: 299\n",
      "49.9604743083004,0.5020302625185815\n",
      "50.0,0.5020027850461273\n",
      "Epoch: 300\n",
      "49.9604743083004,0.5020302625067824\n",
      "50.0,0.5020027850503415\n",
      "Epoch: 301\n",
      "49.9604743083004,0.5020302624952047\n",
      "50.0,0.5020027850544759\n",
      "Epoch: 302\n",
      "49.9604743083004,0.5020302624838454\n",
      "50.0,0.5020027850585329\n",
      "Epoch: 303\n",
      "49.9604743083004,0.5020302624726992\n",
      "50.0,0.5020027850625133\n",
      "Epoch: 304\n",
      "49.9604743083004,0.5020302624617631\n",
      "50.0,0.5020027850664193\n",
      "Epoch: 305\n",
      "49.9604743083004,0.5020302624510323\n",
      "50.0,0.5020027850702508\n",
      "Epoch: 306\n",
      "49.9604743083004,0.5020302624405037\n",
      "50.0,0.502002785074011\n",
      "Epoch: 307\n",
      "49.9604743083004,0.5020302624301731\n",
      "50.0,0.5020027850777001\n",
      "Epoch: 308\n",
      "49.9604743083004,0.5020302624200361\n",
      "50.0,0.5020027850813198\n"
     ]
    }
   ],
   "source": [
    "train_lab = np.asarray(train_lab)\n",
    "log_erms_val = np.zeros(300000)\n",
    "log_erms_train = np.zeros(300000)\n",
    "log_erms_test = []\n",
    "np.random.seed(589)\n",
    "if(mode == 2):\n",
    "    if(subMode == 'a'):\n",
    "        prev_weight = np.zeros((M,1))\n",
    "else:\n",
    "    prev_weight = prev_weight = np.zeros((M,1))\n",
    "'''1 B\n",
    "alpha = 0.00003\n",
    "lam = 0.5\n",
    "sensitivity =  0.001\n",
    "'''\n",
    "alpha = 0.00003\n",
    "lam = 0.5\n",
    "sensitivity =  0.00000000001\n",
    "pErms_Val = 0\n",
    "nErms_Val = 10\n",
    "ptrain_erms = 0\n",
    "ntrain_erms = 10\n",
    "epoch = 0\n",
    "ValAccString = ''\n",
    "TrainAccString = ''\n",
    "'''\n",
    "Logging for ERMS Train and Validate should have graphMode enabled\n",
    "'''\n",
    "\n",
    "graphMode = False\n",
    "\n",
    "while(abs(ntrain_erms - ptrain_erms ) > sensitivity):\n",
    "    print(\"Epoch: \"+str(epoch))\n",
    "    print(TrainAccString)\n",
    "    print(ValAccString)\n",
    "    for i in range(0,len(train)):\n",
    "        #print(\"Iteration: \"+str(i))\n",
    "        prev_weight = updateWeights(prev_weight,phiMat[i],train_lab[i],alpha,lam)\n",
    "        #-----------------TrainingData Accuracy---------------------#\n",
    "        #TR_TEST_OUT   = GetValTest(phiMat,prev_weight) \n",
    "        #Erms_TR,train_erms       = GetErms(np.transpose(TR_TEST_OUT),np.asarray(train_lab))\n",
    "        #print ('---------ValidationData Accuracy: ' + Erms_Val + '--------------')\n",
    "        #VAL_TEST_OUT  = GetValTest(valMat,prev_weight) \n",
    "        #Erms_Val,val_erms      = GetErms(np.transpose(VAL_TEST_OUT),np.asarray(val_lab))\n",
    "        \n",
    "        \n",
    "        #---------------TestingData Accuracy---------------------#\n",
    "        #TEST_OUT      = GetValTest(testMat,prev_weight) \n",
    "        #Erms_Test = GetErms(np.transpose(TEST_OUT),np.asarray(test_lab))\n",
    "        #log_erms_test.append(float(Erms_Test.split(',')[1]))\n",
    "        if(graphMode):\n",
    "            log_erms_train[i] = train_erms\n",
    "            log_erms_val[i] = val_erms\n",
    "            \n",
    "    #train,train_lab,phiMat = epoch_shuffle(train,train_lab,phiMat)\n",
    "    \n",
    "    TR_TEST_OUT   = GetValTest(phiMat,prev_weight)\n",
    "    ptrain_erms = ntrain_erms\n",
    "    TrainAccString,ntrain_erms       = GetErms(np.transpose(TR_TEST_OUT),np.asarray(train_lab))\n",
    "    \n",
    "    VAL_TEST_OUT  = GetValTest(valMat,prev_weight)\n",
    "    pErms_Val = nErms_Val\n",
    "    ValAccString,nErms_Val      = GetErms(np.transpose(VAL_TEST_OUT),np.asarray(val_lab))\n",
    "    epoch +=1\n",
    "    #if(epoch >5):\n",
    "       # pErms_Val = nErms_Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotData(log_erms_train,log_erms_val,log_erms_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[79,  0],\n",
       "       [79,  0]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(val_lab.iloc[:,0],np.array(np.round(VAL_TEST_OUT.reshape(np.shape(VAL_TEST_OUT)[1],1),0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[79,  0],\n",
       "       [79,  0]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(val_lab.iloc[:,0],np.array(np.round(VAL_TEST_OUT.reshape(np.shape(VAL_TEST_OUT)[1],1),0)))\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0.0  All\n",
       "True               \n",
       "0           80   80\n",
       "1           79   79\n",
       "All        159  159"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = pd.Series(np.array(test_lab.iloc[:,0]))\n",
    "y_pred = pd.Series(np.array((np.around(TR_TEST_OUT, 0))).ravel())\n",
    "\n",
    "pd.crosstab(y_true, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
