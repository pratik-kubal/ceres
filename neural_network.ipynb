{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(111)\n",
    "    \n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(125)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Linear Regression README:\n",
    "Modes:\n",
    "1. Human Observed Dataset\n",
    "2. GSC\n",
    "Feature Type:\n",
    "a. Feature Concat\n",
    "b. Feature Subs\n",
    "'''\n",
    "mode = 1\n",
    "subMode = 'b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_setting_one(master_data,pos_data):\n",
    "    raw_data_temp = pd.concat([pos_data.set_index('img_id_A'),master_data.set_index('img_id')],axis=1,join='inner').reset_index()\n",
    "    raw_data_feature_concat = pd.concat([raw_data_temp.set_index('img_id_B'),master_data.set_index('img_id')],axis=1,join='inner').reset_index()\n",
    "    if(np.shape(raw_data_feature_concat)[1] < 25):\n",
    "        raw_data_feature_concat.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "        num_features = 9 + 1\n",
    "    else:\n",
    "        num_features = 512+1\n",
    "    col_rename = ['img_id_B','img_id_A','target']\n",
    "    for columns in range(1,len(list(raw_data_feature_concat.columns)[3:])+1):\n",
    "        if(columns < num_features):\n",
    "            col_rename.append(\"fa\"+str(columns))\n",
    "        else:\n",
    "            col_rename.append(\"fb\"+str(columns - num_features+1))\n",
    "    raw_data_feature_concat.columns = col_rename\n",
    "    col_rename.append(col_rename.pop(2))\n",
    "    temp = col_rename[0]\n",
    "    col_rename[0] = col_rename[1]\n",
    "    col_rename[1] = temp\n",
    "    raw_data_feature_concat = raw_data_feature_concat[col_rename]\n",
    "    return raw_data_feature_concat\n",
    "\n",
    "def create_setting_two(raw_data_feature_concat):\n",
    "    raw_data_feature_subs = pd.concat([raw_data_feature_concat.iloc[:,0:2],raw_data_feature_concat.iloc[:,-1]],axis=1,join='inner').reset_index()\n",
    "    for columns in range(1,int((len(list(raw_data_feature_concat.columns))-3)/2+1)):\n",
    "        raw_data_feature_subs['fm'+str(columns)] = abs(raw_data_feature_concat['fa'+str(columns)] - raw_data_feature_concat['fb'+str(columns)])\n",
    "    col_swap = list(raw_data_feature_subs.columns)[1:]\n",
    "    col_swap.append(col_swap.pop(2))\n",
    "    raw_data_feature_subs=raw_data_feature_subs[col_swap]\n",
    "    return raw_data_feature_subs\n",
    "\n",
    "def stratifiedSampling(data,test_split,seed):\n",
    "    train,test = train_test_split(data,test_size = test_split,stratify=data[[\"target\"]],random_state=seed)\n",
    "    return train,test\n",
    "\n",
    "def data_selection(mode,subMode):\n",
    "    # GSC or HOD??\n",
    "    if(mode == 1):\n",
    "        hum_obs_master_data = pd.read_csv(\"../HumanObserved-Dataset/HumanObserved-Dataset/HumanObserved-Features-Data/HumanObserved-Features-Data.csv\")\n",
    "        hum_obs_pos_data = pd.read_csv(\"../HumanObserved-Dataset/HumanObserved-Dataset/HumanObserved-Features-Data/same_pairs.csv\")\n",
    "        hum_obs_neg_data = pd.read_csv(\"../HumanObserved-Dataset/HumanObserved-Dataset/HumanObserved-Features-Data/diffn_pairs.csv\")\n",
    "        raw_pos_data = create_setting_one(hum_obs_master_data,hum_obs_pos_data)\n",
    "        raw_neg_data = create_setting_one(hum_obs_master_data,hum_obs_neg_data.sample(len(hum_obs_pos_data),random_state=444))\n",
    "        if(subMode == 'b'):\n",
    "            raw_pos_data = create_setting_two(raw_pos_data)\n",
    "            raw_neg_data = create_setting_two(raw_neg_data)\n",
    "            del hum_obs_master_data,hum_obs_pos_data,hum_obs_neg_data\n",
    "    elif(mode ==2):\n",
    "        gsc_master_data = pd.read_csv(\"../GSC-Dataset/GSC-Dataset/GSC-Features-Data/GSC-Features.csv\")\n",
    "        gsc_pos_data = pd.read_csv(\"../GSC-Dataset/GSC-Dataset/GSC-Features-Data/same_pairs.csv\")\n",
    "        gsc_neg_data = pd.read_csv(\"../GSC-Dataset/GSC-Dataset/GSC-Features-Data/diffn_pairs.csv\")\n",
    "                # High Memory -> NEED TO FIX\n",
    "        raw_pos_data = create_setting_one(gsc_master_data,gsc_pos_data)\n",
    "        raw_neg_data = create_setting_one(gsc_master_data,gsc_neg_data.sample(len(gsc_pos_data),random_state=444))\n",
    "        if(subMode == 'b'):\n",
    "            raw_pos_data = create_setting_two(raw_pos_data)\n",
    "            raw_neg_data = create_setting_two(raw_neg_data)\n",
    "            del gsc_master_data,gsc_pos_data,gsc_neg_data\n",
    "    '''\n",
    "    Partition Scheme\n",
    "    unseenWriter = true\n",
    "    default = false\n",
    "    '''\n",
    "    partScheme = False\n",
    "    if(partScheme):\n",
    "        # Unseen Writer partitions\n",
    "        raw_data_feature_concat_pos[['A','A_imgNo']] = raw_data_feature_concat_pos['img_id_A'].str.extract('(\\d\\d\\d\\d)([a-z])', expand=False)\n",
    "        raw_data_feature_concat_pos[['B','B_imgNo']] = raw_data_feature_concat_pos['img_id_B'].str.extract('(\\d\\d\\d\\d)([a-z])', expand=False)\n",
    "        #raw_data_feature_concat['img_id_A'].str.extract('(?P<writerA>\\d\\d\\d\\d)(?P<imageNo>[abcd])', expand=False)\n",
    "        raw_data_feature_concat_neg[['A','A_imgNo']] = raw_data_feature_concat_neg['img_id_A'].str.extract('(\\d\\d\\d\\d)([a-z])', expand=False)\n",
    "        raw_data_feature_concat_neg[['B','B_imgNo']] = raw_data_feature_concat_neg['img_id_B'].str.extract('(\\d\\d\\d\\d)([a-z])', expand=False)\n",
    "        data = pd.concat([raw_pos_data,raw_neg_data],ignore_index=True)\n",
    "    else:\n",
    "        data = pd.concat([raw_pos_data,raw_neg_data],ignore_index=True)\n",
    "    data = data.iloc[:,2:np.shape(data)[1]]\n",
    "    \n",
    "    data = data.sample(frac=1,random_state=44)\n",
    "    \n",
    "    if(mode == 1):\n",
    "        train,test = stratifiedSampling(data,0.05,444)\n",
    "    elif(mode == 2):\n",
    "        train,test = stratifiedSampling(data,0.1,444)\n",
    "    \n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = data_selection(1,\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_87 (Dense)             (None, 256)               4864      \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 54,530\n",
      "Trainable params: 54,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    input_size = len(train.columns)-1\n",
    "    drop_out = 0.5\n",
    "    first_dense_layer_nodes  = 256\n",
    "    second_dense_layer_nodes = 128\n",
    "    third_dense_layer_nodes = 64\n",
    "    final_dense_layer_nodes = 2\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(first_dense_layer_nodes, input_dim=input_size))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(second_dense_layer_nodes))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # Why dropout?\n",
    "    # Avoids the model being overfitted for the training data such that it fails to generalize for new \n",
    "    # incidences.\n",
    "    model.add(Dropout(drop_out))\n",
    "    \n",
    "    model.add(Dense(second_dense_layer_nodes))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(final_dense_layer_nodes))\n",
    "    model.add(Activation('softmax'))\n",
    "    # Why Softmax?\n",
    "    # Since this is a multi class classification problem, for the last output layer we need to translate the continous signal \n",
    "    # into a discrete signal which will give us the classes. The softmax activation converts a vector of arbitary\n",
    "    # real values into a vector of values in a specific range from which we can get categories.\n",
    "    # Important thing to note is that the predicted class will belong to only one class, therefore sum of \n",
    "    # probabalities sums to one. For Multi label problem we have to use a different activation, perhaps \n",
    "    # sigmoid.\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    # Why use categorical_crossentropy?\n",
    "    # Here if we have to use crossentropy loss functions we have various choices such as Binary Crossentropy, categorical\n",
    "    # crossentropy and Sparse Crossentropy. Here we have One-hot Encoded the input therefore we have to use categorical\n",
    "    # crossentropy.\n",
    "    # https://jovianlin.io/cat-crossentropy-vs-sparse-cat-crossentropy/\n",
    "    \n",
    "    # Commented out to use metrics as categorical_accuracy for categorical data\n",
    "    #model.compile(optimizer='rmsprop',\n",
    "    #              loss='categorical_crossentropy',\n",
    "    #              metrics=['accuracy'])\n",
    "    #model.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=['accuracy'])\n",
    "    #rmsprop = keras.optimizers.RMSprop(lr=0.01, rho=0.9, epsilon=None, decay=0.0)\n",
    "    #model.compile(loss='categorical_crossentropy', optimizer=rmsprop,metrics=['accuracy'])\n",
    "    \n",
    "    #sgd = keras.optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    adadelta = keras.optimizers.Adadelta(lr=0.1, rho=0.95, epsilon=None, decay=0)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=adadelta,metrics=['binary_accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_91 (Dense)             (None, 1024)              19456     \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 32)                32800     \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 52,322\n",
      "Trainable params: 52,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def small_model():\n",
    "    input_size = len(train.columns)-1\n",
    "    drop_out = 0.03\n",
    "    first_dense_layer_nodes  = 1024\n",
    "    second_dense_layer_nodes = 32\n",
    "    final_dense_layer_nodes = 2\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(first_dense_layer_nodes, input_dim=input_size))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # Why dropout?\n",
    "    # Avoids the model being overfitted for the training data such that it fails to generalize for new \n",
    "    # incidences.\n",
    "    model.add(Dropout(drop_out))\n",
    "    \n",
    "    model.add(Dense(second_dense_layer_nodes, input_dim=input_size))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(final_dense_layer_nodes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    sgd = keras.optimizers.SGD(lr=0.3, decay=0.001, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=\"adam\",metrics=['binary_accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = small_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 751 samples, validate on 751 samples\n",
      "Epoch 1/10000\n",
      "751/751 [==============================] - 2s 2ms/step - loss: 0.6982 - binary_accuracy: 0.5366 - val_loss: 0.6979 - val_binary_accuracy: 0.5073\n",
      "Epoch 2/10000\n",
      "751/751 [==============================] - 0s 104us/step - loss: 0.6903 - binary_accuracy: 0.5233 - val_loss: 0.6927 - val_binary_accuracy: 0.5113\n",
      "Epoch 3/10000\n",
      "751/751 [==============================] - 0s 87us/step - loss: 0.6757 - binary_accuracy: 0.5832 - val_loss: 0.6965 - val_binary_accuracy: 0.5246\n",
      "Epoch 4/10000\n",
      "751/751 [==============================] - 0s 99us/step - loss: 0.6746 - binary_accuracy: 0.5846 - val_loss: 0.7007 - val_binary_accuracy: 0.5233\n",
      "Epoch 5/10000\n",
      "751/751 [==============================] - 0s 117us/step - loss: 0.6655 - binary_accuracy: 0.5872 - val_loss: 0.7034 - val_binary_accuracy: 0.5020\n",
      "Epoch 6/10000\n",
      "751/751 [==============================] - 0s 115us/step - loss: 0.6603 - binary_accuracy: 0.6099 - val_loss: 0.7066 - val_binary_accuracy: 0.5206\n",
      "Epoch 7/10000\n",
      "751/751 [==============================] - 0s 111us/step - loss: 0.6569 - binary_accuracy: 0.6165 - val_loss: 0.7049 - val_binary_accuracy: 0.5246\n",
      "Epoch 8/10000\n",
      "751/751 [==============================] - 0s 110us/step - loss: 0.6501 - binary_accuracy: 0.6178 - val_loss: 0.7063 - val_binary_accuracy: 0.5366\n",
      "Epoch 9/10000\n",
      "751/751 [==============================] - 0s 121us/step - loss: 0.6426 - binary_accuracy: 0.6325 - val_loss: 0.7063 - val_binary_accuracy: 0.5300\n",
      "Epoch 10/10000\n",
      "751/751 [==============================] - 0s 112us/step - loss: 0.6404 - binary_accuracy: 0.6365 - val_loss: 0.7054 - val_binary_accuracy: 0.5393\n",
      "Epoch 11/10000\n",
      "751/751 [==============================] - 0s 125us/step - loss: 0.6360 - binary_accuracy: 0.6485 - val_loss: 0.7057 - val_binary_accuracy: 0.5300\n",
      "Epoch 12/10000\n",
      "751/751 [==============================] - 0s 135us/step - loss: 0.6322 - binary_accuracy: 0.6458 - val_loss: 0.7097 - val_binary_accuracy: 0.5393\n",
      "Epoch 13/10000\n",
      "751/751 [==============================] - 0s 122us/step - loss: 0.6284 - binary_accuracy: 0.6418 - val_loss: 0.7101 - val_binary_accuracy: 0.5340\n",
      "Epoch 14/10000\n",
      "751/751 [==============================] - 0s 107us/step - loss: 0.6204 - binary_accuracy: 0.6631 - val_loss: 0.7104 - val_binary_accuracy: 0.5353\n",
      "Epoch 15/10000\n",
      "751/751 [==============================] - 0s 118us/step - loss: 0.6131 - binary_accuracy: 0.6711 - val_loss: 0.7127 - val_binary_accuracy: 0.5379\n",
      "Epoch 16/10000\n",
      "751/751 [==============================] - 0s 117us/step - loss: 0.6065 - binary_accuracy: 0.6724 - val_loss: 0.7168 - val_binary_accuracy: 0.5353\n",
      "Epoch 17/10000\n",
      "751/751 [==============================] - 0s 136us/step - loss: 0.6008 - binary_accuracy: 0.6738 - val_loss: 0.7177 - val_binary_accuracy: 0.5326\n",
      "Epoch 18/10000\n",
      "751/751 [==============================] - 0s 119us/step - loss: 0.5961 - binary_accuracy: 0.6871 - val_loss: 0.7185 - val_binary_accuracy: 0.5340\n",
      "Epoch 19/10000\n",
      "751/751 [==============================] - 0s 118us/step - loss: 0.5844 - binary_accuracy: 0.7044 - val_loss: 0.7200 - val_binary_accuracy: 0.5260\n",
      "Epoch 20/10000\n",
      "751/751 [==============================] - 0s 133us/step - loss: 0.5832 - binary_accuracy: 0.7190 - val_loss: 0.7255 - val_binary_accuracy: 0.5273\n",
      "Epoch 21/10000\n",
      "751/751 [==============================] - 0s 143us/step - loss: 0.5726 - binary_accuracy: 0.7164 - val_loss: 0.7262 - val_binary_accuracy: 0.5326\n",
      "Epoch 22/10000\n",
      "751/751 [==============================] - 0s 132us/step - loss: 0.5676 - binary_accuracy: 0.7257 - val_loss: 0.7330 - val_binary_accuracy: 0.5206\n",
      "Epoch 23/10000\n",
      "751/751 [==============================] - 0s 95us/step - loss: 0.5549 - binary_accuracy: 0.7470 - val_loss: 0.7293 - val_binary_accuracy: 0.5353\n",
      "Epoch 24/10000\n",
      "751/751 [==============================] - 0s 102us/step - loss: 0.5512 - binary_accuracy: 0.7510 - val_loss: 0.7330 - val_binary_accuracy: 0.5313\n",
      "Epoch 25/10000\n",
      "751/751 [==============================] - 0s 112us/step - loss: 0.5456 - binary_accuracy: 0.7537 - val_loss: 0.7359 - val_binary_accuracy: 0.5313\n",
      "Epoch 26/10000\n",
      "751/751 [==============================] - 0s 130us/step - loss: 0.5365 - binary_accuracy: 0.7617 - val_loss: 0.7414 - val_binary_accuracy: 0.5260\n",
      "Epoch 27/10000\n",
      "751/751 [==============================] - 0s 123us/step - loss: 0.5263 - binary_accuracy: 0.7696 - val_loss: 0.7443 - val_binary_accuracy: 0.5246\n",
      "Epoch 28/10000\n",
      "751/751 [==============================] - 0s 124us/step - loss: 0.5159 - binary_accuracy: 0.7816 - val_loss: 0.7511 - val_binary_accuracy: 0.5313\n",
      "Epoch 29/10000\n",
      "751/751 [==============================] - 0s 113us/step - loss: 0.5096 - binary_accuracy: 0.7843 - val_loss: 0.7545 - val_binary_accuracy: 0.5313\n",
      "Epoch 30/10000\n",
      "751/751 [==============================] - 0s 107us/step - loss: 0.5055 - binary_accuracy: 0.7870 - val_loss: 0.7588 - val_binary_accuracy: 0.5073\n",
      "Epoch 31/10000\n",
      "751/751 [==============================] - 0s 120us/step - loss: 0.4927 - binary_accuracy: 0.7976 - val_loss: 0.7620 - val_binary_accuracy: 0.5246\n",
      "Epoch 32/10000\n",
      "751/751 [==============================] - 0s 113us/step - loss: 0.4877 - binary_accuracy: 0.8083 - val_loss: 0.7667 - val_binary_accuracy: 0.5326\n",
      "Epoch 33/10000\n",
      "751/751 [==============================] - 0s 122us/step - loss: 0.4737 - binary_accuracy: 0.8189 - val_loss: 0.7805 - val_binary_accuracy: 0.4887\n",
      "Epoch 34/10000\n",
      "751/751 [==============================] - 0s 107us/step - loss: 0.4710 - binary_accuracy: 0.8069 - val_loss: 0.7903 - val_binary_accuracy: 0.5286\n",
      "Epoch 35/10000\n",
      "751/751 [==============================] - 0s 109us/step - loss: 0.4783 - binary_accuracy: 0.7949 - val_loss: 0.7843 - val_binary_accuracy: 0.5007\n",
      "Epoch 36/10000\n",
      "751/751 [==============================] - 0s 125us/step - loss: 0.4501 - binary_accuracy: 0.8402 - val_loss: 0.7886 - val_binary_accuracy: 0.5260\n",
      "Epoch 37/10000\n",
      "751/751 [==============================] - 0s 105us/step - loss: 0.4440 - binary_accuracy: 0.8229 - val_loss: 0.7981 - val_binary_accuracy: 0.4913\n",
      "Epoch 38/10000\n",
      "751/751 [==============================] - 0s 93us/step - loss: 0.4355 - binary_accuracy: 0.8375 - val_loss: 0.8035 - val_binary_accuracy: 0.5153\n",
      "Epoch 39/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 0.4293 - binary_accuracy: 0.8429 - val_loss: 0.8042 - val_binary_accuracy: 0.5260\n",
      "Epoch 40/10000\n",
      "751/751 [==============================] - 0s 95us/step - loss: 0.4208 - binary_accuracy: 0.8402 - val_loss: 0.8130 - val_binary_accuracy: 0.4847\n",
      "Epoch 41/10000\n",
      "751/751 [==============================] - 0s 108us/step - loss: 0.4082 - binary_accuracy: 0.8602 - val_loss: 0.8411 - val_binary_accuracy: 0.5313\n",
      "Epoch 42/10000\n",
      "751/751 [==============================] - 0s 93us/step - loss: 0.4080 - binary_accuracy: 0.8349 - val_loss: 0.8553 - val_binary_accuracy: 0.4993\n",
      "Epoch 43/10000\n",
      "751/751 [==============================] - 0s 83us/step - loss: 0.3991 - binary_accuracy: 0.8495 - val_loss: 0.8544 - val_binary_accuracy: 0.5273\n",
      "Epoch 44/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 0.3965 - binary_accuracy: 0.8615 - val_loss: 0.8402 - val_binary_accuracy: 0.4700\n",
      "Epoch 45/10000\n",
      "751/751 [==============================] - 0s 99us/step - loss: 0.3845 - binary_accuracy: 0.8695 - val_loss: 0.8427 - val_binary_accuracy: 0.5166\n",
      "Epoch 46/10000\n",
      "751/751 [==============================] - 0s 114us/step - loss: 0.3766 - binary_accuracy: 0.8735 - val_loss: 0.8597 - val_binary_accuracy: 0.5153\n",
      "Epoch 47/10000\n",
      "751/751 [==============================] - 0s 95us/step - loss: 0.3726 - binary_accuracy: 0.8589 - val_loss: 0.8856 - val_binary_accuracy: 0.4900\n",
      "Epoch 48/10000\n",
      "751/751 [==============================] - 0s 93us/step - loss: 0.3657 - binary_accuracy: 0.8642 - val_loss: 0.8924 - val_binary_accuracy: 0.5260\n",
      "Epoch 49/10000\n",
      "751/751 [==============================] - 0s 94us/step - loss: 0.3556 - binary_accuracy: 0.8722 - val_loss: 0.8801 - val_binary_accuracy: 0.4887\n",
      "Epoch 50/10000\n",
      "751/751 [==============================] - 0s 97us/step - loss: 0.3666 - binary_accuracy: 0.8589 - val_loss: 0.8751 - val_binary_accuracy: 0.4953\n",
      "Epoch 51/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751/751 [==============================] - 0s 91us/step - loss: 0.3415 - binary_accuracy: 0.8921 - val_loss: 0.8907 - val_binary_accuracy: 0.5087\n",
      "Epoch 52/10000\n",
      "751/751 [==============================] - 0s 114us/step - loss: 0.3379 - binary_accuracy: 0.8881 - val_loss: 0.9324 - val_binary_accuracy: 0.4874\n",
      "Epoch 53/10000\n",
      "751/751 [==============================] - 0s 92us/step - loss: 0.3337 - binary_accuracy: 0.8908 - val_loss: 0.9489 - val_binary_accuracy: 0.5180\n",
      "Epoch 54/10000\n",
      "751/751 [==============================] - 0s 97us/step - loss: 0.3410 - binary_accuracy: 0.8788 - val_loss: 0.9392 - val_binary_accuracy: 0.4847\n",
      "Epoch 55/10000\n",
      "751/751 [==============================] - 0s 102us/step - loss: 0.3176 - binary_accuracy: 0.8961 - val_loss: 0.9393 - val_binary_accuracy: 0.5087\n",
      "Epoch 56/10000\n",
      "751/751 [==============================] - 0s 93us/step - loss: 0.3163 - binary_accuracy: 0.9055 - val_loss: 0.9550 - val_binary_accuracy: 0.4980\n",
      "Epoch 57/10000\n",
      "751/751 [==============================] - 0s 93us/step - loss: 0.3021 - binary_accuracy: 0.9081 - val_loss: 0.9640 - val_binary_accuracy: 0.5113\n",
      "Epoch 58/10000\n",
      "751/751 [==============================] - 0s 90us/step - loss: 0.3103 - binary_accuracy: 0.8988 - val_loss: 0.9629 - val_binary_accuracy: 0.4834\n",
      "Epoch 59/10000\n",
      "751/751 [==============================] - 0s 99us/step - loss: 0.2969 - binary_accuracy: 0.9214 - val_loss: 0.9470 - val_binary_accuracy: 0.5060\n",
      "Epoch 60/10000\n",
      "751/751 [==============================] - 0s 102us/step - loss: 0.2770 - binary_accuracy: 0.9201 - val_loss: 0.9522 - val_binary_accuracy: 0.4887\n",
      "Epoch 61/10000\n",
      "751/751 [==============================] - 0s 96us/step - loss: 0.2772 - binary_accuracy: 0.9308 - val_loss: 0.9644 - val_binary_accuracy: 0.5060\n",
      "Epoch 62/10000\n",
      "751/751 [==============================] - 0s 94us/step - loss: 0.2633 - binary_accuracy: 0.9308 - val_loss: 0.9658 - val_binary_accuracy: 0.4967\n",
      "Epoch 63/10000\n",
      "751/751 [==============================] - 0s 116us/step - loss: 0.2611 - binary_accuracy: 0.9348 - val_loss: 0.9712 - val_binary_accuracy: 0.4887\n",
      "Epoch 64/10000\n",
      "751/751 [==============================] - 0s 98us/step - loss: 0.2518 - binary_accuracy: 0.9427 - val_loss: 0.9898 - val_binary_accuracy: 0.5126\n",
      "Epoch 65/10000\n",
      "751/751 [==============================] - 0s 100us/step - loss: 0.2581 - binary_accuracy: 0.9241 - val_loss: 1.0053 - val_binary_accuracy: 0.4940\n",
      "Epoch 66/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.2426 - binary_accuracy: 0.9321 - val_loss: 1.0051 - val_binary_accuracy: 0.5047\n",
      "Epoch 67/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 0.2422 - binary_accuracy: 0.9334 - val_loss: 0.9993 - val_binary_accuracy: 0.4980\n",
      "Epoch 68/10000\n",
      "751/751 [==============================] - 0s 93us/step - loss: 0.2392 - binary_accuracy: 0.9361 - val_loss: 1.0283 - val_binary_accuracy: 0.4887\n",
      "Epoch 69/10000\n",
      "751/751 [==============================] - 0s 109us/step - loss: 0.2406 - binary_accuracy: 0.9414 - val_loss: 1.0502 - val_binary_accuracy: 0.5047\n",
      "Epoch 70/10000\n",
      "751/751 [==============================] - 0s 105us/step - loss: 0.2338 - binary_accuracy: 0.9334 - val_loss: 1.0714 - val_binary_accuracy: 0.4874\n",
      "Epoch 71/10000\n",
      "751/751 [==============================] - 0s 89us/step - loss: 0.2277 - binary_accuracy: 0.9427 - val_loss: 1.0526 - val_binary_accuracy: 0.5100\n",
      "Epoch 72/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.2174 - binary_accuracy: 0.9414 - val_loss: 1.0614 - val_binary_accuracy: 0.4900\n",
      "Epoch 73/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.2099 - binary_accuracy: 0.9574 - val_loss: 1.0613 - val_binary_accuracy: 0.5113\n",
      "Epoch 74/10000\n",
      "751/751 [==============================] - 0s 87us/step - loss: 0.2155 - binary_accuracy: 0.9494 - val_loss: 1.0724 - val_binary_accuracy: 0.4860\n",
      "Epoch 75/10000\n",
      "751/751 [==============================] - 0s 92us/step - loss: 0.2046 - binary_accuracy: 0.9441 - val_loss: 1.0742 - val_binary_accuracy: 0.4967\n",
      "Epoch 76/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 0.2009 - binary_accuracy: 0.9574 - val_loss: 1.0840 - val_binary_accuracy: 0.5113\n",
      "Epoch 77/10000\n",
      "751/751 [==============================] - 0s 88us/step - loss: 0.1933 - binary_accuracy: 0.9601 - val_loss: 1.1018 - val_binary_accuracy: 0.4847\n",
      "Epoch 78/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.1898 - binary_accuracy: 0.9587 - val_loss: 1.0945 - val_binary_accuracy: 0.4927\n",
      "Epoch 79/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.1813 - binary_accuracy: 0.9720 - val_loss: 1.1209 - val_binary_accuracy: 0.4847\n",
      "Epoch 80/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.1843 - binary_accuracy: 0.9561 - val_loss: 1.1118 - val_binary_accuracy: 0.4927\n",
      "Epoch 81/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.1746 - binary_accuracy: 0.9640 - val_loss: 1.1152 - val_binary_accuracy: 0.4953\n",
      "Epoch 82/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.1688 - binary_accuracy: 0.9667 - val_loss: 1.1251 - val_binary_accuracy: 0.4993\n",
      "Epoch 83/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.1629 - binary_accuracy: 0.9720 - val_loss: 1.1321 - val_binary_accuracy: 0.5087\n",
      "Epoch 84/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.1600 - binary_accuracy: 0.9694 - val_loss: 1.1451 - val_binary_accuracy: 0.4993\n",
      "Epoch 85/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.1541 - binary_accuracy: 0.9774 - val_loss: 1.1536 - val_binary_accuracy: 0.4913\n",
      "Epoch 86/10000\n",
      "751/751 [==============================] - 0s 94us/step - loss: 0.1537 - binary_accuracy: 0.9747 - val_loss: 1.1638 - val_binary_accuracy: 0.4980\n",
      "Epoch 87/10000\n",
      "751/751 [==============================] - 0s 109us/step - loss: 0.1521 - binary_accuracy: 0.9720 - val_loss: 1.1878 - val_binary_accuracy: 0.5140\n",
      "Epoch 88/10000\n",
      "751/751 [==============================] - 0s 122us/step - loss: 0.1509 - binary_accuracy: 0.9827 - val_loss: 1.2335 - val_binary_accuracy: 0.4860\n",
      "Epoch 89/10000\n",
      "751/751 [==============================] - 0s 111us/step - loss: 0.1590 - binary_accuracy: 0.9601 - val_loss: 1.2294 - val_binary_accuracy: 0.5087\n",
      "Epoch 90/10000\n",
      "751/751 [==============================] - 0s 117us/step - loss: 0.1491 - binary_accuracy: 0.9680 - val_loss: 1.2907 - val_binary_accuracy: 0.4913\n",
      "Epoch 91/10000\n",
      "751/751 [==============================] - 0s 104us/step - loss: 0.1784 - binary_accuracy: 0.9454 - val_loss: 1.2253 - val_binary_accuracy: 0.5100\n",
      "Epoch 92/10000\n",
      "751/751 [==============================] - 0s 111us/step - loss: 0.1581 - binary_accuracy: 0.9627 - val_loss: 1.2138 - val_binary_accuracy: 0.5020\n",
      "Epoch 93/10000\n",
      "751/751 [==============================] - 0s 101us/step - loss: 0.1366 - binary_accuracy: 0.9734 - val_loss: 1.2072 - val_binary_accuracy: 0.4980\n",
      "Epoch 94/10000\n",
      "751/751 [==============================] - 0s 116us/step - loss: 0.1328 - binary_accuracy: 0.9760 - val_loss: 1.2194 - val_binary_accuracy: 0.4927\n",
      "Epoch 95/10000\n",
      "751/751 [==============================] - 0s 100us/step - loss: 0.1210 - binary_accuracy: 0.9827 - val_loss: 1.2422 - val_binary_accuracy: 0.5060\n",
      "Epoch 96/10000\n",
      "751/751 [==============================] - 0s 96us/step - loss: 0.1179 - binary_accuracy: 0.9840 - val_loss: 1.2545 - val_binary_accuracy: 0.5020\n",
      "Epoch 97/10000\n",
      "751/751 [==============================] - 0s 99us/step - loss: 0.1196 - binary_accuracy: 0.9840 - val_loss: 1.2756 - val_binary_accuracy: 0.5020\n",
      "Epoch 98/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 0.1215 - binary_accuracy: 0.9827 - val_loss: 1.2768 - val_binary_accuracy: 0.4940\n",
      "Epoch 99/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 0.1121 - binary_accuracy: 0.9880 - val_loss: 1.2751 - val_binary_accuracy: 0.4953\n",
      "Epoch 100/10000\n",
      "751/751 [==============================] - 0s 86us/step - loss: 0.1065 - binary_accuracy: 0.9907 - val_loss: 1.2864 - val_binary_accuracy: 0.5060\n",
      "Epoch 101/10000\n",
      "751/751 [==============================] - 0s 102us/step - loss: 0.1058 - binary_accuracy: 0.9893 - val_loss: 1.3007 - val_binary_accuracy: 0.4993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/10000\n",
      "751/751 [==============================] - 0s 93us/step - loss: 0.1029 - binary_accuracy: 0.9947 - val_loss: 1.3238 - val_binary_accuracy: 0.4860\n",
      "Epoch 103/10000\n",
      "751/751 [==============================] - 0s 88us/step - loss: 0.1051 - binary_accuracy: 0.9893 - val_loss: 1.3380 - val_binary_accuracy: 0.5060\n",
      "Epoch 104/10000\n",
      "751/751 [==============================] - 0s 83us/step - loss: 0.1072 - binary_accuracy: 0.9880 - val_loss: 1.3456 - val_binary_accuracy: 0.4847\n",
      "Epoch 105/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.1085 - binary_accuracy: 0.9814 - val_loss: 1.3295 - val_binary_accuracy: 0.5060\n",
      "Epoch 106/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.1020 - binary_accuracy: 0.9854 - val_loss: 1.3179 - val_binary_accuracy: 0.5033\n",
      "Epoch 107/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 0.0958 - binary_accuracy: 0.9933 - val_loss: 1.3356 - val_binary_accuracy: 0.5007\n",
      "Epoch 108/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0911 - binary_accuracy: 0.9933 - val_loss: 1.3616 - val_binary_accuracy: 0.4980\n",
      "Epoch 109/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0915 - binary_accuracy: 0.9920 - val_loss: 1.3766 - val_binary_accuracy: 0.4913\n",
      "Epoch 110/10000\n",
      "751/751 [==============================] - 0s 90us/step - loss: 0.0942 - binary_accuracy: 0.9867 - val_loss: 1.3904 - val_binary_accuracy: 0.5100\n",
      "Epoch 111/10000\n",
      "751/751 [==============================] - 0s 71us/step - loss: 0.0936 - binary_accuracy: 0.9907 - val_loss: 1.3941 - val_binary_accuracy: 0.4900\n",
      "Epoch 112/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0925 - binary_accuracy: 0.9893 - val_loss: 1.4060 - val_binary_accuracy: 0.4967\n",
      "Epoch 113/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0899 - binary_accuracy: 0.9947 - val_loss: 1.4202 - val_binary_accuracy: 0.4887\n",
      "Epoch 114/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0921 - binary_accuracy: 0.9893 - val_loss: 1.4088 - val_binary_accuracy: 0.5060\n",
      "Epoch 115/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.0789 - binary_accuracy: 0.9960 - val_loss: 1.4069 - val_binary_accuracy: 0.5007\n",
      "Epoch 116/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0772 - binary_accuracy: 0.9933 - val_loss: 1.4145 - val_binary_accuracy: 0.5033\n",
      "Epoch 117/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0715 - binary_accuracy: 0.9987 - val_loss: 1.4326 - val_binary_accuracy: 0.5033\n",
      "Epoch 118/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.0736 - binary_accuracy: 0.9973 - val_loss: 1.4425 - val_binary_accuracy: 0.4980\n",
      "Epoch 119/10000\n",
      "751/751 [==============================] - 0s 97us/step - loss: 0.0692 - binary_accuracy: 0.9973 - val_loss: 1.4552 - val_binary_accuracy: 0.4967\n",
      "Epoch 120/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 0.0680 - binary_accuracy: 1.0000 - val_loss: 1.4643 - val_binary_accuracy: 0.4940\n",
      "Epoch 121/10000\n",
      "751/751 [==============================] - 0s 87us/step - loss: 0.0703 - binary_accuracy: 0.9947 - val_loss: 1.4664 - val_binary_accuracy: 0.4967\n",
      "Epoch 122/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.0665 - binary_accuracy: 0.9987 - val_loss: 1.4704 - val_binary_accuracy: 0.5007\n",
      "Epoch 123/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0645 - binary_accuracy: 0.9973 - val_loss: 1.4797 - val_binary_accuracy: 0.4993\n",
      "Epoch 124/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0623 - binary_accuracy: 0.9973 - val_loss: 1.4991 - val_binary_accuracy: 0.4927\n",
      "Epoch 125/10000\n",
      "751/751 [==============================] - 0s 65us/step - loss: 0.0598 - binary_accuracy: 1.0000 - val_loss: 1.5043 - val_binary_accuracy: 0.4940\n",
      "Epoch 126/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0579 - binary_accuracy: 0.9987 - val_loss: 1.5095 - val_binary_accuracy: 0.5020\n",
      "Epoch 127/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0598 - binary_accuracy: 0.9987 - val_loss: 1.5184 - val_binary_accuracy: 0.5007\n",
      "Epoch 128/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0562 - binary_accuracy: 0.9973 - val_loss: 1.5234 - val_binary_accuracy: 0.5020\n",
      "Epoch 129/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0554 - binary_accuracy: 0.9987 - val_loss: 1.5254 - val_binary_accuracy: 0.5033\n",
      "Epoch 130/10000\n",
      "751/751 [==============================] - 0s 68us/step - loss: 0.0556 - binary_accuracy: 0.9987 - val_loss: 1.5483 - val_binary_accuracy: 0.4967\n",
      "Epoch 131/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 0.0535 - binary_accuracy: 1.0000 - val_loss: 1.5616 - val_binary_accuracy: 0.5020\n",
      "Epoch 132/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0505 - binary_accuracy: 1.0000 - val_loss: 1.5765 - val_binary_accuracy: 0.4927\n",
      "Epoch 133/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0525 - binary_accuracy: 0.9973 - val_loss: 1.5741 - val_binary_accuracy: 0.4913\n",
      "Epoch 134/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0487 - binary_accuracy: 1.0000 - val_loss: 1.6017 - val_binary_accuracy: 0.5073\n",
      "Epoch 135/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0528 - binary_accuracy: 0.9973 - val_loss: 1.6059 - val_binary_accuracy: 0.5007\n",
      "Epoch 136/10000\n",
      "751/751 [==============================] - 0s 87us/step - loss: 0.0537 - binary_accuracy: 0.9973 - val_loss: 1.6047 - val_binary_accuracy: 0.4993\n",
      "Epoch 137/10000\n",
      "751/751 [==============================] - 0s 102us/step - loss: 0.0502 - binary_accuracy: 0.9973 - val_loss: 1.5968 - val_binary_accuracy: 0.4927\n",
      "Epoch 138/10000\n",
      "751/751 [==============================] - 0s 109us/step - loss: 0.0461 - binary_accuracy: 1.0000 - val_loss: 1.6015 - val_binary_accuracy: 0.4940\n",
      "Epoch 139/10000\n",
      "751/751 [==============================] - 0s 120us/step - loss: 0.0439 - binary_accuracy: 1.0000 - val_loss: 1.6065 - val_binary_accuracy: 0.4953\n",
      "Epoch 140/10000\n",
      "751/751 [==============================] - 0s 122us/step - loss: 0.0429 - binary_accuracy: 0.9987 - val_loss: 1.6117 - val_binary_accuracy: 0.4993\n",
      "Epoch 141/10000\n",
      "751/751 [==============================] - 0s 126us/step - loss: 0.0408 - binary_accuracy: 1.0000 - val_loss: 1.6340 - val_binary_accuracy: 0.4980\n",
      "Epoch 142/10000\n",
      "751/751 [==============================] - 0s 131us/step - loss: 0.0487 - binary_accuracy: 0.9960 - val_loss: 1.6545 - val_binary_accuracy: 0.4980\n",
      "Epoch 143/10000\n",
      "751/751 [==============================] - 0s 113us/step - loss: 0.0478 - binary_accuracy: 0.9987 - val_loss: 1.6754 - val_binary_accuracy: 0.4900\n",
      "Epoch 144/10000\n",
      "751/751 [==============================] - 0s 125us/step - loss: 0.0436 - binary_accuracy: 1.0000 - val_loss: 1.6681 - val_binary_accuracy: 0.4940\n",
      "Epoch 145/10000\n",
      "751/751 [==============================] - 0s 132us/step - loss: 0.0410 - binary_accuracy: 1.0000 - val_loss: 1.6686 - val_binary_accuracy: 0.4913\n",
      "Epoch 146/10000\n",
      "751/751 [==============================] - 0s 138us/step - loss: 0.0409 - binary_accuracy: 1.0000 - val_loss: 1.6719 - val_binary_accuracy: 0.4993\n",
      "Epoch 147/10000\n",
      "751/751 [==============================] - 0s 140us/step - loss: 0.0369 - binary_accuracy: 1.0000 - val_loss: 1.6770 - val_binary_accuracy: 0.4967\n",
      "Epoch 148/10000\n",
      "751/751 [==============================] - 0s 123us/step - loss: 0.0358 - binary_accuracy: 1.0000 - val_loss: 1.6781 - val_binary_accuracy: 0.4980\n",
      "Epoch 149/10000\n",
      "751/751 [==============================] - 0s 102us/step - loss: 0.0358 - binary_accuracy: 1.0000 - val_loss: 1.6850 - val_binary_accuracy: 0.4993\n",
      "Epoch 150/10000\n",
      "751/751 [==============================] - 0s 108us/step - loss: 0.0351 - binary_accuracy: 1.0000 - val_loss: 1.7001 - val_binary_accuracy: 0.4913\n",
      "Epoch 151/10000\n",
      "751/751 [==============================] - 0s 99us/step - loss: 0.0333 - binary_accuracy: 1.0000 - val_loss: 1.7095 - val_binary_accuracy: 0.4900\n",
      "Epoch 152/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751/751 [==============================] - 0s 103us/step - loss: 0.0324 - binary_accuracy: 1.0000 - val_loss: 1.7209 - val_binary_accuracy: 0.4967\n",
      "Epoch 153/10000\n",
      "751/751 [==============================] - 0s 107us/step - loss: 0.0327 - binary_accuracy: 1.0000 - val_loss: 1.7249 - val_binary_accuracy: 0.4913\n",
      "Epoch 154/10000\n",
      "751/751 [==============================] - 0s 122us/step - loss: 0.0322 - binary_accuracy: 1.0000 - val_loss: 1.7314 - val_binary_accuracy: 0.4900\n",
      "Epoch 155/10000\n",
      "751/751 [==============================] - 0s 103us/step - loss: 0.0314 - binary_accuracy: 1.0000 - val_loss: 1.7509 - val_binary_accuracy: 0.4913\n",
      "Epoch 156/10000\n",
      "751/751 [==============================] - 0s 109us/step - loss: 0.0337 - binary_accuracy: 1.0000 - val_loss: 1.7449 - val_binary_accuracy: 0.4980\n",
      "Epoch 157/10000\n",
      "751/751 [==============================] - 0s 112us/step - loss: 0.0292 - binary_accuracy: 1.0000 - val_loss: 1.7501 - val_binary_accuracy: 0.4967\n",
      "Epoch 158/10000\n",
      "751/751 [==============================] - 0s 109us/step - loss: 0.0304 - binary_accuracy: 1.0000 - val_loss: 1.7552 - val_binary_accuracy: 0.4913\n",
      "Epoch 159/10000\n",
      "751/751 [==============================] - 0s 107us/step - loss: 0.0292 - binary_accuracy: 1.0000 - val_loss: 1.7744 - val_binary_accuracy: 0.4913\n",
      "Epoch 160/10000\n",
      "751/751 [==============================] - 0s 107us/step - loss: 0.0292 - binary_accuracy: 1.0000 - val_loss: 1.7843 - val_binary_accuracy: 0.4913\n",
      "Epoch 161/10000\n",
      "751/751 [==============================] - 0s 94us/step - loss: 0.0269 - binary_accuracy: 1.0000 - val_loss: 1.7904 - val_binary_accuracy: 0.4953\n",
      "Epoch 162/10000\n",
      "751/751 [==============================] - 0s 112us/step - loss: 0.0288 - binary_accuracy: 1.0000 - val_loss: 1.7980 - val_binary_accuracy: 0.4967\n",
      "Epoch 163/10000\n",
      "751/751 [==============================] - 0s 120us/step - loss: 0.0265 - binary_accuracy: 1.0000 - val_loss: 1.7983 - val_binary_accuracy: 0.4953\n",
      "Epoch 164/10000\n",
      "751/751 [==============================] - 0s 134us/step - loss: 0.0258 - binary_accuracy: 1.0000 - val_loss: 1.8051 - val_binary_accuracy: 0.4967\n",
      "Epoch 165/10000\n",
      "751/751 [==============================] - 0s 98us/step - loss: 0.0249 - binary_accuracy: 1.0000 - val_loss: 1.8179 - val_binary_accuracy: 0.4940\n",
      "Epoch 166/10000\n",
      "751/751 [==============================] - 0s 107us/step - loss: 0.0260 - binary_accuracy: 1.0000 - val_loss: 1.8160 - val_binary_accuracy: 0.4940\n",
      "Epoch 167/10000\n",
      "751/751 [==============================] - 0s 106us/step - loss: 0.0271 - binary_accuracy: 0.9987 - val_loss: 1.8254 - val_binary_accuracy: 0.4913\n",
      "Epoch 168/10000\n",
      "751/751 [==============================] - 0s 120us/step - loss: 0.0241 - binary_accuracy: 1.0000 - val_loss: 1.8370 - val_binary_accuracy: 0.4860\n",
      "Epoch 169/10000\n",
      "751/751 [==============================] - 0s 140us/step - loss: 0.0226 - binary_accuracy: 1.0000 - val_loss: 1.8443 - val_binary_accuracy: 0.4940\n",
      "Epoch 170/10000\n",
      "751/751 [==============================] - 0s 108us/step - loss: 0.0254 - binary_accuracy: 1.0000 - val_loss: 1.8423 - val_binary_accuracy: 0.4927\n",
      "Epoch 171/10000\n",
      "751/751 [==============================] - 0s 111us/step - loss: 0.0234 - binary_accuracy: 1.0000 - val_loss: 1.8473 - val_binary_accuracy: 0.4940\n",
      "Epoch 172/10000\n",
      "751/751 [==============================] - 0s 173us/step - loss: 0.0233 - binary_accuracy: 1.0000 - val_loss: 1.8548 - val_binary_accuracy: 0.4940\n",
      "Epoch 173/10000\n",
      "751/751 [==============================] - 0s 137us/step - loss: 0.0265 - binary_accuracy: 0.9987 - val_loss: 1.8598 - val_binary_accuracy: 0.4913\n",
      "Epoch 174/10000\n",
      "751/751 [==============================] - 0s 130us/step - loss: 0.0210 - binary_accuracy: 1.0000 - val_loss: 1.8691 - val_binary_accuracy: 0.4874\n",
      "Epoch 175/10000\n",
      "751/751 [==============================] - 0s 133us/step - loss: 0.0222 - binary_accuracy: 1.0000 - val_loss: 1.8711 - val_binary_accuracy: 0.4967\n",
      "Epoch 176/10000\n",
      "751/751 [==============================] - 0s 114us/step - loss: 0.0238 - binary_accuracy: 1.0000 - val_loss: 1.8747 - val_binary_accuracy: 0.4980\n",
      "Epoch 177/10000\n",
      "751/751 [==============================] - 0s 135us/step - loss: 0.0227 - binary_accuracy: 1.0000 - val_loss: 1.8797 - val_binary_accuracy: 0.5020\n",
      "Epoch 178/10000\n",
      "751/751 [==============================] - 0s 125us/step - loss: 0.0209 - binary_accuracy: 1.0000 - val_loss: 1.8873 - val_binary_accuracy: 0.4993\n",
      "Epoch 179/10000\n",
      "751/751 [==============================] - 0s 118us/step - loss: 0.0205 - binary_accuracy: 1.0000 - val_loss: 1.9057 - val_binary_accuracy: 0.4860\n",
      "Epoch 180/10000\n",
      "751/751 [==============================] - 0s 119us/step - loss: 0.0202 - binary_accuracy: 1.0000 - val_loss: 1.9119 - val_binary_accuracy: 0.5020\n",
      "Epoch 181/10000\n",
      "751/751 [==============================] - 0s 137us/step - loss: 0.0202 - binary_accuracy: 1.0000 - val_loss: 1.9182 - val_binary_accuracy: 0.4927\n",
      "Epoch 182/10000\n",
      "751/751 [==============================] - 0s 137us/step - loss: 0.0201 - binary_accuracy: 1.0000 - val_loss: 1.9206 - val_binary_accuracy: 0.4927\n",
      "Epoch 183/10000\n",
      "751/751 [==============================] - 0s 155us/step - loss: 0.0183 - binary_accuracy: 1.0000 - val_loss: 1.9275 - val_binary_accuracy: 0.4953\n",
      "Epoch 184/10000\n",
      "751/751 [==============================] - 0s 141us/step - loss: 0.0191 - binary_accuracy: 1.0000 - val_loss: 1.9384 - val_binary_accuracy: 0.4967\n",
      "Epoch 185/10000\n",
      "751/751 [==============================] - 0s 109us/step - loss: 0.0195 - binary_accuracy: 1.0000 - val_loss: 1.9461 - val_binary_accuracy: 0.4967\n",
      "Epoch 186/10000\n",
      "751/751 [==============================] - 0s 124us/step - loss: 0.0196 - binary_accuracy: 0.9987 - val_loss: 1.9405 - val_binary_accuracy: 0.5033\n",
      "Epoch 187/10000\n",
      "751/751 [==============================] - 0s 103us/step - loss: 0.0192 - binary_accuracy: 1.0000 - val_loss: 1.9422 - val_binary_accuracy: 0.4940\n",
      "Epoch 188/10000\n",
      "751/751 [==============================] - 0s 91us/step - loss: 0.0182 - binary_accuracy: 1.0000 - val_loss: 1.9538 - val_binary_accuracy: 0.4887\n",
      "Epoch 189/10000\n",
      "751/751 [==============================] - 0s 88us/step - loss: 0.0170 - binary_accuracy: 1.0000 - val_loss: 1.9569 - val_binary_accuracy: 0.4927\n",
      "Epoch 190/10000\n",
      "751/751 [==============================] - 0s 97us/step - loss: 0.0169 - binary_accuracy: 1.0000 - val_loss: 1.9590 - val_binary_accuracy: 0.4913\n",
      "Epoch 191/10000\n",
      "751/751 [==============================] - 0s 93us/step - loss: 0.0160 - binary_accuracy: 1.0000 - val_loss: 1.9694 - val_binary_accuracy: 0.5007\n",
      "Epoch 192/10000\n",
      "751/751 [==============================] - 0s 103us/step - loss: 0.0155 - binary_accuracy: 1.0000 - val_loss: 1.9827 - val_binary_accuracy: 0.4900\n",
      "Epoch 193/10000\n",
      "751/751 [==============================] - 0s 135us/step - loss: 0.0150 - binary_accuracy: 1.0000 - val_loss: 1.9894 - val_binary_accuracy: 0.4887\n",
      "Epoch 194/10000\n",
      "751/751 [==============================] - 0s 117us/step - loss: 0.0170 - binary_accuracy: 1.0000 - val_loss: 1.9959 - val_binary_accuracy: 0.4913\n",
      "Epoch 195/10000\n",
      "751/751 [==============================] - 0s 106us/step - loss: 0.0173 - binary_accuracy: 1.0000 - val_loss: 2.0063 - val_binary_accuracy: 0.4940\n",
      "Epoch 196/10000\n",
      "751/751 [==============================] - 0s 123us/step - loss: 0.0156 - binary_accuracy: 1.0000 - val_loss: 2.0051 - val_binary_accuracy: 0.4980\n",
      "Epoch 197/10000\n",
      "751/751 [==============================] - 0s 139us/step - loss: 0.0161 - binary_accuracy: 1.0000 - val_loss: 1.9991 - val_binary_accuracy: 0.5060\n",
      "Epoch 198/10000\n",
      "751/751 [==============================] - 0s 101us/step - loss: 0.0155 - binary_accuracy: 1.0000 - val_loss: 2.0183 - val_binary_accuracy: 0.4980\n",
      "Epoch 199/10000\n",
      "751/751 [==============================] - 0s 103us/step - loss: 0.0161 - binary_accuracy: 1.0000 - val_loss: 2.0280 - val_binary_accuracy: 0.5007\n",
      "Epoch 200/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0162 - binary_accuracy: 1.0000 - val_loss: 2.0180 - val_binary_accuracy: 0.4993\n",
      "Epoch 201/10000\n",
      "751/751 [==============================] - 0s 115us/step - loss: 0.0151 - binary_accuracy: 1.0000 - val_loss: 1.9966 - val_binary_accuracy: 0.4967\n",
      "Epoch 202/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751/751 [==============================] - 0s 145us/step - loss: 0.0158 - binary_accuracy: 1.0000 - val_loss: 2.0258 - val_binary_accuracy: 0.4940\n",
      "Epoch 203/10000\n",
      "751/751 [==============================] - 0s 123us/step - loss: 0.0130 - binary_accuracy: 1.0000 - val_loss: 2.0658 - val_binary_accuracy: 0.4980\n",
      "Epoch 204/10000\n",
      "751/751 [==============================] - 0s 101us/step - loss: 0.0142 - binary_accuracy: 1.0000 - val_loss: 2.0819 - val_binary_accuracy: 0.4927\n",
      "Epoch 205/10000\n",
      "751/751 [==============================] - 0s 104us/step - loss: 0.0142 - binary_accuracy: 1.0000 - val_loss: 2.0535 - val_binary_accuracy: 0.4993\n",
      "Epoch 206/10000\n",
      "751/751 [==============================] - 0s 179us/step - loss: 0.0129 - binary_accuracy: 1.0000 - val_loss: 2.0418 - val_binary_accuracy: 0.4967\n",
      "Epoch 207/10000\n",
      "751/751 [==============================] - 0s 157us/step - loss: 0.0139 - binary_accuracy: 1.0000 - val_loss: 2.0633 - val_binary_accuracy: 0.4927\n",
      "Epoch 208/10000\n",
      "751/751 [==============================] - 0s 135us/step - loss: 0.0126 - binary_accuracy: 1.0000 - val_loss: 2.0789 - val_binary_accuracy: 0.4860\n",
      "Epoch 209/10000\n",
      "751/751 [==============================] - 0s 100us/step - loss: 0.0130 - binary_accuracy: 1.0000 - val_loss: 2.0853 - val_binary_accuracy: 0.4887\n",
      "Epoch 210/10000\n",
      "751/751 [==============================] - 0s 106us/step - loss: 0.0135 - binary_accuracy: 1.0000 - val_loss: 2.0870 - val_binary_accuracy: 0.4967\n",
      "Epoch 211/10000\n",
      "751/751 [==============================] - 0s 135us/step - loss: 0.0120 - binary_accuracy: 1.0000 - val_loss: 2.0862 - val_binary_accuracy: 0.4927\n",
      "Epoch 212/10000\n",
      "751/751 [==============================] - 0s 131us/step - loss: 0.0115 - binary_accuracy: 1.0000 - val_loss: 2.0954 - val_binary_accuracy: 0.4953\n",
      "Epoch 213/10000\n",
      "751/751 [==============================] - 0s 125us/step - loss: 0.0123 - binary_accuracy: 1.0000 - val_loss: 2.1092 - val_binary_accuracy: 0.4967\n",
      "Epoch 214/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.0110 - binary_accuracy: 1.0000 - val_loss: 2.1130 - val_binary_accuracy: 0.4953\n",
      "Epoch 215/10000\n",
      "751/751 [==============================] - 0s 86us/step - loss: 0.0112 - binary_accuracy: 1.0000 - val_loss: 2.1126 - val_binary_accuracy: 0.4900\n",
      "Epoch 216/10000\n",
      "751/751 [==============================] - 0s 100us/step - loss: 0.0106 - binary_accuracy: 1.0000 - val_loss: 2.1171 - val_binary_accuracy: 0.4927\n",
      "Epoch 217/10000\n",
      "751/751 [==============================] - 0s 119us/step - loss: 0.0118 - binary_accuracy: 1.0000 - val_loss: 2.1201 - val_binary_accuracy: 0.4967\n",
      "Epoch 218/10000\n",
      "751/751 [==============================] - 0s 103us/step - loss: 0.0116 - binary_accuracy: 1.0000 - val_loss: 2.1307 - val_binary_accuracy: 0.4980\n",
      "Epoch 219/10000\n",
      "751/751 [==============================] - 0s 111us/step - loss: 0.0120 - binary_accuracy: 1.0000 - val_loss: 2.1386 - val_binary_accuracy: 0.4927\n",
      "Epoch 220/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 0.0116 - binary_accuracy: 1.0000 - val_loss: 2.1394 - val_binary_accuracy: 0.4887\n",
      "Epoch 221/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0108 - binary_accuracy: 1.0000 - val_loss: 2.1420 - val_binary_accuracy: 0.4913\n",
      "Epoch 222/10000\n",
      "751/751 [==============================] - 0s 83us/step - loss: 0.0106 - binary_accuracy: 1.0000 - val_loss: 2.1469 - val_binary_accuracy: 0.4927\n",
      "Epoch 223/10000\n",
      "751/751 [==============================] - 0s 92us/step - loss: 0.0111 - binary_accuracy: 1.0000 - val_loss: 2.1549 - val_binary_accuracy: 0.4940\n",
      "Epoch 224/10000\n",
      "751/751 [==============================] - 0s 92us/step - loss: 0.0122 - binary_accuracy: 0.9987 - val_loss: 2.1562 - val_binary_accuracy: 0.4993\n",
      "Epoch 225/10000\n",
      "751/751 [==============================] - 0s 101us/step - loss: 0.0099 - binary_accuracy: 1.0000 - val_loss: 2.1562 - val_binary_accuracy: 0.4940\n",
      "Epoch 226/10000\n",
      "751/751 [==============================] - 0s 99us/step - loss: 0.0106 - binary_accuracy: 1.0000 - val_loss: 2.1593 - val_binary_accuracy: 0.4953\n",
      "Epoch 227/10000\n",
      "751/751 [==============================] - 0s 122us/step - loss: 0.0106 - binary_accuracy: 1.0000 - val_loss: 2.1578 - val_binary_accuracy: 0.4927\n",
      "Epoch 228/10000\n",
      "751/751 [==============================] - 0s 188us/step - loss: 0.0107 - binary_accuracy: 1.0000 - val_loss: 2.1582 - val_binary_accuracy: 0.4953\n",
      "Epoch 229/10000\n",
      "751/751 [==============================] - 0s 111us/step - loss: 0.0100 - binary_accuracy: 1.0000 - val_loss: 2.1572 - val_binary_accuracy: 0.4913\n",
      "Epoch 230/10000\n",
      "751/751 [==============================] - 0s 131us/step - loss: 0.0097 - binary_accuracy: 1.0000 - val_loss: 2.1598 - val_binary_accuracy: 0.4953\n",
      "Epoch 231/10000\n",
      "751/751 [==============================] - 0s 108us/step - loss: 0.0102 - binary_accuracy: 1.0000 - val_loss: 2.1756 - val_binary_accuracy: 0.4887\n",
      "Epoch 232/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0099 - binary_accuracy: 1.0000 - val_loss: 2.1826 - val_binary_accuracy: 0.4927\n",
      "Epoch 233/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 0.0090 - binary_accuracy: 1.0000 - val_loss: 2.1919 - val_binary_accuracy: 0.4967\n",
      "Epoch 234/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0096 - binary_accuracy: 1.0000 - val_loss: 2.2051 - val_binary_accuracy: 0.4980\n",
      "Epoch 235/10000\n",
      "751/751 [==============================] - 0s 86us/step - loss: 0.0099 - binary_accuracy: 1.0000 - val_loss: 2.2049 - val_binary_accuracy: 0.4927\n",
      "Epoch 236/10000\n",
      "751/751 [==============================] - 0s 94us/step - loss: 0.0094 - binary_accuracy: 1.0000 - val_loss: 2.2014 - val_binary_accuracy: 0.4980\n",
      "Epoch 237/10000\n",
      "751/751 [==============================] - 0s 111us/step - loss: 0.0097 - binary_accuracy: 1.0000 - val_loss: 2.2053 - val_binary_accuracy: 0.5033\n",
      "Epoch 238/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 0.0099 - binary_accuracy: 1.0000 - val_loss: 2.2065 - val_binary_accuracy: 0.4913\n",
      "Epoch 239/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0100 - binary_accuracy: 1.0000 - val_loss: 2.2236 - val_binary_accuracy: 0.4953\n",
      "Epoch 240/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0092 - binary_accuracy: 1.0000 - val_loss: 2.2305 - val_binary_accuracy: 0.4913\n",
      "Epoch 241/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 0.0090 - binary_accuracy: 1.0000 - val_loss: 2.2342 - val_binary_accuracy: 0.4953\n",
      "Epoch 242/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 0.0086 - binary_accuracy: 1.0000 - val_loss: 2.2331 - val_binary_accuracy: 0.5047\n",
      "Epoch 243/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.0085 - binary_accuracy: 1.0000 - val_loss: 2.2438 - val_binary_accuracy: 0.4953\n",
      "Epoch 244/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 0.0102 - binary_accuracy: 1.0000 - val_loss: 2.2526 - val_binary_accuracy: 0.4993\n",
      "Epoch 245/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.0086 - binary_accuracy: 1.0000 - val_loss: 2.2559 - val_binary_accuracy: 0.5007\n",
      "Epoch 246/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0092 - binary_accuracy: 1.0000 - val_loss: 2.2543 - val_binary_accuracy: 0.4940\n",
      "Epoch 247/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0086 - binary_accuracy: 1.0000 - val_loss: 2.2497 - val_binary_accuracy: 0.4967\n",
      "Epoch 248/10000\n",
      "751/751 [==============================] - 0s 71us/step - loss: 0.0092 - binary_accuracy: 0.9987 - val_loss: 2.2469 - val_binary_accuracy: 0.4980\n",
      "Epoch 249/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0080 - binary_accuracy: 1.0000 - val_loss: 2.2681 - val_binary_accuracy: 0.5020\n",
      "Epoch 250/10000\n",
      "751/751 [==============================] - 0s 70us/step - loss: 0.0087 - binary_accuracy: 1.0000 - val_loss: 2.2780 - val_binary_accuracy: 0.4993\n",
      "Epoch 251/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0081 - binary_accuracy: 1.0000 - val_loss: 2.2980 - val_binary_accuracy: 0.4967\n",
      "Epoch 252/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751/751 [==============================] - 0s 80us/step - loss: 0.0090 - binary_accuracy: 1.0000 - val_loss: 2.2971 - val_binary_accuracy: 0.4940\n",
      "Epoch 253/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 0.0084 - binary_accuracy: 1.0000 - val_loss: 2.2928 - val_binary_accuracy: 0.4874\n",
      "Epoch 254/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0087 - binary_accuracy: 1.0000 - val_loss: 2.2990 - val_binary_accuracy: 0.5033\n",
      "Epoch 255/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0078 - binary_accuracy: 1.0000 - val_loss: 2.3036 - val_binary_accuracy: 0.5020\n",
      "Epoch 256/10000\n",
      "751/751 [==============================] - 0s 70us/step - loss: 0.0081 - binary_accuracy: 1.0000 - val_loss: 2.3003 - val_binary_accuracy: 0.4980\n",
      "Epoch 257/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0083 - binary_accuracy: 1.0000 - val_loss: 2.3020 - val_binary_accuracy: 0.4900\n",
      "Epoch 258/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 0.0075 - binary_accuracy: 1.0000 - val_loss: 2.3209 - val_binary_accuracy: 0.4913\n",
      "Epoch 259/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0074 - binary_accuracy: 1.0000 - val_loss: 2.3288 - val_binary_accuracy: 0.5020\n",
      "Epoch 260/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0089 - binary_accuracy: 0.9987 - val_loss: 2.3155 - val_binary_accuracy: 0.4900\n",
      "Epoch 261/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0072 - binary_accuracy: 1.0000 - val_loss: 2.3099 - val_binary_accuracy: 0.4940\n",
      "Epoch 262/10000\n",
      "751/751 [==============================] - 0s 101us/step - loss: 0.0071 - binary_accuracy: 1.0000 - val_loss: 2.3127 - val_binary_accuracy: 0.4913\n",
      "Epoch 263/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0070 - binary_accuracy: 1.0000 - val_loss: 2.3245 - val_binary_accuracy: 0.4967\n",
      "Epoch 264/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 0.0072 - binary_accuracy: 1.0000 - val_loss: 2.3366 - val_binary_accuracy: 0.5007\n",
      "Epoch 265/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0078 - binary_accuracy: 1.0000 - val_loss: 2.3355 - val_binary_accuracy: 0.5033\n",
      "Epoch 266/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0070 - binary_accuracy: 1.0000 - val_loss: 2.3254 - val_binary_accuracy: 0.4940\n",
      "Epoch 267/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0068 - binary_accuracy: 1.0000 - val_loss: 2.3181 - val_binary_accuracy: 0.5020\n",
      "Epoch 268/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0072 - binary_accuracy: 1.0000 - val_loss: 2.3225 - val_binary_accuracy: 0.5007\n",
      "Epoch 269/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0068 - binary_accuracy: 1.0000 - val_loss: 2.3391 - val_binary_accuracy: 0.5047\n",
      "Epoch 270/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0063 - binary_accuracy: 1.0000 - val_loss: 2.3690 - val_binary_accuracy: 0.5020\n",
      "Epoch 271/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 0.0070 - binary_accuracy: 1.0000 - val_loss: 2.3887 - val_binary_accuracy: 0.4913\n",
      "Epoch 272/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0069 - binary_accuracy: 1.0000 - val_loss: 2.3946 - val_binary_accuracy: 0.4940\n",
      "Epoch 273/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 0.0067 - binary_accuracy: 1.0000 - val_loss: 2.3652 - val_binary_accuracy: 0.4900\n",
      "Epoch 274/10000\n",
      "751/751 [==============================] - 0s 70us/step - loss: 0.0065 - binary_accuracy: 1.0000 - val_loss: 2.3538 - val_binary_accuracy: 0.4993\n",
      "Epoch 275/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0066 - binary_accuracy: 1.0000 - val_loss: 2.3700 - val_binary_accuracy: 0.4967\n",
      "Epoch 276/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0065 - binary_accuracy: 1.0000 - val_loss: 2.3877 - val_binary_accuracy: 0.4980\n",
      "Epoch 277/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0068 - binary_accuracy: 1.0000 - val_loss: 2.3793 - val_binary_accuracy: 0.4980\n",
      "Epoch 278/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0061 - binary_accuracy: 1.0000 - val_loss: 2.3863 - val_binary_accuracy: 0.4953\n",
      "Epoch 279/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.0058 - binary_accuracy: 1.0000 - val_loss: 2.3891 - val_binary_accuracy: 0.4980\n",
      "Epoch 280/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0057 - binary_accuracy: 1.0000 - val_loss: 2.3964 - val_binary_accuracy: 0.4953\n",
      "Epoch 281/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0058 - binary_accuracy: 1.0000 - val_loss: 2.4007 - val_binary_accuracy: 0.4967\n",
      "Epoch 282/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0054 - binary_accuracy: 1.0000 - val_loss: 2.4029 - val_binary_accuracy: 0.4953\n",
      "Epoch 283/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 0.0064 - binary_accuracy: 1.0000 - val_loss: 2.4113 - val_binary_accuracy: 0.4913\n",
      "Epoch 284/10000\n",
      "751/751 [==============================] - 0s 71us/step - loss: 0.0052 - binary_accuracy: 1.0000 - val_loss: 2.4090 - val_binary_accuracy: 0.4953\n",
      "Epoch 285/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 0.0058 - binary_accuracy: 1.0000 - val_loss: 2.4166 - val_binary_accuracy: 0.4980\n",
      "Epoch 286/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0061 - binary_accuracy: 1.0000 - val_loss: 2.4136 - val_binary_accuracy: 0.4940\n",
      "Epoch 287/10000\n",
      "751/751 [==============================] - 0s 90us/step - loss: 0.0054 - binary_accuracy: 1.0000 - val_loss: 2.4158 - val_binary_accuracy: 0.4913\n",
      "Epoch 288/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0057 - binary_accuracy: 1.0000 - val_loss: 2.4204 - val_binary_accuracy: 0.4967\n",
      "Epoch 289/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0051 - binary_accuracy: 1.0000 - val_loss: 2.4284 - val_binary_accuracy: 0.4967\n",
      "Epoch 290/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0052 - binary_accuracy: 1.0000 - val_loss: 2.4310 - val_binary_accuracy: 0.4980\n",
      "Epoch 291/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0055 - binary_accuracy: 1.0000 - val_loss: 2.4354 - val_binary_accuracy: 0.4980\n",
      "Epoch 292/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 0.0052 - binary_accuracy: 1.0000 - val_loss: 2.4431 - val_binary_accuracy: 0.4940\n",
      "Epoch 293/10000\n",
      "751/751 [==============================] - 0s 139us/step - loss: 0.0047 - binary_accuracy: 1.0000 - val_loss: 2.4461 - val_binary_accuracy: 0.4967\n",
      "Epoch 294/10000\n",
      "751/751 [==============================] - 0s 123us/step - loss: 0.0048 - binary_accuracy: 1.0000 - val_loss: 2.4498 - val_binary_accuracy: 0.4927\n",
      "Epoch 295/10000\n",
      "751/751 [==============================] - 0s 89us/step - loss: 0.0057 - binary_accuracy: 1.0000 - val_loss: 2.4704 - val_binary_accuracy: 0.5007\n",
      "Epoch 296/10000\n",
      "751/751 [==============================] - 0s 92us/step - loss: 0.0051 - binary_accuracy: 1.0000 - val_loss: 2.4801 - val_binary_accuracy: 0.4980\n",
      "Epoch 297/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0049 - binary_accuracy: 1.0000 - val_loss: 2.4750 - val_binary_accuracy: 0.4980\n",
      "Epoch 298/10000\n",
      "751/751 [==============================] - 0s 124us/step - loss: 0.0051 - binary_accuracy: 1.0000 - val_loss: 2.4628 - val_binary_accuracy: 0.4927\n",
      "Epoch 299/10000\n",
      "751/751 [==============================] - 0s 157us/step - loss: 0.0046 - binary_accuracy: 1.0000 - val_loss: 2.4611 - val_binary_accuracy: 0.4967\n",
      "Epoch 300/10000\n",
      "751/751 [==============================] - 0s 145us/step - loss: 0.0053 - binary_accuracy: 1.0000 - val_loss: 2.4672 - val_binary_accuracy: 0.4967\n",
      "Epoch 301/10000\n",
      "751/751 [==============================] - 0s 100us/step - loss: 0.0047 - binary_accuracy: 1.0000 - val_loss: 2.4826 - val_binary_accuracy: 0.5007\n",
      "Epoch 302/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751/751 [==============================] - 0s 93us/step - loss: 0.0047 - binary_accuracy: 1.0000 - val_loss: 2.4866 - val_binary_accuracy: 0.4967\n",
      "Epoch 303/10000\n",
      "751/751 [==============================] - 0s 107us/step - loss: 0.0047 - binary_accuracy: 1.0000 - val_loss: 2.4795 - val_binary_accuracy: 0.4953\n",
      "Epoch 304/10000\n",
      "751/751 [==============================] - 0s 83us/step - loss: 0.0041 - binary_accuracy: 1.0000 - val_loss: 2.4759 - val_binary_accuracy: 0.4980\n",
      "Epoch 305/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0046 - binary_accuracy: 1.0000 - val_loss: 2.4735 - val_binary_accuracy: 0.4980\n",
      "Epoch 306/10000\n",
      "751/751 [==============================] - 0s 88us/step - loss: 0.0045 - binary_accuracy: 1.0000 - val_loss: 2.4846 - val_binary_accuracy: 0.4953\n",
      "Epoch 307/10000\n",
      "751/751 [==============================] - 0s 89us/step - loss: 0.0045 - binary_accuracy: 1.0000 - val_loss: 2.4988 - val_binary_accuracy: 0.4967\n",
      "Epoch 308/10000\n",
      "751/751 [==============================] - 0s 89us/step - loss: 0.0045 - binary_accuracy: 1.0000 - val_loss: 2.5175 - val_binary_accuracy: 0.4993\n",
      "Epoch 309/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0046 - binary_accuracy: 1.0000 - val_loss: 2.5260 - val_binary_accuracy: 0.4940\n",
      "Epoch 310/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0044 - binary_accuracy: 1.0000 - val_loss: 2.5154 - val_binary_accuracy: 0.4967\n",
      "Epoch 311/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0041 - binary_accuracy: 1.0000 - val_loss: 2.5079 - val_binary_accuracy: 0.4993\n",
      "Epoch 312/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0044 - binary_accuracy: 1.0000 - val_loss: 2.5012 - val_binary_accuracy: 0.5033\n",
      "Epoch 313/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 0.0042 - binary_accuracy: 1.0000 - val_loss: 2.5047 - val_binary_accuracy: 0.5047\n",
      "Epoch 314/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0038 - binary_accuracy: 1.0000 - val_loss: 2.5133 - val_binary_accuracy: 0.5047\n",
      "Epoch 315/10000\n",
      "751/751 [==============================] - 0s 90us/step - loss: 0.0039 - binary_accuracy: 1.0000 - val_loss: 2.5179 - val_binary_accuracy: 0.5007\n",
      "Epoch 316/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0042 - binary_accuracy: 1.0000 - val_loss: 2.5160 - val_binary_accuracy: 0.5033\n",
      "Epoch 317/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0057 - binary_accuracy: 0.9987 - val_loss: 2.5346 - val_binary_accuracy: 0.5007\n",
      "Epoch 318/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0054 - binary_accuracy: 1.0000 - val_loss: 2.5405 - val_binary_accuracy: 0.4993\n",
      "Epoch 319/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 0.0056 - binary_accuracy: 1.0000 - val_loss: 2.5287 - val_binary_accuracy: 0.4900\n",
      "Epoch 320/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0061 - binary_accuracy: 1.0000 - val_loss: 2.5353 - val_binary_accuracy: 0.4940\n",
      "Epoch 321/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0052 - binary_accuracy: 1.0000 - val_loss: 2.5322 - val_binary_accuracy: 0.5007\n",
      "Epoch 322/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0061 - binary_accuracy: 1.0000 - val_loss: 2.5371 - val_binary_accuracy: 0.4967\n",
      "Epoch 323/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0063 - binary_accuracy: 1.0000 - val_loss: 2.5468 - val_binary_accuracy: 0.4940\n",
      "Epoch 324/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0052 - binary_accuracy: 1.0000 - val_loss: 2.5415 - val_binary_accuracy: 0.4874\n",
      "Epoch 325/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 0.0044 - binary_accuracy: 1.0000 - val_loss: 2.5307 - val_binary_accuracy: 0.5007\n",
      "Epoch 326/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 0.0048 - binary_accuracy: 1.0000 - val_loss: 2.5361 - val_binary_accuracy: 0.4940\n",
      "Epoch 327/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0046 - binary_accuracy: 1.0000 - val_loss: 2.5361 - val_binary_accuracy: 0.4940\n",
      "Epoch 328/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0043 - binary_accuracy: 1.0000 - val_loss: 2.5558 - val_binary_accuracy: 0.4900\n",
      "Epoch 329/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0047 - binary_accuracy: 1.0000 - val_loss: 2.5403 - val_binary_accuracy: 0.5047\n",
      "Epoch 330/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.0047 - binary_accuracy: 1.0000 - val_loss: 2.5297 - val_binary_accuracy: 0.4927\n",
      "Epoch 331/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0041 - binary_accuracy: 1.0000 - val_loss: 2.5387 - val_binary_accuracy: 0.4993\n",
      "Epoch 332/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.0049 - binary_accuracy: 1.0000 - val_loss: 2.5604 - val_binary_accuracy: 0.5020\n",
      "Epoch 333/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 0.0041 - binary_accuracy: 1.0000 - val_loss: 2.5656 - val_binary_accuracy: 0.5047\n",
      "Epoch 334/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0046 - binary_accuracy: 1.0000 - val_loss: 2.5633 - val_binary_accuracy: 0.4993\n",
      "Epoch 335/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0042 - binary_accuracy: 1.0000 - val_loss: 2.5610 - val_binary_accuracy: 0.5007\n",
      "Epoch 336/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 0.0055 - binary_accuracy: 1.0000 - val_loss: 2.5738 - val_binary_accuracy: 0.4993\n",
      "Epoch 337/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0049 - binary_accuracy: 1.0000 - val_loss: 2.5610 - val_binary_accuracy: 0.4927\n",
      "Epoch 338/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0101 - binary_accuracy: 0.9987 - val_loss: 2.5940 - val_binary_accuracy: 0.4967\n",
      "Epoch 339/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0104 - binary_accuracy: 0.9987 - val_loss: 2.6627 - val_binary_accuracy: 0.4900\n",
      "Epoch 340/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 0.0072 - binary_accuracy: 0.9987 - val_loss: 2.6456 - val_binary_accuracy: 0.4927\n",
      "Epoch 341/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0074 - binary_accuracy: 1.0000 - val_loss: 2.6198 - val_binary_accuracy: 0.4860\n",
      "Epoch 342/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0071 - binary_accuracy: 1.0000 - val_loss: 2.5714 - val_binary_accuracy: 0.5033\n",
      "Epoch 343/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0074 - binary_accuracy: 1.0000 - val_loss: 2.5932 - val_binary_accuracy: 0.5020\n",
      "Epoch 344/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0065 - binary_accuracy: 1.0000 - val_loss: 2.6268 - val_binary_accuracy: 0.4940\n",
      "Epoch 345/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 0.0055 - binary_accuracy: 1.0000 - val_loss: 2.6136 - val_binary_accuracy: 0.4980\n",
      "Epoch 346/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0042 - binary_accuracy: 1.0000 - val_loss: 2.6122 - val_binary_accuracy: 0.5007\n",
      "Epoch 347/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0049 - binary_accuracy: 1.0000 - val_loss: 2.6048 - val_binary_accuracy: 0.5033\n",
      "Epoch 348/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0044 - binary_accuracy: 1.0000 - val_loss: 2.6247 - val_binary_accuracy: 0.4953\n",
      "Epoch 349/10000\n",
      "751/751 [==============================] - 0s 83us/step - loss: 0.0038 - binary_accuracy: 1.0000 - val_loss: 2.6309 - val_binary_accuracy: 0.4913\n",
      "Epoch 350/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0041 - binary_accuracy: 1.0000 - val_loss: 2.6234 - val_binary_accuracy: 0.5020\n",
      "Epoch 351/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0033 - binary_accuracy: 1.0000 - val_loss: 2.6287 - val_binary_accuracy: 0.4980\n",
      "Epoch 352/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 0.0046 - binary_accuracy: 1.0000 - val_loss: 2.6258 - val_binary_accuracy: 0.4993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 0.0040 - binary_accuracy: 1.0000 - val_loss: 2.6087 - val_binary_accuracy: 0.4927\n",
      "Epoch 354/10000\n",
      "751/751 [==============================] - 0s 69us/step - loss: 0.0035 - binary_accuracy: 1.0000 - val_loss: 2.6191 - val_binary_accuracy: 0.4993\n",
      "Epoch 355/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0033 - binary_accuracy: 1.0000 - val_loss: 2.6540 - val_binary_accuracy: 0.5020\n",
      "Epoch 356/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 2.6695 - val_binary_accuracy: 0.4993\n",
      "Epoch 357/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0029 - binary_accuracy: 1.0000 - val_loss: 2.6737 - val_binary_accuracy: 0.4953\n",
      "Epoch 358/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0028 - binary_accuracy: 1.0000 - val_loss: 2.6709 - val_binary_accuracy: 0.4953\n",
      "Epoch 359/10000\n",
      "751/751 [==============================] - 0s 71us/step - loss: 0.0032 - binary_accuracy: 1.0000 - val_loss: 2.6665 - val_binary_accuracy: 0.4913\n",
      "Epoch 360/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0026 - binary_accuracy: 1.0000 - val_loss: 2.6628 - val_binary_accuracy: 0.4993\n",
      "Epoch 361/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 2.6633 - val_binary_accuracy: 0.4980\n",
      "Epoch 362/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 0.0029 - binary_accuracy: 1.0000 - val_loss: 2.6730 - val_binary_accuracy: 0.5020\n",
      "Epoch 363/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0044 - binary_accuracy: 0.9987 - val_loss: 2.6981 - val_binary_accuracy: 0.4967\n",
      "Epoch 364/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0033 - binary_accuracy: 1.0000 - val_loss: 2.6938 - val_binary_accuracy: 0.5020\n",
      "Epoch 365/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 0.0038 - binary_accuracy: 1.0000 - val_loss: 2.7088 - val_binary_accuracy: 0.4953\n",
      "Epoch 366/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 0.0034 - binary_accuracy: 1.0000 - val_loss: 2.6920 - val_binary_accuracy: 0.4967\n",
      "Epoch 367/10000\n",
      "751/751 [==============================] - 0s 70us/step - loss: 0.0034 - binary_accuracy: 1.0000 - val_loss: 2.6938 - val_binary_accuracy: 0.4980\n",
      "Epoch 368/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0040 - binary_accuracy: 0.9987 - val_loss: 2.7174 - val_binary_accuracy: 0.4927\n",
      "Epoch 369/10000\n",
      "751/751 [==============================] - 0s 71us/step - loss: 0.0040 - binary_accuracy: 1.0000 - val_loss: 2.6744 - val_binary_accuracy: 0.4927\n",
      "Epoch 370/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 0.0039 - binary_accuracy: 1.0000 - val_loss: 2.6757 - val_binary_accuracy: 0.5047\n",
      "Epoch 371/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0035 - binary_accuracy: 1.0000 - val_loss: 2.7047 - val_binary_accuracy: 0.5007\n",
      "Epoch 372/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 2.7554 - val_binary_accuracy: 0.4927\n",
      "Epoch 373/10000\n",
      "751/751 [==============================] - 0s 88us/step - loss: 0.0038 - binary_accuracy: 1.0000 - val_loss: 2.7377 - val_binary_accuracy: 0.4980\n",
      "Epoch 374/10000\n",
      "751/751 [==============================] - 0s 96us/step - loss: 0.0035 - binary_accuracy: 1.0000 - val_loss: 2.7177 - val_binary_accuracy: 0.4980\n",
      "Epoch 375/10000\n",
      "751/751 [==============================] - 0s 87us/step - loss: 0.0031 - binary_accuracy: 1.0000 - val_loss: 2.7031 - val_binary_accuracy: 0.4967\n",
      "Epoch 376/10000\n",
      "751/751 [==============================] - 0s 71us/step - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 2.7097 - val_binary_accuracy: 0.4980\n",
      "Epoch 377/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0035 - binary_accuracy: 1.0000 - val_loss: 2.7054 - val_binary_accuracy: 0.5007\n",
      "Epoch 378/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 0.0026 - binary_accuracy: 1.0000 - val_loss: 2.7253 - val_binary_accuracy: 0.4940\n",
      "Epoch 379/10000\n",
      "751/751 [==============================] - 0s 88us/step - loss: 0.0029 - binary_accuracy: 1.0000 - val_loss: 2.7379 - val_binary_accuracy: 0.5047\n",
      "Epoch 380/10000\n",
      "751/751 [==============================] - 0s 94us/step - loss: 0.0027 - binary_accuracy: 1.0000 - val_loss: 2.7605 - val_binary_accuracy: 0.4967\n",
      "Epoch 381/10000\n",
      "751/751 [==============================] - 0s 108us/step - loss: 0.0027 - binary_accuracy: 1.0000 - val_loss: 2.7651 - val_binary_accuracy: 0.4940\n",
      "Epoch 382/10000\n",
      "751/751 [==============================] - 0s 96us/step - loss: 0.0027 - binary_accuracy: 1.0000 - val_loss: 2.7593 - val_binary_accuracy: 0.4980\n",
      "Epoch 383/10000\n",
      "751/751 [==============================] - 0s 89us/step - loss: 0.0026 - binary_accuracy: 1.0000 - val_loss: 2.7567 - val_binary_accuracy: 0.4967\n",
      "Epoch 384/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 0.0025 - binary_accuracy: 1.0000 - val_loss: 2.7569 - val_binary_accuracy: 0.5007\n",
      "Epoch 385/10000\n",
      "751/751 [==============================] - 0s 128us/step - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 2.7609 - val_binary_accuracy: 0.4860\n",
      "Epoch 386/10000\n",
      "751/751 [==============================] - 0s 101us/step - loss: 0.0053 - binary_accuracy: 0.9987 - val_loss: 2.7923 - val_binary_accuracy: 0.4953\n",
      "Epoch 387/10000\n",
      "751/751 [==============================] - 0s 103us/step - loss: 0.0035 - binary_accuracy: 1.0000 - val_loss: 2.7959 - val_binary_accuracy: 0.4913\n",
      "Epoch 388/10000\n",
      "751/751 [==============================] - 0s 115us/step - loss: 0.0045 - binary_accuracy: 1.0000 - val_loss: 2.7835 - val_binary_accuracy: 0.4887\n",
      "Epoch 389/10000\n",
      "751/751 [==============================] - 0s 106us/step - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 2.7854 - val_binary_accuracy: 0.4847\n",
      "Epoch 390/10000\n",
      "751/751 [==============================] - 0s 107us/step - loss: 0.0064 - binary_accuracy: 0.9987 - val_loss: 2.8702 - val_binary_accuracy: 0.4927\n",
      "Epoch 391/10000\n",
      "751/751 [==============================] - 0s 107us/step - loss: 0.0045 - binary_accuracy: 1.0000 - val_loss: 2.8734 - val_binary_accuracy: 0.4847\n",
      "Epoch 392/10000\n",
      "751/751 [==============================] - 0s 126us/step - loss: 0.0040 - binary_accuracy: 1.0000 - val_loss: 2.8041 - val_binary_accuracy: 0.5007\n",
      "Epoch 393/10000\n",
      "751/751 [==============================] - 0s 158us/step - loss: 0.0043 - binary_accuracy: 1.0000 - val_loss: 2.7279 - val_binary_accuracy: 0.4967\n",
      "Epoch 394/10000\n",
      "751/751 [==============================] - 0s 192us/step - loss: 0.0044 - binary_accuracy: 1.0000 - val_loss: 2.7047 - val_binary_accuracy: 0.4967\n",
      "Epoch 395/10000\n",
      "751/751 [==============================] - 0s 133us/step - loss: 0.0031 - binary_accuracy: 1.0000 - val_loss: 2.7099 - val_binary_accuracy: 0.4993\n",
      "Epoch 396/10000\n",
      "751/751 [==============================] - 0s 124us/step - loss: 0.0029 - binary_accuracy: 1.0000 - val_loss: 2.7258 - val_binary_accuracy: 0.5020\n",
      "Epoch 397/10000\n",
      "751/751 [==============================] - 0s 103us/step - loss: 0.0035 - binary_accuracy: 1.0000 - val_loss: 2.7408 - val_binary_accuracy: 0.5047\n",
      "Epoch 398/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0025 - binary_accuracy: 1.0000 - val_loss: 2.7547 - val_binary_accuracy: 0.4980\n",
      "Epoch 399/10000\n",
      "751/751 [==============================] - 0s 89us/step - loss: 0.0028 - binary_accuracy: 1.0000 - val_loss: 2.7675 - val_binary_accuracy: 0.5007\n",
      "Epoch 400/10000\n",
      "751/751 [==============================] - 0s 86us/step - loss: 0.0024 - binary_accuracy: 1.0000 - val_loss: 2.7745 - val_binary_accuracy: 0.4953\n",
      "Epoch 401/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 2.7847 - val_binary_accuracy: 0.4900\n",
      "Epoch 402/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0024 - binary_accuracy: 1.0000 - val_loss: 2.8081 - val_binary_accuracy: 0.4967\n",
      "Epoch 403/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751/751 [==============================] - 0s 82us/step - loss: 0.0027 - binary_accuracy: 1.0000 - val_loss: 2.8184 - val_binary_accuracy: 0.4940\n",
      "Epoch 404/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 2.8342 - val_binary_accuracy: 0.5007\n",
      "Epoch 405/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 2.8298 - val_binary_accuracy: 0.4927\n",
      "Epoch 406/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 2.8330 - val_binary_accuracy: 0.4953\n",
      "Epoch 407/10000\n",
      "751/751 [==============================] - 0s 114us/step - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 2.8271 - val_binary_accuracy: 0.4913\n",
      "Epoch 408/10000\n",
      "751/751 [==============================] - 0s 92us/step - loss: 0.0022 - binary_accuracy: 1.0000 - val_loss: 2.8233 - val_binary_accuracy: 0.4940\n",
      "Epoch 409/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 2.8183 - val_binary_accuracy: 0.4900\n",
      "Epoch 410/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0025 - binary_accuracy: 1.0000 - val_loss: 2.8214 - val_binary_accuracy: 0.4940\n",
      "Epoch 411/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0022 - binary_accuracy: 1.0000 - val_loss: 2.8188 - val_binary_accuracy: 0.5033\n",
      "Epoch 412/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 0.0024 - binary_accuracy: 1.0000 - val_loss: 2.8180 - val_binary_accuracy: 0.5033\n",
      "Epoch 413/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0019 - binary_accuracy: 1.0000 - val_loss: 2.8253 - val_binary_accuracy: 0.5033\n",
      "Epoch 414/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 0.0019 - binary_accuracy: 1.0000 - val_loss: 2.8317 - val_binary_accuracy: 0.5047\n",
      "Epoch 415/10000\n",
      "751/751 [==============================] - 0s 71us/step - loss: 0.0018 - binary_accuracy: 1.0000 - val_loss: 2.8327 - val_binary_accuracy: 0.5033\n",
      "Epoch 416/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 2.8372 - val_binary_accuracy: 0.4913\n",
      "Epoch 417/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 0.0018 - binary_accuracy: 1.0000 - val_loss: 2.8465 - val_binary_accuracy: 0.4953\n",
      "Epoch 418/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 2.8548 - val_binary_accuracy: 0.4940\n",
      "Epoch 419/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 2.8558 - val_binary_accuracy: 0.4953\n",
      "Epoch 420/10000\n",
      "751/751 [==============================] - 0s 109us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 2.8514 - val_binary_accuracy: 0.4927\n",
      "Epoch 421/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 2.8478 - val_binary_accuracy: 0.4993\n",
      "Epoch 422/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 0.0046 - binary_accuracy: 0.9987 - val_loss: 2.8941 - val_binary_accuracy: 0.4953\n",
      "Epoch 423/10000\n",
      "751/751 [==============================] - 0s 114us/step - loss: 0.0055 - binary_accuracy: 0.9987 - val_loss: 2.9062 - val_binary_accuracy: 0.4847\n",
      "Epoch 424/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0048 - binary_accuracy: 1.0000 - val_loss: 2.8424 - val_binary_accuracy: 0.4874\n",
      "Epoch 425/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 0.0061 - binary_accuracy: 1.0000 - val_loss: 2.8618 - val_binary_accuracy: 0.4900\n",
      "Epoch 426/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 0.0054 - binary_accuracy: 1.0000 - val_loss: 2.8336 - val_binary_accuracy: 0.4874\n",
      "Epoch 427/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.0075 - binary_accuracy: 0.9987 - val_loss: 2.7924 - val_binary_accuracy: 0.4980\n",
      "Epoch 428/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0045 - binary_accuracy: 1.0000 - val_loss: 2.7443 - val_binary_accuracy: 0.4913\n",
      "Epoch 429/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0048 - binary_accuracy: 1.0000 - val_loss: 2.7765 - val_binary_accuracy: 0.4900\n",
      "Epoch 430/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0034 - binary_accuracy: 1.0000 - val_loss: 2.8422 - val_binary_accuracy: 0.4874\n",
      "Epoch 431/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 2.8987 - val_binary_accuracy: 0.4887\n",
      "Epoch 432/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0041 - binary_accuracy: 1.0000 - val_loss: 2.8949 - val_binary_accuracy: 0.4900\n",
      "Epoch 433/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 2.8456 - val_binary_accuracy: 0.4913\n",
      "Epoch 434/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0024 - binary_accuracy: 1.0000 - val_loss: 2.8120 - val_binary_accuracy: 0.4940\n",
      "Epoch 435/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0025 - binary_accuracy: 1.0000 - val_loss: 2.8068 - val_binary_accuracy: 0.4993\n",
      "Epoch 436/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 0.0028 - binary_accuracy: 1.0000 - val_loss: 2.8335 - val_binary_accuracy: 0.4980\n",
      "Epoch 437/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 2.8457 - val_binary_accuracy: 0.5007\n",
      "Epoch 438/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 0.0022 - binary_accuracy: 1.0000 - val_loss: 2.8597 - val_binary_accuracy: 0.4967\n",
      "Epoch 439/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 2.8605 - val_binary_accuracy: 0.4940\n",
      "Epoch 440/10000\n",
      "751/751 [==============================] - 0s 89us/step - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 2.8632 - val_binary_accuracy: 0.4927\n",
      "Epoch 441/10000\n",
      "751/751 [==============================] - 0s 97us/step - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 2.8676 - val_binary_accuracy: 0.4913\n",
      "Epoch 442/10000\n",
      "751/751 [==============================] - 0s 90us/step - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 2.8696 - val_binary_accuracy: 0.4980\n",
      "Epoch 443/10000\n",
      "751/751 [==============================] - 0s 99us/step - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 2.8780 - val_binary_accuracy: 0.4900\n",
      "Epoch 444/10000\n",
      "751/751 [==============================] - 0s 105us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 2.8943 - val_binary_accuracy: 0.4940\n",
      "Epoch 445/10000\n",
      "751/751 [==============================] - 0s 97us/step - loss: 0.0018 - binary_accuracy: 1.0000 - val_loss: 2.9018 - val_binary_accuracy: 0.4993\n",
      "Epoch 446/10000\n",
      "751/751 [==============================] - 0s 86us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 2.8989 - val_binary_accuracy: 0.4993\n",
      "Epoch 447/10000\n",
      "751/751 [==============================] - 0s 103us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 2.8861 - val_binary_accuracy: 0.4967\n",
      "Epoch 448/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 2.8885 - val_binary_accuracy: 0.4980\n",
      "Epoch 449/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 2.9004 - val_binary_accuracy: 0.4940\n",
      "Epoch 450/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0018 - binary_accuracy: 1.0000 - val_loss: 2.9169 - val_binary_accuracy: 0.4940\n",
      "Epoch 451/10000\n",
      "751/751 [==============================] - 0s 127us/step - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 2.9294 - val_binary_accuracy: 0.4953\n",
      "Epoch 452/10000\n",
      "751/751 [==============================] - 0s 114us/step - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 2.9237 - val_binary_accuracy: 0.5033\n",
      "Epoch 453/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751/751 [==============================] - 0s 119us/step - loss: 0.0027 - binary_accuracy: 1.0000 - val_loss: 2.9263 - val_binary_accuracy: 0.4940\n",
      "Epoch 454/10000\n",
      "751/751 [==============================] - 0s 87us/step - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 2.8854 - val_binary_accuracy: 0.4980\n",
      "Epoch 455/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 2.8810 - val_binary_accuracy: 0.4927\n",
      "Epoch 456/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 2.8996 - val_binary_accuracy: 0.4887\n",
      "Epoch 457/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 2.9092 - val_binary_accuracy: 0.4913\n",
      "Epoch 458/10000\n",
      "751/751 [==============================] - 0s 95us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 2.9283 - val_binary_accuracy: 0.4980\n",
      "Epoch 459/10000\n",
      "751/751 [==============================] - 0s 106us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 2.9294 - val_binary_accuracy: 0.4967\n",
      "Epoch 460/10000\n",
      "751/751 [==============================] - 0s 92us/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 2.9218 - val_binary_accuracy: 0.4993\n",
      "Epoch 461/10000\n",
      "751/751 [==============================] - 0s 88us/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 2.9084 - val_binary_accuracy: 0.4940\n",
      "Epoch 462/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 2.9067 - val_binary_accuracy: 0.4953\n",
      "Epoch 463/10000\n",
      "751/751 [==============================] - 0s 86us/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 2.9091 - val_binary_accuracy: 0.4967\n",
      "Epoch 464/10000\n",
      "751/751 [==============================] - 0s 90us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 2.9123 - val_binary_accuracy: 0.4927\n",
      "Epoch 465/10000\n",
      "751/751 [==============================] - 0s 122us/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 2.9268 - val_binary_accuracy: 0.4967\n",
      "Epoch 466/10000\n",
      "751/751 [==============================] - 0s 87us/step - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 2.9413 - val_binary_accuracy: 0.4887\n",
      "Epoch 467/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 2.9558 - val_binary_accuracy: 0.4980\n",
      "Epoch 468/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 2.9498 - val_binary_accuracy: 0.4927\n",
      "Epoch 469/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 2.9570 - val_binary_accuracy: 0.4900\n",
      "Epoch 470/10000\n",
      "751/751 [==============================] - 0s 86us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 2.9359 - val_binary_accuracy: 0.4887\n",
      "Epoch 471/10000\n",
      "751/751 [==============================] - 0s 104us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 2.9591 - val_binary_accuracy: 0.5007\n",
      "Epoch 472/10000\n",
      "751/751 [==============================] - 0s 140us/step - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 2.9690 - val_binary_accuracy: 0.4993\n",
      "Epoch 473/10000\n",
      "751/751 [==============================] - ETA: 0s - loss: 0.0024 - binary_accuracy: 1.000 - 0s 119us/step - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 2.9671 - val_binary_accuracy: 0.5047\n",
      "Epoch 474/10000\n",
      "751/751 [==============================] - 0s 125us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 2.9744 - val_binary_accuracy: 0.5020\n",
      "Epoch 475/10000\n",
      "751/751 [==============================] - 0s 100us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 2.9539 - val_binary_accuracy: 0.5047\n",
      "Epoch 476/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 2.9634 - val_binary_accuracy: 0.4900\n",
      "Epoch 477/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 2.9926 - val_binary_accuracy: 0.4980\n",
      "Epoch 478/10000\n",
      "751/751 [==============================] - 0s 100us/step - loss: 0.0019 - binary_accuracy: 1.0000 - val_loss: 2.9892 - val_binary_accuracy: 0.4913\n",
      "Epoch 479/10000\n",
      "751/751 [==============================] - 0s 97us/step - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 3.0003 - val_binary_accuracy: 0.4927\n",
      "Epoch 480/10000\n",
      "751/751 [==============================] - 0s 86us/step - loss: 0.0032 - binary_accuracy: 0.9987 - val_loss: 2.9443 - val_binary_accuracy: 0.4913\n",
      "Epoch 481/10000\n",
      "751/751 [==============================] - 0s 89us/step - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 2.9002 - val_binary_accuracy: 0.4940\n",
      "Epoch 482/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0037 - binary_accuracy: 0.9987 - val_loss: 2.9266 - val_binary_accuracy: 0.5020\n",
      "Epoch 483/10000\n",
      "751/751 [==============================] - 0s 89us/step - loss: 0.0031 - binary_accuracy: 1.0000 - val_loss: 2.9541 - val_binary_accuracy: 0.4993\n",
      "Epoch 484/10000\n",
      "751/751 [==============================] - 0s 87us/step - loss: 0.0026 - binary_accuracy: 1.0000 - val_loss: 2.9394 - val_binary_accuracy: 0.5033\n",
      "Epoch 485/10000\n",
      "751/751 [==============================] - 0s 86us/step - loss: 0.0041 - binary_accuracy: 1.0000 - val_loss: 2.9402 - val_binary_accuracy: 0.4967\n",
      "Epoch 486/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0032 - binary_accuracy: 1.0000 - val_loss: 2.9466 - val_binary_accuracy: 0.4980\n",
      "Epoch 487/10000\n",
      "751/751 [==============================] - 0s 86us/step - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 2.9457 - val_binary_accuracy: 0.5007\n",
      "Epoch 488/10000\n",
      "751/751 [==============================] - 0s 86us/step - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 2.9578 - val_binary_accuracy: 0.4874\n",
      "Epoch 489/10000\n",
      "751/751 [==============================] - 0s 86us/step - loss: 0.0027 - binary_accuracy: 1.0000 - val_loss: 2.9529 - val_binary_accuracy: 0.4887\n",
      "Epoch 490/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 2.9593 - val_binary_accuracy: 0.4993\n",
      "Epoch 491/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.0019 - binary_accuracy: 1.0000 - val_loss: 2.9695 - val_binary_accuracy: 0.5020\n",
      "Epoch 492/10000\n",
      "751/751 [==============================] - 0s 91us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 2.9868 - val_binary_accuracy: 0.4980\n",
      "Epoch 493/10000\n",
      "751/751 [==============================] - 0s 90us/step - loss: 0.0026 - binary_accuracy: 1.0000 - val_loss: 2.9814 - val_binary_accuracy: 0.5007\n",
      "Epoch 494/10000\n",
      "751/751 [==============================] - 0s 87us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 2.9670 - val_binary_accuracy: 0.4993\n",
      "Epoch 495/10000\n",
      "751/751 [==============================] - 0s 89us/step - loss: 0.0024 - binary_accuracy: 1.0000 - val_loss: 2.9937 - val_binary_accuracy: 0.4980\n",
      "Epoch 496/10000\n",
      "751/751 [==============================] - 0s 93us/step - loss: 0.0025 - binary_accuracy: 1.0000 - val_loss: 2.9606 - val_binary_accuracy: 0.4953\n",
      "Epoch 497/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 2.9424 - val_binary_accuracy: 0.5020\n",
      "Epoch 498/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 0.0028 - binary_accuracy: 1.0000 - val_loss: 2.9608 - val_binary_accuracy: 0.4953\n",
      "Epoch 499/10000\n",
      "751/751 [==============================] - 0s 97us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 2.9764 - val_binary_accuracy: 0.4953\n",
      "Epoch 500/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 2.9718 - val_binary_accuracy: 0.4913\n",
      "Epoch 501/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0018 - binary_accuracy: 1.0000 - val_loss: 2.9701 - val_binary_accuracy: 0.5033\n",
      "Epoch 502/10000\n",
      "751/751 [==============================] - 0s 91us/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 2.9828 - val_binary_accuracy: 0.4967\n",
      "Epoch 503/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751/751 [==============================] - 0s 77us/step - loss: 0.0018 - binary_accuracy: 1.0000 - val_loss: 3.0035 - val_binary_accuracy: 0.4967\n",
      "Epoch 504/10000\n",
      "751/751 [==============================] - 0s 88us/step - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 3.0093 - val_binary_accuracy: 0.5007\n",
      "Epoch 505/10000\n",
      "751/751 [==============================] - 0s 86us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 3.0110 - val_binary_accuracy: 0.4967\n",
      "Epoch 506/10000\n",
      "751/751 [==============================] - 0s 92us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 3.0232 - val_binary_accuracy: 0.4953\n",
      "Epoch 507/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 3.0205 - val_binary_accuracy: 0.5033\n",
      "Epoch 508/10000\n",
      "751/751 [==============================] - 0s 89us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 3.0172 - val_binary_accuracy: 0.5047\n",
      "Epoch 509/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 3.0156 - val_binary_accuracy: 0.4980\n",
      "Epoch 510/10000\n",
      "751/751 [==============================] - 0s 86us/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 2.9977 - val_binary_accuracy: 0.5007\n",
      "Epoch 511/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 2.9985 - val_binary_accuracy: 0.5033\n",
      "Epoch 512/10000\n",
      "751/751 [==============================] - 0s 95us/step - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 3.0100 - val_binary_accuracy: 0.5033\n",
      "Epoch 513/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.0296 - val_binary_accuracy: 0.5020\n",
      "Epoch 514/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 3.0430 - val_binary_accuracy: 0.5033\n",
      "Epoch 515/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 3.0567 - val_binary_accuracy: 0.4967\n",
      "Epoch 516/10000\n",
      "751/751 [==============================] - 0s 111us/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 3.0644 - val_binary_accuracy: 0.5007\n",
      "Epoch 517/10000\n",
      "751/751 [==============================] - 0s 95us/step - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 3.0792 - val_binary_accuracy: 0.4900\n",
      "Epoch 518/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 3.0871 - val_binary_accuracy: 0.4940\n",
      "Epoch 519/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 3.1036 - val_binary_accuracy: 0.4967\n",
      "Epoch 520/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 0.0010 - binary_accuracy: 1.0000 - val_loss: 3.1157 - val_binary_accuracy: 0.4980\n",
      "Epoch 521/10000\n",
      "751/751 [==============================] - 0s 96us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 3.1461 - val_binary_accuracy: 0.4967\n",
      "Epoch 522/10000\n",
      "751/751 [==============================] - 0s 90us/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 3.0984 - val_binary_accuracy: 0.5060\n",
      "Epoch 523/10000\n",
      "751/751 [==============================] - 0s 87us/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 3.0835 - val_binary_accuracy: 0.4980\n",
      "Epoch 524/10000\n",
      "751/751 [==============================] - 0s 106us/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 3.0706 - val_binary_accuracy: 0.4940\n",
      "Epoch 525/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.0749 - val_binary_accuracy: 0.4940\n",
      "Epoch 526/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 3.0564 - val_binary_accuracy: 0.5007\n",
      "Epoch 527/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 3.0676 - val_binary_accuracy: 0.4913\n",
      "Epoch 528/10000\n",
      "751/751 [==============================] - 0s 83us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 3.0801 - val_binary_accuracy: 0.5020\n",
      "Epoch 529/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 3.0903 - val_binary_accuracy: 0.4940\n",
      "Epoch 530/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 3.1256 - val_binary_accuracy: 0.4940\n",
      "Epoch 531/10000\n",
      "751/751 [==============================] - 0s 92us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 3.1527 - val_binary_accuracy: 0.5047\n",
      "Epoch 532/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 3.1418 - val_binary_accuracy: 0.4980\n",
      "Epoch 533/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 3.1474 - val_binary_accuracy: 0.4993\n",
      "Epoch 534/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 3.0757 - val_binary_accuracy: 0.5033\n",
      "Epoch 535/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 3.0835 - val_binary_accuracy: 0.4980\n",
      "Epoch 536/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 3.0910 - val_binary_accuracy: 0.4967\n",
      "Epoch 537/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 3.0890 - val_binary_accuracy: 0.4927\n",
      "Epoch 538/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 3.1067 - val_binary_accuracy: 0.5020\n",
      "Epoch 539/10000\n",
      "751/751 [==============================] - 0s 83us/step - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 3.1004 - val_binary_accuracy: 0.5007\n",
      "Epoch 540/10000\n",
      "751/751 [==============================] - 0s 83us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.1013 - val_binary_accuracy: 0.5073\n",
      "Epoch 541/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0027 - binary_accuracy: 0.9987 - val_loss: 3.1394 - val_binary_accuracy: 0.5047\n",
      "Epoch 542/10000\n",
      "751/751 [==============================] - 0s 87us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 3.1492 - val_binary_accuracy: 0.4953\n",
      "Epoch 543/10000\n",
      "751/751 [==============================] - 0s 90us/step - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 3.1803 - val_binary_accuracy: 0.4913\n",
      "Epoch 544/10000\n",
      "751/751 [==============================] - 0s 83us/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 3.1336 - val_binary_accuracy: 0.5073\n",
      "Epoch 545/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0019 - binary_accuracy: 1.0000 - val_loss: 3.1250 - val_binary_accuracy: 0.5007\n",
      "Epoch 546/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.1600 - val_binary_accuracy: 0.4940\n",
      "Epoch 547/10000\n",
      "751/751 [==============================] - 0s 88us/step - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 3.1405 - val_binary_accuracy: 0.4967\n",
      "Epoch 548/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0010 - binary_accuracy: 1.0000 - val_loss: 3.1469 - val_binary_accuracy: 0.4874\n",
      "Epoch 549/10000\n",
      "751/751 [==============================] - 0s 87us/step - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 3.1555 - val_binary_accuracy: 0.4927\n",
      "Epoch 550/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.1879 - val_binary_accuracy: 0.4913\n",
      "Epoch 551/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.1619 - val_binary_accuracy: 0.4953\n",
      "Epoch 552/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0026 - binary_accuracy: 0.9987 - val_loss: 3.1671 - val_binary_accuracy: 0.4940\n",
      "Epoch 553/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751/751 [==============================] - 0s 84us/step - loss: 0.0025 - binary_accuracy: 1.0000 - val_loss: 3.2050 - val_binary_accuracy: 0.5047\n",
      "Epoch 554/10000\n",
      "751/751 [==============================] - 0s 86us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 3.1369 - val_binary_accuracy: 0.4953\n",
      "Epoch 555/10000\n",
      "751/751 [==============================] - 0s 83us/step - loss: 0.0022 - binary_accuracy: 1.0000 - val_loss: 3.1100 - val_binary_accuracy: 0.4993\n",
      "Epoch 556/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 3.1342 - val_binary_accuracy: 0.5020\n",
      "Epoch 557/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 3.1486 - val_binary_accuracy: 0.5007\n",
      "Epoch 558/10000\n",
      "751/751 [==============================] - 0s 83us/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 3.1618 - val_binary_accuracy: 0.4913\n",
      "Epoch 559/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 3.1635 - val_binary_accuracy: 0.4887\n",
      "Epoch 560/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0010 - binary_accuracy: 1.0000 - val_loss: 3.1711 - val_binary_accuracy: 0.4927\n",
      "Epoch 561/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 3.1752 - val_binary_accuracy: 0.4927\n",
      "Epoch 562/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 9.5084e-04 - binary_accuracy: 1.0000 - val_loss: 3.1719 - val_binary_accuracy: 0.4953\n",
      "Epoch 563/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 3.1576 - val_binary_accuracy: 0.4980\n",
      "Epoch 564/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 8.4606e-04 - binary_accuracy: 1.0000 - val_loss: 3.1396 - val_binary_accuracy: 0.5100\n",
      "Epoch 565/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0018 - binary_accuracy: 1.0000 - val_loss: 3.1409 - val_binary_accuracy: 0.4927\n",
      "Epoch 566/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 3.1673 - val_binary_accuracy: 0.4860\n",
      "Epoch 567/10000\n",
      "751/751 [==============================] - 0s 71us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.1583 - val_binary_accuracy: 0.5033\n",
      "Epoch 568/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 3.1566 - val_binary_accuracy: 0.5007\n",
      "Epoch 569/10000\n",
      "751/751 [==============================] - 0s 69us/step - loss: 0.0018 - binary_accuracy: 1.0000 - val_loss: 3.1789 - val_binary_accuracy: 0.4980\n",
      "Epoch 570/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 3.1330 - val_binary_accuracy: 0.5007\n",
      "Epoch 571/10000\n",
      "751/751 [==============================] - 0s 87us/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 3.1464 - val_binary_accuracy: 0.4900\n",
      "Epoch 572/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.0019 - binary_accuracy: 1.0000 - val_loss: 3.1582 - val_binary_accuracy: 0.4927\n",
      "Epoch 573/10000\n",
      "751/751 [==============================] - 0s 99us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 3.1694 - val_binary_accuracy: 0.4967\n",
      "Epoch 574/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 3.1559 - val_binary_accuracy: 0.5020\n",
      "Epoch 575/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0010 - binary_accuracy: 1.0000 - val_loss: 3.1243 - val_binary_accuracy: 0.5020\n",
      "Epoch 576/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.1101 - val_binary_accuracy: 0.4993\n",
      "Epoch 577/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.1152 - val_binary_accuracy: 0.5033\n",
      "Epoch 578/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 3.1528 - val_binary_accuracy: 0.4927\n",
      "Epoch 579/10000\n",
      "751/751 [==============================] - 0s 91us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.1562 - val_binary_accuracy: 0.4927\n",
      "Epoch 580/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 3.1702 - val_binary_accuracy: 0.4927\n",
      "Epoch 581/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 3.1915 - val_binary_accuracy: 0.4940\n",
      "Epoch 582/10000\n",
      "751/751 [==============================] - 0s 92us/step - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 3.1687 - val_binary_accuracy: 0.5007\n",
      "Epoch 583/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 3.2044 - val_binary_accuracy: 0.4927\n",
      "Epoch 584/10000\n",
      "751/751 [==============================] - 0s 83us/step - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 3.2843 - val_binary_accuracy: 0.4874\n",
      "Epoch 585/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0024 - binary_accuracy: 1.0000 - val_loss: 3.1853 - val_binary_accuracy: 0.5073\n",
      "Epoch 586/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 0.0033 - binary_accuracy: 0.9987 - val_loss: 3.1755 - val_binary_accuracy: 0.5033\n",
      "Epoch 587/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 0.0019 - binary_accuracy: 1.0000 - val_loss: 3.2603 - val_binary_accuracy: 0.4980\n",
      "Epoch 588/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0084 - binary_accuracy: 0.9973 - val_loss: 3.1687 - val_binary_accuracy: 0.5033\n",
      "Epoch 589/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 0.0061 - binary_accuracy: 1.0000 - val_loss: 3.1506 - val_binary_accuracy: 0.5060\n",
      "Epoch 590/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.0060 - binary_accuracy: 1.0000 - val_loss: 3.2120 - val_binary_accuracy: 0.4900\n",
      "Epoch 591/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0060 - binary_accuracy: 0.9987 - val_loss: 3.2091 - val_binary_accuracy: 0.4940\n",
      "Epoch 592/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0085 - binary_accuracy: 0.9987 - val_loss: 3.3825 - val_binary_accuracy: 0.4794\n",
      "Epoch 593/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0265 - binary_accuracy: 0.9907 - val_loss: 3.3431 - val_binary_accuracy: 0.4953\n",
      "Epoch 594/10000\n",
      "751/751 [==============================] - 0s 70us/step - loss: 0.0209 - binary_accuracy: 0.9920 - val_loss: 3.3251 - val_binary_accuracy: 0.4940\n",
      "Epoch 595/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 0.0333 - binary_accuracy: 0.9920 - val_loss: 3.1976 - val_binary_accuracy: 0.4993\n",
      "Epoch 596/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0541 - binary_accuracy: 0.9840 - val_loss: 3.0749 - val_binary_accuracy: 0.5033\n",
      "Epoch 597/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 0.0367 - binary_accuracy: 0.9827 - val_loss: 3.4672 - val_binary_accuracy: 0.5033\n",
      "Epoch 598/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.2011 - binary_accuracy: 0.9241 - val_loss: 3.1072 - val_binary_accuracy: 0.5100\n",
      "Epoch 599/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.1015 - binary_accuracy: 0.9574 - val_loss: 3.3841 - val_binary_accuracy: 0.5007\n",
      "Epoch 600/10000\n",
      "751/751 [==============================] - 0s 68us/step - loss: 0.1479 - binary_accuracy: 0.9427 - val_loss: 3.1154 - val_binary_accuracy: 0.4754\n",
      "Epoch 601/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.1373 - binary_accuracy: 0.9441 - val_loss: 3.9812 - val_binary_accuracy: 0.5060\n",
      "Epoch 602/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.4540 - binary_accuracy: 0.8375 - val_loss: 2.8981 - val_binary_accuracy: 0.5100\n",
      "Epoch 603/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751/751 [==============================] - 0s 70us/step - loss: 0.2518 - binary_accuracy: 0.9095 - val_loss: 2.5875 - val_binary_accuracy: 0.5153\n",
      "Epoch 604/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 0.2129 - binary_accuracy: 0.9041 - val_loss: 2.5106 - val_binary_accuracy: 0.5033\n",
      "Epoch 605/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.2182 - binary_accuracy: 0.9001 - val_loss: 2.4702 - val_binary_accuracy: 0.5100\n",
      "Epoch 606/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.1846 - binary_accuracy: 0.9241 - val_loss: 2.5460 - val_binary_accuracy: 0.5073\n",
      "Epoch 607/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0797 - binary_accuracy: 0.9707 - val_loss: 3.0974 - val_binary_accuracy: 0.5007\n",
      "Epoch 608/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.1184 - binary_accuracy: 0.9521 - val_loss: 2.4327 - val_binary_accuracy: 0.4953\n",
      "Epoch 609/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0817 - binary_accuracy: 0.9694 - val_loss: 2.4030 - val_binary_accuracy: 0.4913\n",
      "Epoch 610/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0332 - binary_accuracy: 0.9947 - val_loss: 2.5462 - val_binary_accuracy: 0.4900\n",
      "Epoch 611/10000\n",
      "751/751 [==============================] - 0s 70us/step - loss: 0.0496 - binary_accuracy: 0.9854 - val_loss: 2.5020 - val_binary_accuracy: 0.5033\n",
      "Epoch 612/10000\n",
      "751/751 [==============================] - 0s 88us/step - loss: 0.0163 - binary_accuracy: 1.0000 - val_loss: 2.6193 - val_binary_accuracy: 0.4900\n",
      "Epoch 613/10000\n",
      "751/751 [==============================] - 0s 97us/step - loss: 0.0301 - binary_accuracy: 0.9960 - val_loss: 2.5584 - val_binary_accuracy: 0.4967\n",
      "Epoch 614/10000\n",
      "751/751 [==============================] - 0s 102us/step - loss: 0.0092 - binary_accuracy: 1.0000 - val_loss: 2.6136 - val_binary_accuracy: 0.4887\n",
      "Epoch 615/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 0.0191 - binary_accuracy: 0.9987 - val_loss: 2.6548 - val_binary_accuracy: 0.4887\n",
      "Epoch 616/10000\n",
      "751/751 [==============================] - 0s 68us/step - loss: 0.0111 - binary_accuracy: 0.9987 - val_loss: 2.6323 - val_binary_accuracy: 0.4980\n",
      "Epoch 617/10000\n",
      "751/751 [==============================] - 0s 86us/step - loss: 0.0075 - binary_accuracy: 1.0000 - val_loss: 2.7031 - val_binary_accuracy: 0.4980\n",
      "Epoch 618/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 0.0099 - binary_accuracy: 1.0000 - val_loss: 2.7033 - val_binary_accuracy: 0.5007\n",
      "Epoch 619/10000\n",
      "751/751 [==============================] - 0s 68us/step - loss: 0.0057 - binary_accuracy: 0.9987 - val_loss: 2.7448 - val_binary_accuracy: 0.4927\n",
      "Epoch 620/10000\n",
      "751/751 [==============================] - 0s 68us/step - loss: 0.0049 - binary_accuracy: 1.0000 - val_loss: 2.8013 - val_binary_accuracy: 0.4980\n",
      "Epoch 621/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 0.0048 - binary_accuracy: 1.0000 - val_loss: 2.8130 - val_binary_accuracy: 0.4900\n",
      "Epoch 622/10000\n",
      "751/751 [==============================] - 0s 64us/step - loss: 0.0059 - binary_accuracy: 0.9987 - val_loss: 2.8100 - val_binary_accuracy: 0.4900\n",
      "Epoch 623/10000\n",
      "751/751 [==============================] - 0s 64us/step - loss: 0.0036 - binary_accuracy: 1.0000 - val_loss: 2.8199 - val_binary_accuracy: 0.4967\n",
      "Epoch 624/10000\n",
      "751/751 [==============================] - 0s 55us/step - loss: 0.0035 - binary_accuracy: 1.0000 - val_loss: 2.8365 - val_binary_accuracy: 0.4980\n",
      "Epoch 625/10000\n",
      "751/751 [==============================] - 0s 61us/step - loss: 0.0037 - binary_accuracy: 1.0000 - val_loss: 2.8528 - val_binary_accuracy: 0.4967\n",
      "Epoch 626/10000\n",
      "751/751 [==============================] - 0s 59us/step - loss: 0.0028 - binary_accuracy: 1.0000 - val_loss: 2.8692 - val_binary_accuracy: 0.4940\n",
      "Epoch 627/10000\n",
      "751/751 [==============================] - 0s 60us/step - loss: 0.0028 - binary_accuracy: 1.0000 - val_loss: 2.8883 - val_binary_accuracy: 0.4913\n",
      "Epoch 628/10000\n",
      "751/751 [==============================] - 0s 96us/step - loss: 0.0046 - binary_accuracy: 0.9987 - val_loss: 2.9030 - val_binary_accuracy: 0.4927\n",
      "Epoch 629/10000\n",
      "751/751 [==============================] - 0s 64us/step - loss: 0.0024 - binary_accuracy: 1.0000 - val_loss: 2.9201 - val_binary_accuracy: 0.4967\n",
      "Epoch 630/10000\n",
      "751/751 [==============================] - 0s 144us/step - loss: 0.0026 - binary_accuracy: 1.0000 - val_loss: 2.9349 - val_binary_accuracy: 0.4967\n",
      "Epoch 631/10000\n",
      "751/751 [==============================] - 0s 106us/step - loss: 0.0026 - binary_accuracy: 1.0000 - val_loss: 2.9435 - val_binary_accuracy: 0.4940\n",
      "Epoch 632/10000\n",
      "751/751 [==============================] - 0s 108us/step - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 2.9509 - val_binary_accuracy: 0.4913\n",
      "Epoch 633/10000\n",
      "751/751 [==============================] - 0s 96us/step - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 2.9593 - val_binary_accuracy: 0.4953\n",
      "Epoch 634/10000\n",
      "751/751 [==============================] - 0s 90us/step - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 2.9633 - val_binary_accuracy: 0.4967\n",
      "Epoch 635/10000\n",
      "751/751 [==============================] - 0s 102us/step - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 2.9684 - val_binary_accuracy: 0.4953\n",
      "Epoch 636/10000\n",
      "751/751 [==============================] - 0s 134us/step - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 2.9725 - val_binary_accuracy: 0.4967\n",
      "Epoch 637/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 2.9776 - val_binary_accuracy: 0.5007\n",
      "Epoch 638/10000\n",
      "751/751 [==============================] - 0s 95us/step - loss: 0.0022 - binary_accuracy: 1.0000 - val_loss: 2.9835 - val_binary_accuracy: 0.4993\n",
      "Epoch 639/10000\n",
      "751/751 [==============================] - 0s 110us/step - loss: 0.0019 - binary_accuracy: 1.0000 - val_loss: 2.9888 - val_binary_accuracy: 0.4993\n",
      "Epoch 640/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0019 - binary_accuracy: 1.0000 - val_loss: 2.9935 - val_binary_accuracy: 0.5007\n",
      "Epoch 641/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 2.9997 - val_binary_accuracy: 0.4980\n",
      "Epoch 642/10000\n",
      "751/751 [==============================] - 0s 110us/step - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 3.0046 - val_binary_accuracy: 0.4953\n",
      "Epoch 643/10000\n",
      "751/751 [==============================] - 0s 153us/step - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 3.0090 - val_binary_accuracy: 0.4980\n",
      "Epoch 644/10000\n",
      "751/751 [==============================] - 0s 146us/step - loss: 0.0018 - binary_accuracy: 1.0000 - val_loss: 3.0134 - val_binary_accuracy: 0.5007\n",
      "Epoch 645/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 3.0188 - val_binary_accuracy: 0.5007\n",
      "Epoch 646/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0019 - binary_accuracy: 1.0000 - val_loss: 3.0231 - val_binary_accuracy: 0.5007\n",
      "Epoch 647/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 3.0263 - val_binary_accuracy: 0.5007\n",
      "Epoch 648/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 3.0308 - val_binary_accuracy: 0.5020\n",
      "Epoch 649/10000\n",
      "751/751 [==============================] - 0s 93us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 3.0348 - val_binary_accuracy: 0.5033\n",
      "Epoch 650/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0019 - binary_accuracy: 1.0000 - val_loss: 3.0406 - val_binary_accuracy: 0.5047\n",
      "Epoch 651/10000\n",
      "751/751 [==============================] - 0s 69us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 3.0469 - val_binary_accuracy: 0.5047\n",
      "Epoch 652/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 3.0533 - val_binary_accuracy: 0.5060\n",
      "Epoch 653/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751/751 [==============================] - 0s 69us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 3.0601 - val_binary_accuracy: 0.5033\n",
      "Epoch 654/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 3.0666 - val_binary_accuracy: 0.5047\n",
      "Epoch 655/10000\n",
      "751/751 [==============================] - 0s 97us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 3.0713 - val_binary_accuracy: 0.5060\n",
      "Epoch 656/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 3.0746 - val_binary_accuracy: 0.5020\n",
      "Epoch 657/10000\n",
      "751/751 [==============================] - 0s 97us/step - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 3.0791 - val_binary_accuracy: 0.5020\n",
      "Epoch 658/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 3.0819 - val_binary_accuracy: 0.5020\n",
      "Epoch 659/10000\n",
      "751/751 [==============================] - 0s 83us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 3.0830 - val_binary_accuracy: 0.5020\n",
      "Epoch 660/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 3.0859 - val_binary_accuracy: 0.5033\n",
      "Epoch 661/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 3.0895 - val_binary_accuracy: 0.5047\n",
      "Epoch 662/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 3.0924 - val_binary_accuracy: 0.5033\n",
      "Epoch 663/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0022 - binary_accuracy: 1.0000 - val_loss: 3.0970 - val_binary_accuracy: 0.5007\n",
      "Epoch 664/10000\n",
      "751/751 [==============================] - 0s 69us/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 3.1020 - val_binary_accuracy: 0.5047\n",
      "Epoch 665/10000\n",
      "751/751 [==============================] - 0s 102us/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 3.1063 - val_binary_accuracy: 0.5060\n",
      "Epoch 666/10000\n",
      "751/751 [==============================] - 0s 108us/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 3.1083 - val_binary_accuracy: 0.5047\n",
      "Epoch 667/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 3.1104 - val_binary_accuracy: 0.5033\n",
      "Epoch 668/10000\n",
      "751/751 [==============================] - 0s 112us/step - loss: 0.0018 - binary_accuracy: 1.0000 - val_loss: 3.1128 - val_binary_accuracy: 0.5060\n",
      "Epoch 669/10000\n",
      "751/751 [==============================] - 0s 96us/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 3.1169 - val_binary_accuracy: 0.5033\n",
      "Epoch 670/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 3.1198 - val_binary_accuracy: 0.5033\n",
      "Epoch 671/10000\n",
      "751/751 [==============================] - 0s 71us/step - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 3.1223 - val_binary_accuracy: 0.4993\n",
      "Epoch 672/10000\n",
      "751/751 [==============================] - 0s 91us/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 3.1254 - val_binary_accuracy: 0.5020\n",
      "Epoch 673/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 3.1299 - val_binary_accuracy: 0.5007\n",
      "Epoch 674/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.1345 - val_binary_accuracy: 0.5007\n",
      "Epoch 675/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.1392 - val_binary_accuracy: 0.4993\n",
      "Epoch 676/10000\n",
      "751/751 [==============================] - 0s 69us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.1448 - val_binary_accuracy: 0.4993\n",
      "Epoch 677/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.1505 - val_binary_accuracy: 0.5020\n",
      "Epoch 678/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 3.1543 - val_binary_accuracy: 0.5047\n",
      "Epoch 679/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 3.1577 - val_binary_accuracy: 0.5033\n",
      "Epoch 680/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.1606 - val_binary_accuracy: 0.5007\n",
      "Epoch 681/10000\n",
      "751/751 [==============================] - 0s 86us/step - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 3.1640 - val_binary_accuracy: 0.5007\n",
      "Epoch 682/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 3.1669 - val_binary_accuracy: 0.5007\n",
      "Epoch 683/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 3.1669 - val_binary_accuracy: 0.5033\n",
      "Epoch 684/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 0.0019 - binary_accuracy: 1.0000 - val_loss: 3.1694 - val_binary_accuracy: 0.4980\n",
      "Epoch 685/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0010 - binary_accuracy: 1.0000 - val_loss: 3.1782 - val_binary_accuracy: 0.4953\n",
      "Epoch 686/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 3.1847 - val_binary_accuracy: 0.4913\n",
      "Epoch 687/10000\n",
      "751/751 [==============================] - 0s 88us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.1893 - val_binary_accuracy: 0.4927\n",
      "Epoch 688/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0022 - binary_accuracy: 1.0000 - val_loss: 3.1898 - val_binary_accuracy: 0.5033\n",
      "Epoch 689/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.1987 - val_binary_accuracy: 0.4967\n",
      "Epoch 690/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 3.1982 - val_binary_accuracy: 0.4940\n",
      "Epoch 691/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 3.1892 - val_binary_accuracy: 0.4967\n",
      "Epoch 692/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 3.1827 - val_binary_accuracy: 0.5033\n",
      "Epoch 693/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 8.9992e-04 - binary_accuracy: 1.0000 - val_loss: 3.1837 - val_binary_accuracy: 0.5007\n",
      "Epoch 694/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.1866 - val_binary_accuracy: 0.5020\n",
      "Epoch 695/10000\n",
      "751/751 [==============================] - 0s 83us/step - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 3.1906 - val_binary_accuracy: 0.5033\n",
      "Epoch 696/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 9.5413e-04 - binary_accuracy: 1.0000 - val_loss: 3.1968 - val_binary_accuracy: 0.5060\n",
      "Epoch 697/10000\n",
      "751/751 [==============================] - 0s 91us/step - loss: 9.7671e-04 - binary_accuracy: 1.0000 - val_loss: 3.2047 - val_binary_accuracy: 0.5060\n",
      "Epoch 698/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0010 - binary_accuracy: 1.0000 - val_loss: 3.2116 - val_binary_accuracy: 0.5033\n",
      "Epoch 699/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 3.2146 - val_binary_accuracy: 0.5020\n",
      "Epoch 700/10000\n",
      "751/751 [==============================] - 0s 88us/step - loss: 8.8091e-04 - binary_accuracy: 1.0000 - val_loss: 3.2159 - val_binary_accuracy: 0.5007\n",
      "Epoch 701/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 0.0010 - binary_accuracy: 1.0000 - val_loss: 3.2159 - val_binary_accuracy: 0.5033\n",
      "Epoch 702/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 9.3844e-04 - binary_accuracy: 1.0000 - val_loss: 3.2171 - val_binary_accuracy: 0.5073\n",
      "Epoch 703/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751/751 [==============================] - 0s 87us/step - loss: 9.3818e-04 - binary_accuracy: 1.0000 - val_loss: 3.2190 - val_binary_accuracy: 0.5073\n",
      "Epoch 704/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.2229 - val_binary_accuracy: 0.5060\n",
      "Epoch 705/10000\n",
      "751/751 [==============================] - 0s 93us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 3.2282 - val_binary_accuracy: 0.5073\n",
      "Epoch 706/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 9.9889e-04 - binary_accuracy: 1.0000 - val_loss: 3.2309 - val_binary_accuracy: 0.5087\n",
      "Epoch 707/10000\n",
      "751/751 [==============================] - 0s 93us/step - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 3.2352 - val_binary_accuracy: 0.5126\n",
      "Epoch 708/10000\n",
      "751/751 [==============================] - 0s 89us/step - loss: 0.0010 - binary_accuracy: 1.0000 - val_loss: 3.2390 - val_binary_accuracy: 0.5020\n",
      "Epoch 709/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 8.3716e-04 - binary_accuracy: 1.0000 - val_loss: 3.2451 - val_binary_accuracy: 0.4967\n",
      "Epoch 710/10000\n",
      "751/751 [==============================] - 0s 93us/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 3.2432 - val_binary_accuracy: 0.4993\n",
      "Epoch 711/10000\n",
      "751/751 [==============================] - 0s 117us/step - loss: 9.2941e-04 - binary_accuracy: 1.0000 - val_loss: 3.2419 - val_binary_accuracy: 0.5087\n",
      "Epoch 712/10000\n",
      "751/751 [==============================] - 0s 128us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.2422 - val_binary_accuracy: 0.5060\n",
      "Epoch 713/10000\n",
      "751/751 [==============================] - 0s 115us/step - loss: 9.0217e-04 - binary_accuracy: 1.0000 - val_loss: 3.2442 - val_binary_accuracy: 0.5087\n",
      "Epoch 714/10000\n",
      "751/751 [==============================] - 0s 103us/step - loss: 8.6929e-04 - binary_accuracy: 1.0000 - val_loss: 3.2454 - val_binary_accuracy: 0.5073\n",
      "Epoch 715/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 6.8744e-04 - binary_accuracy: 1.0000 - val_loss: 3.2476 - val_binary_accuracy: 0.5087\n",
      "Epoch 716/10000\n",
      "751/751 [==============================] - 0s 92us/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 3.2469 - val_binary_accuracy: 0.5007\n",
      "Epoch 717/10000\n",
      "751/751 [==============================] - 0s 90us/step - loss: 0.0037 - binary_accuracy: 0.9987 - val_loss: 3.2504 - val_binary_accuracy: 0.5060\n",
      "Epoch 718/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.2570 - val_binary_accuracy: 0.5033\n",
      "Epoch 719/10000\n",
      "751/751 [==============================] - 0s 92us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.2609 - val_binary_accuracy: 0.5073\n",
      "Epoch 720/10000\n",
      "751/751 [==============================] - 0s 101us/step - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 3.2660 - val_binary_accuracy: 0.5087\n",
      "Epoch 721/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 9.9261e-04 - binary_accuracy: 1.0000 - val_loss: 3.2698 - val_binary_accuracy: 0.5073\n",
      "Epoch 722/10000\n",
      "751/751 [==============================] - 0s 87us/step - loss: 9.4418e-04 - binary_accuracy: 1.0000 - val_loss: 3.2722 - val_binary_accuracy: 0.5060\n",
      "Epoch 723/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 8.9969e-04 - binary_accuracy: 1.0000 - val_loss: 3.2730 - val_binary_accuracy: 0.5060\n",
      "Epoch 724/10000\n",
      "751/751 [==============================] - 0s 71us/step - loss: 8.7960e-04 - binary_accuracy: 1.0000 - val_loss: 3.2704 - val_binary_accuracy: 0.5047\n",
      "Epoch 725/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 9.4619e-04 - binary_accuracy: 1.0000 - val_loss: 3.2663 - val_binary_accuracy: 0.5087\n",
      "Epoch 726/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 9.8459e-04 - binary_accuracy: 1.0000 - val_loss: 3.2643 - val_binary_accuracy: 0.5073\n",
      "Epoch 727/10000\n",
      "751/751 [==============================] - 0s 87us/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 3.2640 - val_binary_accuracy: 0.5060\n",
      "Epoch 728/10000\n",
      "751/751 [==============================] - 0s 93us/step - loss: 9.4330e-04 - binary_accuracy: 1.0000 - val_loss: 3.2644 - val_binary_accuracy: 0.5033\n",
      "Epoch 729/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 9.3507e-04 - binary_accuracy: 1.0000 - val_loss: 3.2643 - val_binary_accuracy: 0.5020\n",
      "Epoch 730/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 0.0010 - binary_accuracy: 1.0000 - val_loss: 3.2630 - val_binary_accuracy: 0.5033\n",
      "Epoch 731/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 8.0779e-04 - binary_accuracy: 1.0000 - val_loss: 3.2631 - val_binary_accuracy: 0.5033\n",
      "Epoch 732/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.2621 - val_binary_accuracy: 0.5060\n",
      "Epoch 733/10000\n",
      "751/751 [==============================] - 0s 100us/step - loss: 9.9491e-04 - binary_accuracy: 1.0000 - val_loss: 3.2638 - val_binary_accuracy: 0.5020\n",
      "Epoch 734/10000\n",
      "751/751 [==============================] - 0s 134us/step - loss: 7.7486e-04 - binary_accuracy: 1.0000 - val_loss: 3.2678 - val_binary_accuracy: 0.5020\n",
      "Epoch 735/10000\n",
      "751/751 [==============================] - 0s 89us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.2748 - val_binary_accuracy: 0.5020\n",
      "Epoch 736/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 7.3820e-04 - binary_accuracy: 1.0000 - val_loss: 3.2845 - val_binary_accuracy: 0.5007\n",
      "Epoch 737/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 8.5801e-04 - binary_accuracy: 1.0000 - val_loss: 3.2885 - val_binary_accuracy: 0.4980\n",
      "Epoch 738/10000\n",
      "751/751 [==============================] - 0s 83us/step - loss: 8.2571e-04 - binary_accuracy: 1.0000 - val_loss: 3.2879 - val_binary_accuracy: 0.5047\n",
      "Epoch 739/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 7.6918e-04 - binary_accuracy: 1.0000 - val_loss: 3.2869 - val_binary_accuracy: 0.5033\n",
      "Epoch 740/10000\n",
      "751/751 [==============================] - 0s 91us/step - loss: 9.2468e-04 - binary_accuracy: 1.0000 - val_loss: 3.2872 - val_binary_accuracy: 0.5033\n",
      "Epoch 741/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 7.5521e-04 - binary_accuracy: 1.0000 - val_loss: 3.2893 - val_binary_accuracy: 0.5047\n",
      "Epoch 742/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 7.8095e-04 - binary_accuracy: 1.0000 - val_loss: 3.2917 - val_binary_accuracy: 0.5033\n",
      "Epoch 743/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 8.5104e-04 - binary_accuracy: 1.0000 - val_loss: 3.2958 - val_binary_accuracy: 0.5060\n",
      "Epoch 744/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 8.0494e-04 - binary_accuracy: 1.0000 - val_loss: 3.2992 - val_binary_accuracy: 0.5126\n",
      "Epoch 745/10000\n",
      "751/751 [==============================] - 0s 86us/step - loss: 6.8694e-04 - binary_accuracy: 1.0000 - val_loss: 3.3023 - val_binary_accuracy: 0.5126\n",
      "Epoch 746/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 7.7762e-04 - binary_accuracy: 1.0000 - val_loss: 3.3044 - val_binary_accuracy: 0.5126\n",
      "Epoch 747/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 7.4864e-04 - binary_accuracy: 1.0000 - val_loss: 3.3059 - val_binary_accuracy: 0.5126\n",
      "Epoch 748/10000\n",
      "751/751 [==============================] - 0s 86us/step - loss: 0.0010 - binary_accuracy: 1.0000 - val_loss: 3.3055 - val_binary_accuracy: 0.5073\n",
      "Epoch 749/10000\n",
      "751/751 [==============================] - 0s 90us/step - loss: 0.0021 - binary_accuracy: 0.9987 - val_loss: 3.3034 - val_binary_accuracy: 0.5087\n",
      "Epoch 750/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 7.3509e-04 - binary_accuracy: 1.0000 - val_loss: 3.3035 - val_binary_accuracy: 0.5100\n",
      "Epoch 751/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 9.7081e-04 - binary_accuracy: 1.0000 - val_loss: 3.3052 - val_binary_accuracy: 0.5060\n",
      "Epoch 752/10000\n",
      "751/751 [==============================] - 0s 91us/step - loss: 8.3034e-04 - binary_accuracy: 1.0000 - val_loss: 3.3043 - val_binary_accuracy: 0.5087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 753/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 8.3493e-04 - binary_accuracy: 1.0000 - val_loss: 3.3044 - val_binary_accuracy: 0.5087\n",
      "Epoch 754/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 7.5802e-04 - binary_accuracy: 1.0000 - val_loss: 3.3055 - val_binary_accuracy: 0.5113\n",
      "Epoch 755/10000\n",
      "751/751 [==============================] - 0s 106us/step - loss: 9.1528e-04 - binary_accuracy: 1.0000 - val_loss: 3.3072 - val_binary_accuracy: 0.5113\n",
      "Epoch 756/10000\n",
      "751/751 [==============================] - 0s 122us/step - loss: 7.7819e-04 - binary_accuracy: 1.0000 - val_loss: 3.3106 - val_binary_accuracy: 0.5100\n",
      "Epoch 757/10000\n",
      "751/751 [==============================] - 0s 103us/step - loss: 7.0422e-04 - binary_accuracy: 1.0000 - val_loss: 3.3154 - val_binary_accuracy: 0.5087\n",
      "Epoch 758/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 7.8989e-04 - binary_accuracy: 1.0000 - val_loss: 3.3239 - val_binary_accuracy: 0.5073\n",
      "Epoch 759/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 6.7035e-04 - binary_accuracy: 1.0000 - val_loss: 3.3301 - val_binary_accuracy: 0.5087\n",
      "Epoch 760/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 6.7743e-04 - binary_accuracy: 1.0000 - val_loss: 3.3344 - val_binary_accuracy: 0.5060\n",
      "Epoch 761/10000\n",
      "751/751 [==============================] - 0s 66us/step - loss: 7.7591e-04 - binary_accuracy: 1.0000 - val_loss: 3.3349 - val_binary_accuracy: 0.5073\n",
      "Epoch 762/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.3324 - val_binary_accuracy: 0.5100\n",
      "Epoch 763/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.3333 - val_binary_accuracy: 0.5047\n",
      "Epoch 764/10000\n",
      "751/751 [==============================] - 0s 99us/step - loss: 6.8784e-04 - binary_accuracy: 1.0000 - val_loss: 3.3384 - val_binary_accuracy: 0.5020\n",
      "Epoch 765/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 7.6306e-04 - binary_accuracy: 1.0000 - val_loss: 3.3423 - val_binary_accuracy: 0.5020\n",
      "Epoch 766/10000\n",
      "751/751 [==============================] - 0s 92us/step - loss: 7.5500e-04 - binary_accuracy: 1.0000 - val_loss: 3.3461 - val_binary_accuracy: 0.5047\n",
      "Epoch 767/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 8.1839e-04 - binary_accuracy: 1.0000 - val_loss: 3.3503 - val_binary_accuracy: 0.5100\n",
      "Epoch 768/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 9.2830e-04 - binary_accuracy: 1.0000 - val_loss: 3.3527 - val_binary_accuracy: 0.5100\n",
      "Epoch 769/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 8.6810e-04 - binary_accuracy: 1.0000 - val_loss: 3.3541 - val_binary_accuracy: 0.5087\n",
      "Epoch 770/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 6.9422e-04 - binary_accuracy: 1.0000 - val_loss: 3.3544 - val_binary_accuracy: 0.5060\n",
      "Epoch 771/10000\n",
      "751/751 [==============================] - 0s 71us/step - loss: 7.3224e-04 - binary_accuracy: 1.0000 - val_loss: 3.3537 - val_binary_accuracy: 0.5060\n",
      "Epoch 772/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 6.3369e-04 - binary_accuracy: 1.0000 - val_loss: 3.3517 - val_binary_accuracy: 0.5047\n",
      "Epoch 773/10000\n",
      "751/751 [==============================] - 0s 71us/step - loss: 6.2241e-04 - binary_accuracy: 1.0000 - val_loss: 3.3497 - val_binary_accuracy: 0.5087\n",
      "Epoch 774/10000\n",
      "751/751 [==============================] - 0s 67us/step - loss: 6.6441e-04 - binary_accuracy: 1.0000 - val_loss: 3.3475 - val_binary_accuracy: 0.5060\n",
      "Epoch 775/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 6.8671e-04 - binary_accuracy: 1.0000 - val_loss: 3.3470 - val_binary_accuracy: 0.5033\n",
      "Epoch 776/10000\n",
      "751/751 [==============================] - 0s 71us/step - loss: 6.9529e-04 - binary_accuracy: 1.0000 - val_loss: 3.3475 - val_binary_accuracy: 0.5007\n",
      "Epoch 777/10000\n",
      "751/751 [==============================] - 0s 83us/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 3.3480 - val_binary_accuracy: 0.4993\n",
      "Epoch 778/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 7.1615e-04 - binary_accuracy: 1.0000 - val_loss: 3.3486 - val_binary_accuracy: 0.5020\n",
      "Epoch 779/10000\n",
      "751/751 [==============================] - 0s 70us/step - loss: 9.2589e-04 - binary_accuracy: 1.0000 - val_loss: 3.3442 - val_binary_accuracy: 0.5020\n",
      "Epoch 780/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 9.0391e-04 - binary_accuracy: 1.0000 - val_loss: 3.3418 - val_binary_accuracy: 0.5047\n",
      "Epoch 781/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 7.1163e-04 - binary_accuracy: 1.0000 - val_loss: 3.3414 - val_binary_accuracy: 0.5073\n",
      "Epoch 782/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 6.7940e-04 - binary_accuracy: 1.0000 - val_loss: 3.3441 - val_binary_accuracy: 0.5047\n",
      "Epoch 783/10000\n",
      "751/751 [==============================] - 0s 67us/step - loss: 8.8163e-04 - binary_accuracy: 1.0000 - val_loss: 3.3504 - val_binary_accuracy: 0.5060\n",
      "Epoch 784/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 6.0316e-04 - binary_accuracy: 1.0000 - val_loss: 3.3560 - val_binary_accuracy: 0.5047\n",
      "Epoch 785/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 6.7540e-04 - binary_accuracy: 1.0000 - val_loss: 3.3570 - val_binary_accuracy: 0.5060\n",
      "Epoch 786/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 6.2498e-04 - binary_accuracy: 1.0000 - val_loss: 3.3570 - val_binary_accuracy: 0.5047\n",
      "Epoch 787/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 8.0320e-04 - binary_accuracy: 1.0000 - val_loss: 3.3565 - val_binary_accuracy: 0.5020\n",
      "Epoch 788/10000\n",
      "751/751 [==============================] - 0s 68us/step - loss: 8.0607e-04 - binary_accuracy: 1.0000 - val_loss: 3.3555 - val_binary_accuracy: 0.5060\n",
      "Epoch 789/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 6.1269e-04 - binary_accuracy: 1.0000 - val_loss: 3.3552 - val_binary_accuracy: 0.5020\n",
      "Epoch 790/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 6.7410e-04 - binary_accuracy: 1.0000 - val_loss: 3.3563 - val_binary_accuracy: 0.5007\n",
      "Epoch 791/10000\n",
      "751/751 [==============================] - 0s 69us/step - loss: 8.1323e-04 - binary_accuracy: 1.0000 - val_loss: 3.3571 - val_binary_accuracy: 0.5020\n",
      "Epoch 792/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 3.3685 - val_binary_accuracy: 0.5007\n",
      "Epoch 793/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 8.5672e-04 - binary_accuracy: 1.0000 - val_loss: 3.3737 - val_binary_accuracy: 0.5033\n",
      "Epoch 794/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 5.7269e-04 - binary_accuracy: 1.0000 - val_loss: 3.3722 - val_binary_accuracy: 0.5073\n",
      "Epoch 795/10000\n",
      "751/751 [==============================] - 0s 69us/step - loss: 6.8985e-04 - binary_accuracy: 1.0000 - val_loss: 3.3735 - val_binary_accuracy: 0.5073\n",
      "Epoch 796/10000\n",
      "751/751 [==============================] - 0s 83us/step - loss: 5.8844e-04 - binary_accuracy: 1.0000 - val_loss: 3.3743 - val_binary_accuracy: 0.5100\n",
      "Epoch 797/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 7.1972e-04 - binary_accuracy: 1.0000 - val_loss: 3.3771 - val_binary_accuracy: 0.5087\n",
      "Epoch 798/10000\n",
      "751/751 [==============================] - 0s 96us/step - loss: 6.3077e-04 - binary_accuracy: 1.0000 - val_loss: 3.3801 - val_binary_accuracy: 0.5100\n",
      "Epoch 799/10000\n",
      "751/751 [==============================] - 0s 70us/step - loss: 5.5022e-04 - binary_accuracy: 1.0000 - val_loss: 3.3827 - val_binary_accuracy: 0.5047\n",
      "Epoch 800/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 5.2869e-04 - binary_accuracy: 1.0000 - val_loss: 3.3834 - val_binary_accuracy: 0.5033\n",
      "Epoch 801/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 7.9255e-04 - binary_accuracy: 1.0000 - val_loss: 3.3841 - val_binary_accuracy: 0.5033\n",
      "Epoch 802/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751/751 [==============================] - 0s 74us/step - loss: 6.1200e-04 - binary_accuracy: 1.0000 - val_loss: 3.3851 - val_binary_accuracy: 0.5047\n",
      "Epoch 803/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 7.9322e-04 - binary_accuracy: 1.0000 - val_loss: 3.3865 - val_binary_accuracy: 0.5047\n",
      "Epoch 804/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 4.9060e-04 - binary_accuracy: 1.0000 - val_loss: 3.3861 - val_binary_accuracy: 0.5007\n",
      "Epoch 805/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 6.0064e-04 - binary_accuracy: 1.0000 - val_loss: 3.3861 - val_binary_accuracy: 0.5033\n",
      "Epoch 806/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 5.6010e-04 - binary_accuracy: 1.0000 - val_loss: 3.3850 - val_binary_accuracy: 0.5033\n",
      "Epoch 807/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 5.5892e-04 - binary_accuracy: 1.0000 - val_loss: 3.3844 - val_binary_accuracy: 0.4993\n",
      "Epoch 808/10000\n",
      "751/751 [==============================] - 0s 69us/step - loss: 0.0019 - binary_accuracy: 0.9987 - val_loss: 3.3761 - val_binary_accuracy: 0.5047\n",
      "Epoch 809/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 7.7010e-04 - binary_accuracy: 1.0000 - val_loss: 3.3740 - val_binary_accuracy: 0.5033\n",
      "Epoch 810/10000\n",
      "751/751 [==============================] - 0s 88us/step - loss: 7.7326e-04 - binary_accuracy: 1.0000 - val_loss: 3.3697 - val_binary_accuracy: 0.5033\n",
      "Epoch 811/10000\n",
      "751/751 [==============================] - 0s 91us/step - loss: 6.7703e-04 - binary_accuracy: 1.0000 - val_loss: 3.3690 - val_binary_accuracy: 0.5060\n",
      "Epoch 812/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 3.3695 - val_binary_accuracy: 0.5047\n",
      "Epoch 813/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 7.6989e-04 - binary_accuracy: 1.0000 - val_loss: 3.3751 - val_binary_accuracy: 0.5033\n",
      "Epoch 814/10000\n",
      "751/751 [==============================] - 0s 120us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.3795 - val_binary_accuracy: 0.5060\n",
      "Epoch 815/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 6.3848e-04 - binary_accuracy: 1.0000 - val_loss: 3.3836 - val_binary_accuracy: 0.5007\n",
      "Epoch 816/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 6.5048e-04 - binary_accuracy: 1.0000 - val_loss: 3.3907 - val_binary_accuracy: 0.4993\n",
      "Epoch 817/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 8.1199e-04 - binary_accuracy: 1.0000 - val_loss: 3.3949 - val_binary_accuracy: 0.5007\n",
      "Epoch 818/10000\n",
      "751/751 [==============================] - 0s 66us/step - loss: 6.0353e-04 - binary_accuracy: 1.0000 - val_loss: 3.3952 - val_binary_accuracy: 0.5033\n",
      "Epoch 819/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 7.1070e-04 - binary_accuracy: 1.0000 - val_loss: 3.3938 - val_binary_accuracy: 0.5020\n",
      "Epoch 820/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 5.7630e-04 - binary_accuracy: 1.0000 - val_loss: 3.3942 - val_binary_accuracy: 0.5047\n",
      "Epoch 821/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 8.2637e-04 - binary_accuracy: 1.0000 - val_loss: 3.3948 - val_binary_accuracy: 0.5020\n",
      "Epoch 822/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 6.6657e-04 - binary_accuracy: 1.0000 - val_loss: 3.3965 - val_binary_accuracy: 0.5020\n",
      "Epoch 823/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 8.1754e-04 - binary_accuracy: 1.0000 - val_loss: 3.3996 - val_binary_accuracy: 0.5033\n",
      "Epoch 824/10000\n",
      "751/751 [==============================] - 0s 68us/step - loss: 5.3536e-04 - binary_accuracy: 1.0000 - val_loss: 3.4050 - val_binary_accuracy: 0.5073\n",
      "Epoch 825/10000\n",
      "751/751 [==============================] - 0s 67us/step - loss: 4.9872e-04 - binary_accuracy: 1.0000 - val_loss: 3.4094 - val_binary_accuracy: 0.5073\n",
      "Epoch 826/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 6.3519e-04 - binary_accuracy: 1.0000 - val_loss: 3.4099 - val_binary_accuracy: 0.5073\n",
      "Epoch 827/10000\n",
      "751/751 [==============================] - 0s 70us/step - loss: 5.7252e-04 - binary_accuracy: 1.0000 - val_loss: 3.4085 - val_binary_accuracy: 0.5087\n",
      "Epoch 828/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 5.3255e-04 - binary_accuracy: 1.0000 - val_loss: 3.4059 - val_binary_accuracy: 0.5087\n",
      "Epoch 829/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 0.0031 - binary_accuracy: 0.9987 - val_loss: 3.4001 - val_binary_accuracy: 0.4980\n",
      "Epoch 830/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 8.7617e-04 - binary_accuracy: 1.0000 - val_loss: 3.3907 - val_binary_accuracy: 0.4913\n",
      "Epoch 831/10000\n",
      "751/751 [==============================] - 0s 104us/step - loss: 6.7406e-04 - binary_accuracy: 1.0000 - val_loss: 3.3776 - val_binary_accuracy: 0.4980\n",
      "Epoch 832/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 7.9485e-04 - binary_accuracy: 1.0000 - val_loss: 3.3647 - val_binary_accuracy: 0.5020\n",
      "Epoch 833/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 6.2942e-04 - binary_accuracy: 1.0000 - val_loss: 3.3582 - val_binary_accuracy: 0.5073\n",
      "Epoch 834/10000\n",
      "751/751 [==============================] - 0s 98us/step - loss: 7.2070e-04 - binary_accuracy: 1.0000 - val_loss: 3.3579 - val_binary_accuracy: 0.5020\n",
      "Epoch 835/10000\n",
      "751/751 [==============================] - 0s 95us/step - loss: 0.0010 - binary_accuracy: 1.0000 - val_loss: 3.3612 - val_binary_accuracy: 0.5020\n",
      "Epoch 836/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 6.8554e-04 - binary_accuracy: 1.0000 - val_loss: 3.3688 - val_binary_accuracy: 0.5073\n",
      "Epoch 837/10000\n",
      "751/751 [==============================] - 0s 102us/step - loss: 6.5998e-04 - binary_accuracy: 1.0000 - val_loss: 3.3785 - val_binary_accuracy: 0.5020\n",
      "Epoch 838/10000\n",
      "751/751 [==============================] - 0s 105us/step - loss: 7.2953e-04 - binary_accuracy: 1.0000 - val_loss: 3.3927 - val_binary_accuracy: 0.4953\n",
      "Epoch 839/10000\n",
      "751/751 [==============================] - 0s 92us/step - loss: 5.6378e-04 - binary_accuracy: 1.0000 - val_loss: 3.4022 - val_binary_accuracy: 0.4967\n",
      "Epoch 840/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 6.4213e-04 - binary_accuracy: 1.0000 - val_loss: 3.4067 - val_binary_accuracy: 0.4980\n",
      "Epoch 841/10000\n",
      "751/751 [==============================] - 0s 102us/step - loss: 6.2879e-04 - binary_accuracy: 1.0000 - val_loss: 3.4096 - val_binary_accuracy: 0.5007\n",
      "Epoch 842/10000\n",
      "751/751 [==============================] - 0s 87us/step - loss: 5.6496e-04 - binary_accuracy: 1.0000 - val_loss: 3.4113 - val_binary_accuracy: 0.4980\n",
      "Epoch 843/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 5.1533e-04 - binary_accuracy: 1.0000 - val_loss: 3.4123 - val_binary_accuracy: 0.5007\n",
      "Epoch 844/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 5.5336e-04 - binary_accuracy: 1.0000 - val_loss: 3.4136 - val_binary_accuracy: 0.4993\n",
      "Epoch 845/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 7.8841e-04 - binary_accuracy: 1.0000 - val_loss: 3.4137 - val_binary_accuracy: 0.5020\n",
      "Epoch 846/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 5.1397e-04 - binary_accuracy: 1.0000 - val_loss: 3.4145 - val_binary_accuracy: 0.4980\n",
      "Epoch 847/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 8.3332e-04 - binary_accuracy: 1.0000 - val_loss: 3.4141 - val_binary_accuracy: 0.4993\n",
      "Epoch 848/10000\n",
      "751/751 [==============================] - 0s 67us/step - loss: 5.2135e-04 - binary_accuracy: 1.0000 - val_loss: 3.4141 - val_binary_accuracy: 0.4993\n",
      "Epoch 849/10000\n",
      "751/751 [==============================] - 0s 147us/step - loss: 5.5159e-04 - binary_accuracy: 1.0000 - val_loss: 3.4133 - val_binary_accuracy: 0.5007\n",
      "Epoch 850/10000\n",
      "751/751 [==============================] - 0s 105us/step - loss: 5.2498e-04 - binary_accuracy: 1.0000 - val_loss: 3.4113 - val_binary_accuracy: 0.5007\n",
      "Epoch 851/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751/751 [==============================] - 0s 96us/step - loss: 0.0010 - binary_accuracy: 1.0000 - val_loss: 3.4092 - val_binary_accuracy: 0.5007\n",
      "Epoch 852/10000\n",
      "751/751 [==============================] - 0s 112us/step - loss: 5.0896e-04 - binary_accuracy: 1.0000 - val_loss: 3.4091 - val_binary_accuracy: 0.5020\n",
      "Epoch 853/10000\n",
      "751/751 [==============================] - 0s 139us/step - loss: 5.5529e-04 - binary_accuracy: 1.0000 - val_loss: 3.4108 - val_binary_accuracy: 0.5020\n",
      "Epoch 854/10000\n",
      "751/751 [==============================] - 0s 119us/step - loss: 7.0970e-04 - binary_accuracy: 1.0000 - val_loss: 3.4136 - val_binary_accuracy: 0.5087\n",
      "Epoch 855/10000\n",
      "751/751 [==============================] - 0s 100us/step - loss: 4.9359e-04 - binary_accuracy: 1.0000 - val_loss: 3.4202 - val_binary_accuracy: 0.5047\n",
      "Epoch 856/10000\n",
      "751/751 [==============================] - 0s 105us/step - loss: 9.9378e-04 - binary_accuracy: 1.0000 - val_loss: 3.4199 - val_binary_accuracy: 0.5073\n",
      "Epoch 857/10000\n",
      "751/751 [==============================] - 0s 86us/step - loss: 5.7126e-04 - binary_accuracy: 1.0000 - val_loss: 3.4209 - val_binary_accuracy: 0.5020\n",
      "Epoch 858/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 8.4829e-04 - binary_accuracy: 1.0000 - val_loss: 3.4246 - val_binary_accuracy: 0.4967\n",
      "Epoch 859/10000\n",
      "751/751 [==============================] - 0s 93us/step - loss: 5.6096e-04 - binary_accuracy: 1.0000 - val_loss: 3.4305 - val_binary_accuracy: 0.4980\n",
      "Epoch 860/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 5.1783e-04 - binary_accuracy: 1.0000 - val_loss: 3.4354 - val_binary_accuracy: 0.4967\n",
      "Epoch 861/10000\n",
      "751/751 [==============================] - 0s 103us/step - loss: 6.0429e-04 - binary_accuracy: 1.0000 - val_loss: 3.4392 - val_binary_accuracy: 0.4993\n",
      "Epoch 862/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 4.7998e-04 - binary_accuracy: 1.0000 - val_loss: 3.4417 - val_binary_accuracy: 0.4980\n",
      "Epoch 863/10000\n",
      "751/751 [==============================] - 0s 103us/step - loss: 6.8310e-04 - binary_accuracy: 1.0000 - val_loss: 3.4461 - val_binary_accuracy: 0.4993\n",
      "Epoch 864/10000\n",
      "751/751 [==============================] - 0s 88us/step - loss: 5.5942e-04 - binary_accuracy: 1.0000 - val_loss: 3.4489 - val_binary_accuracy: 0.4993\n",
      "Epoch 865/10000\n",
      "751/751 [==============================] - 0s 93us/step - loss: 6.9875e-04 - binary_accuracy: 1.0000 - val_loss: 3.4515 - val_binary_accuracy: 0.4993\n",
      "Epoch 866/10000\n",
      "751/751 [==============================] - 0s 89us/step - loss: 6.5470e-04 - binary_accuracy: 1.0000 - val_loss: 3.4542 - val_binary_accuracy: 0.4967\n",
      "Epoch 867/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 5.8179e-04 - binary_accuracy: 1.0000 - val_loss: 3.4548 - val_binary_accuracy: 0.5007\n",
      "Epoch 868/10000\n",
      "751/751 [==============================] - 0s 87us/step - loss: 5.8539e-04 - binary_accuracy: 1.0000 - val_loss: 3.4551 - val_binary_accuracy: 0.5007\n",
      "Epoch 869/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 4.7095e-04 - binary_accuracy: 1.0000 - val_loss: 3.4551 - val_binary_accuracy: 0.5007\n",
      "Epoch 870/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 4.7272e-04 - binary_accuracy: 1.0000 - val_loss: 3.4549 - val_binary_accuracy: 0.4993\n",
      "Epoch 871/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 6.1535e-04 - binary_accuracy: 1.0000 - val_loss: 3.4527 - val_binary_accuracy: 0.4993\n",
      "Epoch 872/10000\n",
      "751/751 [==============================] - 0s 86us/step - loss: 4.3850e-04 - binary_accuracy: 1.0000 - val_loss: 3.4523 - val_binary_accuracy: 0.5007\n",
      "Epoch 873/10000\n",
      "751/751 [==============================] - 0s 92us/step - loss: 5.4708e-04 - binary_accuracy: 1.0000 - val_loss: 3.4516 - val_binary_accuracy: 0.4993\n",
      "Epoch 874/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 6.1657e-04 - binary_accuracy: 1.0000 - val_loss: 3.4528 - val_binary_accuracy: 0.4993\n",
      "Epoch 875/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 5.5592e-04 - binary_accuracy: 1.0000 - val_loss: 3.4539 - val_binary_accuracy: 0.4993\n",
      "Epoch 876/10000\n",
      "751/751 [==============================] - 0s 86us/step - loss: 4.9206e-04 - binary_accuracy: 1.0000 - val_loss: 3.4527 - val_binary_accuracy: 0.5007\n",
      "Epoch 877/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 4.4126e-04 - binary_accuracy: 1.0000 - val_loss: 3.4523 - val_binary_accuracy: 0.5033\n",
      "Epoch 878/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 4.0221e-04 - binary_accuracy: 1.0000 - val_loss: 3.4525 - val_binary_accuracy: 0.4993\n",
      "Epoch 879/10000\n",
      "751/751 [==============================] - 0s 107us/step - loss: 4.9003e-04 - binary_accuracy: 1.0000 - val_loss: 3.4534 - val_binary_accuracy: 0.4993\n",
      "Epoch 880/10000\n",
      "751/751 [==============================] - 0s 69us/step - loss: 4.5411e-04 - binary_accuracy: 1.0000 - val_loss: 3.4543 - val_binary_accuracy: 0.4993\n",
      "Epoch 881/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 4.6711e-04 - binary_accuracy: 1.0000 - val_loss: 3.4550 - val_binary_accuracy: 0.4993\n",
      "Epoch 882/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 4.5688e-04 - binary_accuracy: 1.0000 - val_loss: 3.4560 - val_binary_accuracy: 0.4953\n",
      "Epoch 883/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 4.7770e-04 - binary_accuracy: 1.0000 - val_loss: 3.4578 - val_binary_accuracy: 0.4940\n",
      "Epoch 884/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 5.4899e-04 - binary_accuracy: 1.0000 - val_loss: 3.4590 - val_binary_accuracy: 0.4953\n",
      "Epoch 885/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 3.6651e-04 - binary_accuracy: 1.0000 - val_loss: 3.4606 - val_binary_accuracy: 0.4980\n",
      "Epoch 886/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 3.6463e-04 - binary_accuracy: 1.0000 - val_loss: 3.4621 - val_binary_accuracy: 0.5020\n",
      "Epoch 887/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 4.5602e-04 - binary_accuracy: 1.0000 - val_loss: 3.4633 - val_binary_accuracy: 0.5020\n",
      "Epoch 888/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 5.3965e-04 - binary_accuracy: 1.0000 - val_loss: 3.4632 - val_binary_accuracy: 0.5007\n",
      "Epoch 889/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 4.1142e-04 - binary_accuracy: 1.0000 - val_loss: 3.4629 - val_binary_accuracy: 0.5007\n",
      "Epoch 890/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 6.8210e-04 - binary_accuracy: 1.0000 - val_loss: 3.4677 - val_binary_accuracy: 0.4967\n",
      "Epoch 891/10000\n",
      "751/751 [==============================] - 0s 88us/step - loss: 9.2568e-04 - binary_accuracy: 1.0000 - val_loss: 3.4729 - val_binary_accuracy: 0.5007\n",
      "Epoch 892/10000\n",
      "751/751 [==============================] - 0s 98us/step - loss: 4.5660e-04 - binary_accuracy: 1.0000 - val_loss: 3.4768 - val_binary_accuracy: 0.4993\n",
      "Epoch 893/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 3.7517e-04 - binary_accuracy: 1.0000 - val_loss: 3.4799 - val_binary_accuracy: 0.4980\n",
      "Epoch 894/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.4832 - val_binary_accuracy: 0.4927\n",
      "Epoch 895/10000\n",
      "751/751 [==============================] - 0s 71us/step - loss: 4.5137e-04 - binary_accuracy: 1.0000 - val_loss: 3.4878 - val_binary_accuracy: 0.4913\n",
      "Epoch 896/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 6.9275e-04 - binary_accuracy: 1.0000 - val_loss: 3.4872 - val_binary_accuracy: 0.4927\n",
      "Epoch 897/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 9.9798e-04 - binary_accuracy: 1.0000 - val_loss: 3.4858 - val_binary_accuracy: 0.4913\n",
      "Epoch 898/10000\n",
      "751/751 [==============================] - 0s 92us/step - loss: 5.8297e-04 - binary_accuracy: 1.0000 - val_loss: 3.4945 - val_binary_accuracy: 0.4874\n",
      "Epoch 899/10000\n",
      "751/751 [==============================] - 0s 94us/step - loss: 5.9332e-04 - binary_accuracy: 1.0000 - val_loss: 3.4951 - val_binary_accuracy: 0.4874\n",
      "Epoch 900/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751/751 [==============================] - 0s 76us/step - loss: 9.4321e-04 - binary_accuracy: 1.0000 - val_loss: 3.4816 - val_binary_accuracy: 0.4874\n",
      "Epoch 901/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 6.6074e-04 - binary_accuracy: 1.0000 - val_loss: 3.4650 - val_binary_accuracy: 0.4887\n",
      "Epoch 902/10000\n",
      "751/751 [==============================] - 0s 89us/step - loss: 7.2128e-04 - binary_accuracy: 1.0000 - val_loss: 3.4650 - val_binary_accuracy: 0.4913\n",
      "Epoch 903/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 4.8477e-04 - binary_accuracy: 1.0000 - val_loss: 3.4734 - val_binary_accuracy: 0.4967\n",
      "Epoch 904/10000\n",
      "751/751 [==============================] - 0s 90us/step - loss: 8.6741e-04 - binary_accuracy: 1.0000 - val_loss: 3.4751 - val_binary_accuracy: 0.4940\n",
      "Epoch 905/10000\n",
      "751/751 [==============================] - 0s 99us/step - loss: 6.1471e-04 - binary_accuracy: 1.0000 - val_loss: 3.4767 - val_binary_accuracy: 0.4953\n",
      "Epoch 906/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 4.4833e-04 - binary_accuracy: 1.0000 - val_loss: 3.4837 - val_binary_accuracy: 0.4993\n",
      "Epoch 907/10000\n",
      "751/751 [==============================] - 0s 96us/step - loss: 4.2557e-04 - binary_accuracy: 1.0000 - val_loss: 3.4930 - val_binary_accuracy: 0.4940\n",
      "Epoch 908/10000\n",
      "751/751 [==============================] - 0s 91us/step - loss: 4.3181e-04 - binary_accuracy: 1.0000 - val_loss: 3.4972 - val_binary_accuracy: 0.4980\n",
      "Epoch 909/10000\n",
      "751/751 [==============================] - 0s 88us/step - loss: 5.8311e-04 - binary_accuracy: 1.0000 - val_loss: 3.4977 - val_binary_accuracy: 0.4993\n",
      "Epoch 910/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 5.5671e-04 - binary_accuracy: 1.0000 - val_loss: 3.4970 - val_binary_accuracy: 0.4980\n",
      "Epoch 911/10000\n",
      "751/751 [==============================] - 0s 89us/step - loss: 4.8748e-04 - binary_accuracy: 1.0000 - val_loss: 3.4952 - val_binary_accuracy: 0.4993\n",
      "Epoch 912/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 5.1005e-04 - binary_accuracy: 1.0000 - val_loss: 3.4939 - val_binary_accuracy: 0.5007\n",
      "Epoch 913/10000\n",
      "751/751 [==============================] - 0s 89us/step - loss: 4.5075e-04 - binary_accuracy: 1.0000 - val_loss: 3.4931 - val_binary_accuracy: 0.4993\n",
      "Epoch 914/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 3.6498e-04 - binary_accuracy: 1.0000 - val_loss: 3.4928 - val_binary_accuracy: 0.4980\n",
      "Epoch 915/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 7.5718e-04 - binary_accuracy: 1.0000 - val_loss: 3.4944 - val_binary_accuracy: 0.4980\n",
      "Epoch 916/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 4.4779e-04 - binary_accuracy: 1.0000 - val_loss: 3.4968 - val_binary_accuracy: 0.5033\n",
      "Epoch 917/10000\n",
      "751/751 [==============================] - 0s 68us/step - loss: 5.4295e-04 - binary_accuracy: 1.0000 - val_loss: 3.5024 - val_binary_accuracy: 0.5007\n",
      "Epoch 918/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 5.7177e-04 - binary_accuracy: 1.0000 - val_loss: 3.5034 - val_binary_accuracy: 0.4967\n",
      "Epoch 919/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 5.0328e-04 - binary_accuracy: 1.0000 - val_loss: 3.4999 - val_binary_accuracy: 0.5007\n",
      "Epoch 920/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 4.0337e-04 - binary_accuracy: 1.0000 - val_loss: 3.4973 - val_binary_accuracy: 0.5033\n",
      "Epoch 921/10000\n",
      "751/751 [==============================] - 0s 87us/step - loss: 4.0600e-04 - binary_accuracy: 1.0000 - val_loss: 3.4956 - val_binary_accuracy: 0.5020\n",
      "Epoch 922/10000\n",
      "751/751 [==============================] - 0s 71us/step - loss: 3.5105e-04 - binary_accuracy: 1.0000 - val_loss: 3.4956 - val_binary_accuracy: 0.5007\n",
      "Epoch 923/10000\n",
      "751/751 [==============================] - 0s 91us/step - loss: 3.4717e-04 - binary_accuracy: 1.0000 - val_loss: 3.4958 - val_binary_accuracy: 0.5007\n",
      "Epoch 924/10000\n",
      "751/751 [==============================] - 0s 83us/step - loss: 4.7197e-04 - binary_accuracy: 1.0000 - val_loss: 3.4968 - val_binary_accuracy: 0.5033\n",
      "Epoch 925/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 3.7908e-04 - binary_accuracy: 1.0000 - val_loss: 3.4977 - val_binary_accuracy: 0.5047\n",
      "Epoch 926/10000\n",
      "751/751 [==============================] - 0s 95us/step - loss: 4.2053e-04 - binary_accuracy: 1.0000 - val_loss: 3.4989 - val_binary_accuracy: 0.5033\n",
      "Epoch 927/10000\n",
      "751/751 [==============================] - 0s 88us/step - loss: 3.9382e-04 - binary_accuracy: 1.0000 - val_loss: 3.5006 - val_binary_accuracy: 0.5047\n",
      "Epoch 928/10000\n",
      "751/751 [==============================] - 0s 70us/step - loss: 5.9822e-04 - binary_accuracy: 1.0000 - val_loss: 3.4992 - val_binary_accuracy: 0.5033\n",
      "Epoch 929/10000\n",
      "751/751 [==============================] - 0s 89us/step - loss: 5.6905e-04 - binary_accuracy: 1.0000 - val_loss: 3.4977 - val_binary_accuracy: 0.5033\n",
      "Epoch 930/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 3.9018e-04 - binary_accuracy: 1.0000 - val_loss: 3.4974 - val_binary_accuracy: 0.5033\n",
      "Epoch 931/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 4.9565e-04 - binary_accuracy: 1.0000 - val_loss: 3.4975 - val_binary_accuracy: 0.5033\n",
      "Epoch 932/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 4.2358e-04 - binary_accuracy: 1.0000 - val_loss: 3.5000 - val_binary_accuracy: 0.5073\n",
      "Epoch 933/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 3.6639e-04 - binary_accuracy: 1.0000 - val_loss: 3.5046 - val_binary_accuracy: 0.5020\n",
      "Epoch 934/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 0.0018 - binary_accuracy: 0.9987 - val_loss: 3.4879 - val_binary_accuracy: 0.5047\n",
      "Epoch 935/10000\n",
      "751/751 [==============================] - 0s 71us/step - loss: 8.8135e-04 - binary_accuracy: 1.0000 - val_loss: 3.4903 - val_binary_accuracy: 0.5020\n",
      "Epoch 936/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 8.4758e-04 - binary_accuracy: 1.0000 - val_loss: 3.4846 - val_binary_accuracy: 0.5033\n",
      "Epoch 937/10000\n",
      "751/751 [==============================] - 0s 83us/step - loss: 4.4181e-04 - binary_accuracy: 1.0000 - val_loss: 3.4717 - val_binary_accuracy: 0.5033\n",
      "Epoch 938/10000\n",
      "751/751 [==============================] - 0s 70us/step - loss: 4.6833e-04 - binary_accuracy: 1.0000 - val_loss: 3.4693 - val_binary_accuracy: 0.5060\n",
      "Epoch 939/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 4.1383e-04 - binary_accuracy: 1.0000 - val_loss: 3.4736 - val_binary_accuracy: 0.5073\n",
      "Epoch 940/10000\n",
      "751/751 [==============================] - 0s 67us/step - loss: 6.4733e-04 - binary_accuracy: 1.0000 - val_loss: 3.4790 - val_binary_accuracy: 0.5060\n",
      "Epoch 941/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 4.6566e-04 - binary_accuracy: 1.0000 - val_loss: 3.4815 - val_binary_accuracy: 0.5073\n",
      "Epoch 942/10000\n",
      "751/751 [==============================] - 0s 66us/step - loss: 4.0738e-04 - binary_accuracy: 1.0000 - val_loss: 3.4843 - val_binary_accuracy: 0.5087\n",
      "Epoch 943/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 5.0720e-04 - binary_accuracy: 1.0000 - val_loss: 3.4891 - val_binary_accuracy: 0.5100\n",
      "Epoch 944/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 5.0715e-04 - binary_accuracy: 1.0000 - val_loss: 3.4913 - val_binary_accuracy: 0.5113\n",
      "Epoch 945/10000\n",
      "751/751 [==============================] - 0s 89us/step - loss: 4.9361e-04 - binary_accuracy: 1.0000 - val_loss: 3.4936 - val_binary_accuracy: 0.5087\n",
      "Epoch 946/10000\n",
      "751/751 [==============================] - 0s 91us/step - loss: 5.3877e-04 - binary_accuracy: 1.0000 - val_loss: 3.4963 - val_binary_accuracy: 0.5060\n",
      "Epoch 947/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 4.7426e-04 - binary_accuracy: 1.0000 - val_loss: 3.4998 - val_binary_accuracy: 0.5047\n",
      "Epoch 948/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 4.0674e-04 - binary_accuracy: 1.0000 - val_loss: 3.5009 - val_binary_accuracy: 0.5060\n",
      "Epoch 949/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751/751 [==============================] - 0s 88us/step - loss: 5.2556e-04 - binary_accuracy: 1.0000 - val_loss: 3.5011 - val_binary_accuracy: 0.5047\n",
      "Epoch 950/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 6.0554e-04 - binary_accuracy: 1.0000 - val_loss: 3.5006 - val_binary_accuracy: 0.5100\n",
      "Epoch 951/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 3.8034e-04 - binary_accuracy: 1.0000 - val_loss: 3.5029 - val_binary_accuracy: 0.5060\n",
      "Epoch 952/10000\n",
      "751/751 [==============================] - 0s 71us/step - loss: 3.5760e-04 - binary_accuracy: 1.0000 - val_loss: 3.5052 - val_binary_accuracy: 0.5060\n",
      "Epoch 953/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 4.8800e-04 - binary_accuracy: 1.0000 - val_loss: 3.5092 - val_binary_accuracy: 0.5047\n",
      "Epoch 954/10000\n",
      "751/751 [==============================] - 0s 80us/step - loss: 4.5050e-04 - binary_accuracy: 1.0000 - val_loss: 3.5170 - val_binary_accuracy: 0.5020\n",
      "Epoch 955/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 4.2194e-04 - binary_accuracy: 1.0000 - val_loss: 3.5227 - val_binary_accuracy: 0.5047\n",
      "Epoch 956/10000\n",
      "751/751 [==============================] - 0s 83us/step - loss: 4.7203e-04 - binary_accuracy: 1.0000 - val_loss: 3.5275 - val_binary_accuracy: 0.5047\n",
      "Epoch 957/10000\n",
      "751/751 [==============================] - 0s 78us/step - loss: 4.9757e-04 - binary_accuracy: 1.0000 - val_loss: 3.5300 - val_binary_accuracy: 0.5033\n",
      "Epoch 958/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 4.5480e-04 - binary_accuracy: 1.0000 - val_loss: 3.5298 - val_binary_accuracy: 0.5020\n",
      "Epoch 959/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 4.8943e-04 - binary_accuracy: 1.0000 - val_loss: 3.5284 - val_binary_accuracy: 0.5060\n",
      "Epoch 960/10000\n",
      "751/751 [==============================] - 0s 67us/step - loss: 4.2533e-04 - binary_accuracy: 1.0000 - val_loss: 3.5277 - val_binary_accuracy: 0.5047\n",
      "Epoch 961/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 3.2767e-04 - binary_accuracy: 1.0000 - val_loss: 3.5293 - val_binary_accuracy: 0.5033\n",
      "Epoch 962/10000\n",
      "751/751 [==============================] - 0s 70us/step - loss: 3.6106e-04 - binary_accuracy: 1.0000 - val_loss: 3.5308 - val_binary_accuracy: 0.5033\n",
      "Epoch 963/10000\n",
      "751/751 [==============================] - 0s 98us/step - loss: 4.8041e-04 - binary_accuracy: 1.0000 - val_loss: 3.5335 - val_binary_accuracy: 0.5047\n",
      "Epoch 964/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 3.4997e-04 - binary_accuracy: 1.0000 - val_loss: 3.5369 - val_binary_accuracy: 0.5007\n",
      "Epoch 965/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 4.5146e-04 - binary_accuracy: 1.0000 - val_loss: 3.5410 - val_binary_accuracy: 0.5007\n",
      "Epoch 966/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 3.7326e-04 - binary_accuracy: 1.0000 - val_loss: 3.5436 - val_binary_accuracy: 0.5020\n",
      "Epoch 967/10000\n",
      "751/751 [==============================] - 0s 66us/step - loss: 4.2909e-04 - binary_accuracy: 1.0000 - val_loss: 3.5429 - val_binary_accuracy: 0.5007\n",
      "Epoch 968/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 3.7389e-04 - binary_accuracy: 1.0000 - val_loss: 3.5412 - val_binary_accuracy: 0.4980\n",
      "Epoch 969/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 4.0448e-04 - binary_accuracy: 1.0000 - val_loss: 3.5400 - val_binary_accuracy: 0.5033\n",
      "Epoch 970/10000\n",
      "751/751 [==============================] - 0s 71us/step - loss: 7.0981e-04 - binary_accuracy: 1.0000 - val_loss: 3.5380 - val_binary_accuracy: 0.5047\n",
      "Epoch 971/10000\n",
      "751/751 [==============================] - 0s 83us/step - loss: 3.9930e-04 - binary_accuracy: 1.0000 - val_loss: 3.5338 - val_binary_accuracy: 0.5060\n",
      "Epoch 972/10000\n",
      "751/751 [==============================] - 0s 69us/step - loss: 3.7749e-04 - binary_accuracy: 1.0000 - val_loss: 3.5315 - val_binary_accuracy: 0.5020\n",
      "Epoch 973/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 2.9913e-04 - binary_accuracy: 1.0000 - val_loss: 3.5314 - val_binary_accuracy: 0.5073\n",
      "Epoch 974/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 4.2835e-04 - binary_accuracy: 1.0000 - val_loss: 3.5337 - val_binary_accuracy: 0.5060\n",
      "Epoch 975/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 4.6986e-04 - binary_accuracy: 1.0000 - val_loss: 3.5368 - val_binary_accuracy: 0.5060\n",
      "Epoch 976/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 3.3229e-04 - binary_accuracy: 1.0000 - val_loss: 3.5402 - val_binary_accuracy: 0.5087\n",
      "Epoch 977/10000\n",
      "751/751 [==============================] - 0s 71us/step - loss: 3.3436e-04 - binary_accuracy: 1.0000 - val_loss: 3.5438 - val_binary_accuracy: 0.5087\n",
      "Epoch 978/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 3.3902e-04 - binary_accuracy: 1.0000 - val_loss: 3.5470 - val_binary_accuracy: 0.5073\n",
      "Epoch 979/10000\n",
      "751/751 [==============================] - 0s 71us/step - loss: 3.2376e-04 - binary_accuracy: 1.0000 - val_loss: 3.5488 - val_binary_accuracy: 0.5060\n",
      "Epoch 980/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 3.9447e-04 - binary_accuracy: 1.0000 - val_loss: 3.5498 - val_binary_accuracy: 0.5073\n",
      "Epoch 981/10000\n",
      "751/751 [==============================] - 0s 67us/step - loss: 4.8283e-04 - binary_accuracy: 1.0000 - val_loss: 3.5536 - val_binary_accuracy: 0.5073\n",
      "Epoch 982/10000\n",
      "751/751 [==============================] - 0s 79us/step - loss: 4.4164e-04 - binary_accuracy: 1.0000 - val_loss: 3.5580 - val_binary_accuracy: 0.5060\n",
      "Epoch 983/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 3.2214e-04 - binary_accuracy: 1.0000 - val_loss: 3.5609 - val_binary_accuracy: 0.5033\n",
      "Epoch 984/10000\n",
      "751/751 [==============================] - 0s 68us/step - loss: 6.2436e-04 - binary_accuracy: 1.0000 - val_loss: 3.5607 - val_binary_accuracy: 0.5033\n",
      "Epoch 985/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 4.2052e-04 - binary_accuracy: 1.0000 - val_loss: 3.5575 - val_binary_accuracy: 0.5033\n",
      "Epoch 986/10000\n",
      "751/751 [==============================] - 0s 68us/step - loss: 3.6176e-04 - binary_accuracy: 1.0000 - val_loss: 3.5514 - val_binary_accuracy: 0.5020\n",
      "Epoch 987/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 4.2512e-04 - binary_accuracy: 1.0000 - val_loss: 3.5469 - val_binary_accuracy: 0.4980\n",
      "Epoch 988/10000\n",
      "751/751 [==============================] - 0s 67us/step - loss: 5.7443e-04 - binary_accuracy: 1.0000 - val_loss: 3.5474 - val_binary_accuracy: 0.5007\n",
      "Epoch 989/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 3.6478e-04 - binary_accuracy: 1.0000 - val_loss: 3.5499 - val_binary_accuracy: 0.4993\n",
      "Epoch 990/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 3.8309e-04 - binary_accuracy: 1.0000 - val_loss: 3.5548 - val_binary_accuracy: 0.4993\n",
      "Epoch 991/10000\n",
      "751/751 [==============================] - 0s 70us/step - loss: 3.9213e-04 - binary_accuracy: 1.0000 - val_loss: 3.5591 - val_binary_accuracy: 0.4993\n",
      "Epoch 992/10000\n",
      "751/751 [==============================] - 0s 81us/step - loss: 3.7172e-04 - binary_accuracy: 1.0000 - val_loss: 3.5619 - val_binary_accuracy: 0.4993\n",
      "Epoch 993/10000\n",
      "751/751 [==============================] - 0s 68us/step - loss: 2.9142e-04 - binary_accuracy: 1.0000 - val_loss: 3.5658 - val_binary_accuracy: 0.5007\n",
      "Epoch 994/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 3.3206e-04 - binary_accuracy: 1.0000 - val_loss: 3.5699 - val_binary_accuracy: 0.5033\n",
      "Epoch 995/10000\n",
      "751/751 [==============================] - 0s 72us/step - loss: 3.0717e-04 - binary_accuracy: 1.0000 - val_loss: 3.5719 - val_binary_accuracy: 0.5047\n",
      "Epoch 996/10000\n",
      "751/751 [==============================] - 0s 98us/step - loss: 3.3422e-04 - binary_accuracy: 1.0000 - val_loss: 3.5728 - val_binary_accuracy: 0.5047\n",
      "Epoch 997/10000\n",
      "751/751 [==============================] - 0s 87us/step - loss: 2.5455e-04 - binary_accuracy: 1.0000 - val_loss: 3.5749 - val_binary_accuracy: 0.5020\n",
      "Epoch 998/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751/751 [==============================] - 0s 72us/step - loss: 3.7378e-04 - binary_accuracy: 1.0000 - val_loss: 3.5760 - val_binary_accuracy: 0.5033\n",
      "Epoch 999/10000\n",
      "751/751 [==============================] - 0s 83us/step - loss: 5.5451e-04 - binary_accuracy: 1.0000 - val_loss: 3.5728 - val_binary_accuracy: 0.5020\n",
      "Epoch 1000/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 2.6947e-04 - binary_accuracy: 1.0000 - val_loss: 3.5648 - val_binary_accuracy: 0.5033\n",
      "Epoch 1001/10000\n",
      "751/751 [==============================] - 0s 71us/step - loss: 3.7641e-04 - binary_accuracy: 1.0000 - val_loss: 3.5612 - val_binary_accuracy: 0.5060\n",
      "Epoch 1002/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 3.2956e-04 - binary_accuracy: 1.0000 - val_loss: 3.5596 - val_binary_accuracy: 0.5047\n",
      "Epoch 1003/10000\n",
      "751/751 [==============================] - 0s 83us/step - loss: 0.0022 - binary_accuracy: 0.9987 - val_loss: 3.5521 - val_binary_accuracy: 0.5060\n",
      "Epoch 1004/10000\n",
      "751/751 [==============================] - 0s 73us/step - loss: 5.0410e-04 - binary_accuracy: 1.0000 - val_loss: 3.5604 - val_binary_accuracy: 0.5047\n",
      "Epoch 1005/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 0.0017 - binary_accuracy: 0.9987 - val_loss: 3.5540 - val_binary_accuracy: 0.5007\n",
      "Epoch 1006/10000\n",
      "751/751 [==============================] - 0s 87us/step - loss: 5.0937e-04 - binary_accuracy: 1.0000 - val_loss: 3.5653 - val_binary_accuracy: 0.5073\n",
      "Epoch 1007/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 4.4372e-04 - binary_accuracy: 1.0000 - val_loss: 3.5908 - val_binary_accuracy: 0.4953\n",
      "Epoch 1008/10000\n",
      "751/751 [==============================] - 0s 66us/step - loss: 4.7012e-04 - binary_accuracy: 1.0000 - val_loss: 3.5991 - val_binary_accuracy: 0.4927\n",
      "Epoch 1009/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 6.0306e-04 - binary_accuracy: 1.0000 - val_loss: 3.5834 - val_binary_accuracy: 0.5033\n",
      "Epoch 1010/10000\n",
      "751/751 [==============================] - 0s 90us/step - loss: 7.3882e-04 - binary_accuracy: 1.0000 - val_loss: 3.5557 - val_binary_accuracy: 0.5033\n",
      "Epoch 1011/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 3.8851e-04 - binary_accuracy: 1.0000 - val_loss: 3.5544 - val_binary_accuracy: 0.5113\n",
      "Epoch 1012/10000\n",
      "751/751 [==============================] - 0s 75us/step - loss: 4.9853e-04 - binary_accuracy: 1.0000 - val_loss: 3.5562 - val_binary_accuracy: 0.5126\n",
      "Epoch 1013/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 5.3946e-04 - binary_accuracy: 1.0000 - val_loss: 3.5545 - val_binary_accuracy: 0.5100\n",
      "Epoch 1014/10000\n",
      "751/751 [==============================] - 0s 84us/step - loss: 4.2338e-04 - binary_accuracy: 1.0000 - val_loss: 3.5624 - val_binary_accuracy: 0.5060\n",
      "Epoch 1015/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 3.3372e-04 - binary_accuracy: 1.0000 - val_loss: 3.5736 - val_binary_accuracy: 0.5020\n",
      "Epoch 1016/10000\n",
      "751/751 [==============================] - 0s 85us/step - loss: 8.0104e-04 - binary_accuracy: 1.0000 - val_loss: 3.5729 - val_binary_accuracy: 0.5047\n",
      "Epoch 1017/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 4.6690e-04 - binary_accuracy: 1.0000 - val_loss: 3.5640 - val_binary_accuracy: 0.5033\n",
      "Epoch 1018/10000\n",
      "751/751 [==============================] - 0s 82us/step - loss: 5.5605e-04 - binary_accuracy: 1.0000 - val_loss: 3.5623 - val_binary_accuracy: 0.5087\n",
      "Epoch 1019/10000\n",
      "751/751 [==============================] - 0s 69us/step - loss: 4.7644e-04 - binary_accuracy: 1.0000 - val_loss: 3.5635 - val_binary_accuracy: 0.5100\n",
      "Epoch 1020/10000\n",
      "751/751 [==============================] - 0s 74us/step - loss: 4.4343e-04 - binary_accuracy: 1.0000 - val_loss: 3.5683 - val_binary_accuracy: 0.5113\n",
      "Epoch 1021/10000\n",
      "751/751 [==============================] - 0s 88us/step - loss: 5.3870e-04 - binary_accuracy: 1.0000 - val_loss: 3.5761 - val_binary_accuracy: 0.5020\n",
      "Epoch 1022/10000\n",
      "751/751 [==============================] - 0s 91us/step - loss: 3.2921e-04 - binary_accuracy: 1.0000 - val_loss: 3.5864 - val_binary_accuracy: 0.4967\n",
      "Epoch 1023/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 3.0486e-04 - binary_accuracy: 1.0000 - val_loss: 3.5949 - val_binary_accuracy: 0.4953\n",
      "Epoch 1024/10000\n",
      "751/751 [==============================] - 0s 77us/step - loss: 3.5995e-04 - binary_accuracy: 1.0000 - val_loss: 3.5985 - val_binary_accuracy: 0.4953\n",
      "Epoch 1025/10000\n",
      "751/751 [==============================] - 0s 71us/step - loss: 3.7831e-04 - binary_accuracy: 1.0000 - val_loss: 3.5983 - val_binary_accuracy: 0.4967\n",
      "Epoch 1026/10000\n",
      "751/751 [==============================] - 0s 76us/step - loss: 3.4389e-04 - binary_accuracy: 1.0000 - val_loss: 3.5976 - val_binary_accuracy: 0.4967\n",
      "Epoch 01026: early stopping\n"
     ]
    }
   ],
   "source": [
    "validation_data_split = 0.5\n",
    "num_epochs = 10000\n",
    "model_batch_size = 256\n",
    "early_patience = 1024\n",
    "\n",
    "earlystopping_cb = EarlyStopping(monitor='binary_accuracy', verbose=1, patience=early_patience, mode='min')\n",
    "\n",
    "# Process Dataset\n",
    "model_hist = model.fit(train.iloc[:,0:len(train.columns)-1]\n",
    "                    , to_categorical(train.iloc[:,len(train.columns)-1:])\n",
    "                    , validation_split=validation_data_split\n",
    "                    , epochs=num_epochs\n",
    "                    , batch_size=model_batch_size\n",
    "                    , callbacks = [earlystopping_cb]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Categorical Accuracy Before Early Stopping: 0.9972772543259413\n",
      "Average Validation Accuracy Before Early Stopping: 0.9975997708610266\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Categorical Accuracy Before Early Stopping: \"+ str( np.mean(model_hist.history['binary_accuracy'][-early_patience:])))\n",
    "print(\"Average Validation Accuracy Before Early Stopping: \"+ str(np.mean(model_hist.history['val_binary_accuracy'][-early_patience:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x7fd895d67f98>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x7fd895db2c18>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x7fd8994a3a90>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x7fd895d1de80>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1080 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df = pd.DataFrame(model_hist.history)\n",
    "df.plot(subplots=True, grid=True, figsize=(10,15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.predict(np.array(test.iloc[:,0:len(test.columns)-1]))\n",
    "predicted = np.around(y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14652,     0],\n",
       "       [   40,     0]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(to_categorical(test['target'].values).argmax(axis=1), predicted.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[278380,      0],\n",
       "       [   751,      0]])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model.predict(np.array(train.iloc[:,0:len(train.columns)-1]))\n",
    "predicted = np.around(y,0)\n",
    "confusion_matrix(to_categorical(train['target'].values).argmax(axis=1), predicted.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(abs(to_categorical(test['target'].values).argmax(axis=1) - predicted.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
